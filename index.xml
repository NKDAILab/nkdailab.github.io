<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home | NKD AI Lab</title>
    <link>https://nkdailab.github.io/</link>
      <atom:link href="https://nkdailab.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Home</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://nkdailab.github.io/media/icon_hu_de2b0bb0af672a83.png</url>
      <title>Home</title>
      <link>https://nkdailab.github.io/</link>
    </image>
    
    <item>
      <title>He Zhihai&#39;s group in the Department of Electronics at SUSTech is pleased to present two AAAI-2025 Oral Papers</title>
      <link>https://nkdailab.github.io/post/2025.3.6/</link>
      <pubDate>Wed, 26 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/post/2025.3.6/</guid>
      <description>&lt;p&gt;AAAI, short for The Association for Advancement of Artificial Intelligence, is one of the most important international conferences in the field of Artificial Intelligence, hosted by the International Association for Artificial Intelligence, and recommended by the Chinese Computer Federation (CCF) as a Class A conference. AAAI AAAI 2025 received 12,957 submissions and 3032 papers were accepted, with an acceptance rate of 23.4%, of which the Oral Presentation acceptance rate was 4.6%.AAAI 2025 was held on 25 February - 4 March 2025 in Philadelphia, Pennsylvania, USA.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;u&gt;《Cross-Modal Few-Shot Learning with Second-Order Neural Ordinary Differential Equations》&lt;/u&gt;&lt;/strong&gt;&lt;/br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Authors&lt;/u&gt;&lt;/strong&gt;&lt;/br&gt;
Yi Zhang (Harbin Institute of Technology, Southern University of Science and Technology), Chun-Wun Cheng (University of Cambridge), Junyi He (Southern University of Science and Technology), Zhihai He (Southern University of Science and Technology), Carola-Bibiane Schönlieb (University of Cambridge), Yuyan Chen (Fudan University), Angelica I Aviles-Rivero (Tsinghua University)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Brief introduction&lt;/u&gt;&lt;/strong&gt;&lt;/br&gt;
Yi Zhang, a PhD student in the class of 2021 at the Department of Electronic and Electrical Engineering, Southern University of Science and Technology, proposes an innovative method SONO in the field of cross-modal small-sample learning, which significantly improves the model&amp;rsquo;s generalisation ability in few-sample scenarios through second-order God-frequent differential equations, and effectively solves the overfitting problem due to the scarcity of data in the traditional method.
With the rapid development of multimodal AI technology, how to make the model achieve cross-modal (e.g., image-text) efficient learning under a very small number of labelled samples has become a key challenge. Existing methods generally face bottlenecks such as high risk of overfitting, high consumption of computational resources, and insufficient cross-modal alignment capability. The research team innovatively introduces the second-order God&amp;rsquo;s frequent differential equation into the cross-modal learning framework, enhances the model expression ability through continuous dynamic feature optimisation, and combines the ‘text-as-image’ data enhancement strategy to effectively expand the training data by using the graphic-text correlation feature of CLIP model. Experiments show that the classification accuracy of this method on 11 benchmark datasets, such as ImageNet, is significantly better than that of the existing optimal method for small samples, and shows potential application in data-scarce scenarios, such as medical images.
&lt;img src=&#34;fig1.png&#34; width=&#34;2048&#34;&gt;&lt;/p&gt;
&lt;p&gt;This paper is the result of research conducted by Yi Zhang, a PhD student from the Department of Electronics, SUSTech, class of 2021, during his visit to the University of Cambridge, UK, under the supervision of Professor Zhihai He Chair of SUSTech and Assistant Professor Angelica I. Aviles-Rivero, Tsinghua University Qiu Chengtong Mathematical Sciences Centre, during her tenure as a Senior Associate Researcher at the University of Cambridge, and in collaboration with the research institutes of SUSTech, the Cambridge University Department of Applied Department of Mathematics and Theoretical Physics, University of Cambridge, Tsinghua University&amp;rsquo;s Chuchengtong Centre for Mathematical Sciences, Shanghai Key Laboratory of Data Science and other research institutions. Yi Zhang, a joint PhD candidate of SUSTech and Harbin Institute of Technology, is the first author of this paper, while Junhuan Zheng, a PhD student of Cambridge University, Junyi He, an undergraduate student of SUSTech in the class of 2021, Prof. Carola-Bibiane Schönlieb of Cambridge University, and Yuyan Chen, a PhD student of the Shanghai Key Laboratory of Data Science of Fudan University are the authors of this paper, as well as Zhi-Hai He, a chair professor of the Department of Electronics of SUSTech, Angelica I. Aviles-Rivero, Assistant Professor at the Qiu Chengtong Centre for Mathematical Sciences, Tsinghua University, are the corresponding authors of this paper. NUST doctoral student Yi Zhang and undergraduate student Jun He are also from Zhihai He&amp;rsquo;s group.&lt;/p&gt;
&lt;p&gt;Paper link: &lt;a href=https://arxiv.org/abs/2412.15813&gt;&lt;a href=&#34;https://arxiv.org/abs/2412.15813&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2412.15813&lt;/a&gt;&lt;/a&gt;&lt;/br&gt;
Funding information: This work was supported by the National Natural Science Foundation of China under Key Project No. 62331014.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;u&gt;《Conditional Latent Coding with Learnable Synthesized Reference for Deep Image Compression》&lt;/u&gt;&lt;/strong&gt;&lt;/br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Authors&lt;/u&gt;&lt;/strong&gt;&lt;/br&gt;
Siqi Wu (University of Missouri), Yinda Chen (University of Science and Technology of China), Dong Liu (University of Science and Technology of China), Zhihai He (Southern University of Science and Technology)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Brief introduction&lt;/u&gt;&lt;/strong&gt;&lt;/br&gt;
Siqi Wu, a PhD student in the Department of Electrical and Computer Engineering, University of Missouri, USA, class of 2022, has proposed a conditional latent coding method based on learnable synthetic references to improve the efficiency of deep image compression in collaboration with the University of Science and Technology of China (USTC) during his visit to Southern University of Science and Technology (SUSTech) as a visiting researcher.&lt;/p&gt;
&lt;p&gt;With the rapid development of digital technology and the dramatic increase in the amount of image data, efficient image compression techniques are crucial for storing, transmitting and processing image data. Current deep learning methods have made significant progress in image compression, but still face the challenge of effectively exploiting image source correlation while maintaining high reconstruction quality. The article proposes a conditional latent coding method to conditionally encode the input image by dynamically generating a reference representation from an external dictionary. The input image will be matched with the features in the dictionary to exploit the correlation between the input image and the reference dictionary in order to achieve efficient compression and high quality reconstruction of the input image. This thesis achieves a large enhancement on the publicly available datasets Kodak and CLIC, providing useful insights for further research and potential improvements.
&lt;img src=&#34;fig2.png&#34; width=&#34;888&#34;&gt;&lt;/p&gt;
&lt;p&gt;Siqi Wu, a PhD student from the University of Missouri, class of 2022, is currently conducting visiting research in Zhihai He&amp;rsquo;s group as a visiting student at the Southern University of Science and Technology (SUSTech) in the U.S.A. She is the co-first author of this paper together with Yinda Chen, a PhD student from the University of Science and Technology of China, class of 2024. Dong Liu, a professor in the Department of Electrical Engineering and Information Science at the University of Science and Technology of China (USTC), is the author of this paper, and Zhihai He, a chair professor in the Department of Electronics at USTC, is the corresponding author of this paper. The University of Missouri is the first unit of the paper, and Southern University of Science and Technology is the third unit of the paper.&lt;/p&gt;
&lt;p&gt;Paper link: &lt;a href=https://arxiv.org/abs/2502.09971v1&gt;&lt;a href=&#34;https://arxiv.org/abs/2502.09971v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2502.09971v1&lt;/a&gt;&lt;/a&gt;&lt;/br&gt;
Funding information: This work was supported by the National Natural Science Foundation of China under Key Project No. 62331014.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Professor Zhihai He&#39;s team from the Department of Electronics, SUSTech, won the second prize for technical invention in the 2024 Wu Wenjun Artificial Intelligence Science and Technology Award</title>
      <link>https://nkdailab.github.io/post/2025.2.25/</link>
      <pubDate>Tue, 25 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/post/2025.2.25/</guid>
      <description>&lt;p&gt;Recently, the list of winners of the 2024 Wu Wenjun Artificial Intelligence Science and Technology Award was officially released, and Professor He Zhihai Chair of the Department of Electrical and Electronic Engineering of the Southern University of Science and Technology (SUSTech), as the first project completion, stood out for his project of ‘Big Model-Driven Home AI Doctor and Total Patient Care Management’, which won the ‘Second Prize for Technological Invention of the Year 2024’. ‘The Second Prize for Technical Invention in the 2024 Wu Wenjun Artificial Intelligence Science and Technology Award.&lt;/p&gt;
&lt;img src=&#34;fig1.jpg&#34; width=&#34;888&#34;&gt;
&lt;p style=&#34;font-size:15px;text-align:center&#34;&gt;Figure 1. Winners List.&lt;/p&gt;
&lt;p&gt;Initiated by the Chinese Society for Artificial Intelligence, the Wu Wenjun Artificial Intelligence Science and Technology Award, known as ‘China&amp;rsquo;s Highest Prize for Intelligent Science and Technology’, is a symbol of the highest honour in the field of artificial intelligence. The award aims to recognise units and individuals who have made key discoveries in AI research, promoted scientific and technological progress, and created significant economic and social benefits or ecological and environmental benefits.&lt;/p&gt;
&lt;p&gt;Professor He Zhihai, together with Professor Cao Wenming of Shenzhen University, Professor Cen Yigang of Beijing Jiaotong University, and Senior Research Scholar Ouyang Jian of the Southern University of Science and Technology, jointly declared the achievement of ‘Big Model-Driven Home AI Doctor and Total Disease Management’, which is an innovative use of AI and big model technology to build a set of products that cover the following areas: home health and disease monitoring, analytical modelling, analysis and modelling, and home health and disease management. It innovatively uses artificial intelligence and big model technology to build a comprehensive platform covering home health and disease monitoring, analysis and modelling, early warning and intervention, diagnosis and treatment assistance, as well as chronic disease prevention and control management. The platform greatly empowers healthcare professionals to provide professional and intelligent health monitoring and disease management services for elderly patients with chronic diseases in the home environment, effectively solving the health monitoring and disease management problems brought about by aging.&lt;/p&gt;
&lt;img src=&#34;fig2.jpg&#34; width=&#34;888&#34;&gt;
&lt;p style=&#34;font-size:15px;text-align:center&#34;&gt;Figure 2. AI home healthcare intelligent agent.&lt;/p&gt;
&lt;p&gt;At present, the project has been successfully applied on a large scale in Guangdong, Hunan and Zhejiang, effectively improving the health management of local elderly patients with chronic diseases and generating good social benefits, and is expected to provide reference and demonstration for more regions to cope with the health challenges of aging.&lt;/p&gt;
&lt;p&gt;Original link: &lt;a href=https://mp.weixin.qq.com/s/K3X2Avrt6lgsTJWg3ry3Qw&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/K3X2Avrt6lgsTJWg3ry3Qw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://mp.weixin.qq.com/s/K3X2Avrt6lgsTJWg3ry3Qw&lt;/a&gt;&lt;/a&gt;&lt;/br&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Critical Sampling for Data-Driven Modeling of Unknown Dynamical Systems</title>
      <link>https://nkdailab.github.io/publication/critical-sampling-for-data-driven-modeling-of-unknown-dynamical-systems/</link>
      <pubDate>Sun, 05 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/publication/critical-sampling-for-data-driven-modeling-of-unknown-dynamical-systems/</guid>
      <description>&lt;!-- 


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation</title>
      <link>https://nkdailab.github.io/publication/learning-to-adapt-clip-for-few-shot-monocular-depth-estimation/</link>
      <pubDate>Thu, 02 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/publication/learning-to-adapt-clip-for-few-shot-monocular-depth-estimation/</guid>
      <description>&lt;!-- 


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Cross-inferential networks for source-free unsupervised domain adaptation</title>
      <link>https://nkdailab.github.io/publication/cross-inferential-networks-for-source-free-unsupervised-domain-adaptation/</link>
      <pubDate>Sun, 08 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/publication/cross-inferential-networks-for-source-free-unsupervised-domain-adaptation/</guid>
      <description>&lt;!-- 


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>BDC-Adapter Brownian Distance Covariance for Better Vision-Language Reasoning</title>
      <link>https://nkdailab.github.io/publication/bdc-adapter-brownian-distance-covariance-for-better-vision-language-reasoning/</link>
      <pubDate>Sun, 03 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/publication/bdc-adapter-brownian-distance-covariance-for-better-vision-language-reasoning/</guid>
      <description>&lt;!-- 


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Unsupervised Prototype Adapter for Vision-Language Models</title>
      <link>https://nkdailab.github.io/publication/unsupervised-prototype-adapter-for-vision-language-models/</link>
      <pubDate>Tue, 22 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/publication/unsupervised-prototype-adapter-for-vision-language-models/</guid>
      <description>&lt;!-- 


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Cycle optimization metric learning for few-shot classification</title>
      <link>https://nkdailab.github.io/publication/cycle-optimization-metric-learning-for-few-shot-classification/</link>
      <pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/publication/cycle-optimization-metric-learning-for-few-shot-classification/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Critical Sampling for Robust Evolution Operator Learning of Unknown Dynamical Systems</title>
      <link>https://nkdailab.github.io/publication/critical-sampling-for-robust-evolution-operator-learning-of-unknown-dynamical-systems/</link>
      <pubDate>Sat, 15 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/publication/critical-sampling-for-robust-evolution-operator-learning-of-unknown-dynamical-systems/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation</title>
      <link>https://nkdailab.github.io/publication/self-correctable-and-adaptable-inference-for-generalizable-human-pose-estimation/</link>
      <pubDate>Mon, 20 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/publication/self-correctable-and-adaptable-inference-for-generalizable-human-pose-estimation/</guid>
      <description>&lt;!-- 


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation</title>
      <link>https://nkdailab.github.io/publication/neuro-modulated-hebbian-learning-for-fully-test-time-adaptation/</link>
      <pubDate>Thu, 02 Mar 2023 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/publication/neuro-modulated-hebbian-learning-for-fully-test-time-adaptation/</guid>
      <description>&lt;!-- 


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Self-guided information for few-shot classification</title>
      <link>https://nkdailab.github.io/publication/self-guided-information-for-few-shot-classification/</link>
      <pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/publication/self-guided-information-for-few-shot-classification/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>https://nkdailab.github.io/contact/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Home</title>
      <link>https://nkdailab.github.io/tour/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/tour/</guid>
      <description></description>
    </item>
    
    <item>
      <title>People</title>
      <link>https://nkdailab.github.io/people/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/people/</guid>
      <description></description>
    </item>
    
    <item>
      <title>research</title>
      <link>https://nkdailab.github.io/event/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/event/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation</title>
      <link>https://nkdailab.github.io/publication/self-constrained-inference-optimization-on-structural-groups-for-human-pose-estimation/</link>
      <pubDate>Sun, 23 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/publication/self-constrained-inference-optimization-on-structural-groups-for-human-pose-estimation/</guid>
      <description>&lt;!-- 

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code and math](https://wowchemy.com/docs/content/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Zhehan Kan, a postgraduate of Zhihai He Research Group of the Department of Electronics, in occlusion and generalization issue in human pose estimation with a novel self-constrained approach</title>
      <link>https://nkdailab.github.io/post/zhehan-kan-a-postgraduate-of-zhihai-he-research-group-of-the-department-of-electronics-in-occlusion-and-generalization-issue-in-human-pose-estimation-with-a-novel-self-constrained-approach/</link>
      <pubDate>Sun, 23 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/post/zhehan-kan-a-postgraduate-of-zhihai-he-research-group-of-the-department-of-electronics-in-occlusion-and-generalization-issue-in-human-pose-estimation-with-a-novel-self-constrained-approach/</guid>
      <description>&lt;p&gt;&lt;strong&gt;&lt;u&gt;Context for the reader&lt;/u&gt;&lt;/strong&gt;&lt;/br&gt;
Human pose estimation aims to correctly detect and localize keypoints, i.e., human body joints or parts. It is one of the fundamental computer vision tasks which plays an important role in a variety of downstream applications, such as motion capture, activity recognition and person tracking. With the advent of the XR era, technologies such as virtual reality (VR), human-computer interaction (HCI), and augmented reality (AR) have gradually matured. As a core part in XR research, it is becoming more and more important to reach accurate estimation of human pose. However, due to free-style motion of human bodies, for complex scenes with person-person occlusions, large variations of appearance and texture, and cluttered backgrounds, pose estimation remains very challenging.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Authored researchers and journal details&lt;/u&gt;&lt;/strong&gt;&lt;/br&gt;
Chair Professor Zhihai He’s team from the Department of Electronic and Electrical Engineering (EEE) at the Southern University of Science and Technology (SUSTech)&lt;/br&gt;
European Conference on Computer Vision (ECCV 2022), a top conference in computer vision with the proceedings published by Springer Science+Business Media,&lt;/br&gt;
entitled “Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Findings &amp;amp; Conclusion&lt;/u&gt;&lt;/strong&gt;&lt;/br&gt;
Prof. He’s team observed that human poses exhibit strong group-wise structural correlation and spatial coupling between keypoints due to the biological constraints of different body parts. Based on this observation, researchers propose to partition the body keypoints into structural groups. Within each group, the keypoints are further partitioned into two subsets, proximal keypoints with high estimation accuracy and low-accuracy distal keypoints. This group-wise structural correlation can be explored to improve the accuracy and robustness of human pose estimation.
&lt;img src=&#34;fig1.png&#34; width=&#34;700&#34;&gt;&lt;/p&gt;
&lt;p style=&#34;font-size:15px;text-align:center&#34;&gt;Figure 1. Illustration of the proposed idea of self-constrained inference optimization of structural groups for human pose estimation.&lt;/p&gt;
&lt;p&gt;One fundamental challenge in pose estimation, as well as in generic prediction tasks, is that there is no mechanism for us to verify if the obtained pose estimation or prediction results are accurate or not, since the ground truth is not available. Prof. He’s team developed a self-constrained prediction-verification network to perform forward and backward predictions between these keypoint subsets. In Figure 2, This prediction-verification network with a forward-backward prediction loop learns the internal structural correlation between the proximal keypoints and the distal keypoint. The learning process is guided by the self-constraint loss. If the internal structural correlation is successfully learned, then the self-constraint loss generated by the forward and backward prediction loop should be small. This step is referred to as self-constrained learning.
&lt;img src=&#34;fig2.png&#34; width=&#34;700&#34;&gt;&lt;/p&gt;
&lt;p style=&#34;font-size:15px;text-align:center&#34;&gt;Figure2. The overall framework of the proposed network.&lt;/p&gt;
&lt;p&gt;Once successfully learned, the verification network serves as an accuracy verification module for the forward pose prediction. During the inference stage, it can be used to guide the local optimization of the pose estimation results of low-accuracy keypoints with the self-constrained loss on high-accuracy keypoints as the objective function. This provides an effective mechanism to iteratively refine the prediction result based on the specific statistics of the test sample. This step is referred to as self-constrained optimization. Such feedback-based adaptive prediction will result in better generalization capability on the test sample.&lt;/p&gt;
&lt;p&gt;The comparison and ablation experiments are performed on MS COCO dataset and CrowdPose dataset, both of which contain very challenging scenes for pose estimation such as multi-person poses of various body scales and occlusion patterns. The proposed method outperforms the current best by a large margin, up to 2.5% on MS COCO dataset. On CrowdPose dataset, it has improved the pose estimation accuracy by up to 1.5%, which is quite significantly. Visualization results in Figure 3 also demonstrate that the proposed method can significantly improve the pose estimation results.
&lt;img src=&#34;fig3.png&#34; width=&#34;700&#34;&gt;&lt;/p&gt;
&lt;p style=&#34;font-size:15px;text-align:center&#34;&gt;Figure 3. Three examples of refinement of predicted keypoints. The top row is the original estimation. The bottom row is the refined version by the proposed method.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/br&gt;
In this work, reaserchers partition the body keypoints into structural groups exploring the structural correlation within each group and develop a prediction-verification network to characterize structural correlation between them based on a self-constraint loss. A self-constrained optimization method was introduced which uses the learned verification network as a performance assessment module to optimize the pose estimation of distal keypoints during the inference stage where the ground truth is not available. The extensive experimental results on benchmark MS COCO datasets demonstrated that the proposed SCIO method is able to significantly improve the pose estimation results, providing important reference value for follow-up research.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Authors of the original paper&lt;/u&gt;&lt;/strong&gt;&lt;/br&gt;
Master student Zhehan Kan of the Department of Electronic and Electrical Engineering (EEE) at SUSTech is the first author. Master student Shuoshuo Chen of the Department of Electronic and Electrical Engineering (EEE) at SUSTech and Associate Professor Zeng Li of Department of Statistics and Data Science are authors of this paper. Chair Professor Zhihai He of Electronic and Electrical Engineering (EEE) at SUSTech is the corresponding author.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Supporting organizations&lt;/u&gt;&lt;/strong&gt;&lt;/br&gt;
Zeng Li’s research is partially supported by the National Natural Science Foundation of China NSFC (No. 12031005 and No. 12101292)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;u&gt;Any other recommendations &lt;/u&gt;&lt;/strong&gt;&lt;/br&gt;
Paper link: &lt;u&gt;&lt;a href=&#34;https://arxiv.org/abs/2207.02425&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/2207.02425&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://nkdailab.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://nkdailab.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
