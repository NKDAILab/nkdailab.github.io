<!DOCTYPE html>
<!-- This site was created with Hugo Blox. https://hugoblox.com -->
<!-- Last Published: December 4, 2025 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Hugo Blox Builder 5.9.7" />
  

  
  












  
  










  







  
  

  
  
  

  
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.e4b9d3e8ce28da563d74b4089f677743.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css" integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css" integrity="" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.63b8f95c9bb6734ca6b02cdff7183fab.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  



























  
  
  






  <meta name="author" content="沈滢" />





  

<meta name="description" content="&lt;b&gt;Ying Shen&lt;/b&gt;&lt;/br&gt;&lt;t&gt;12132139@mail.sustech.edu.cn&lt;/t&gt;&lt;/br&gt;" />



  <link rel="alternate" hreflang="zh" href="https://nkdailab.github.io/author/%E4%BD%95%E5%BF%97%E6%B5%B7/" />

<link rel="alternate" hreflang="en-us" href="https://nkdailab.github.io/en/author/%E4%BD%95%E5%BF%97%E6%B5%B7/" />
<link rel="canonical" href="https://nkdailab.github.io/en/author/%E4%BD%95%E5%BF%97%E6%B5%B7/" />



  <link rel="manifest" href="/en/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hu_d78793efeb3744c5.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hu_ce0f57a661b5b57d.png" />

<meta name="theme-color" content="#1565c0" />










  
  
  






<meta property="twitter:card" content="summary" />
<meta property="twitter:image" content="https://nkdailab.github.io/en/author/%E4%BD%95%E5%BF%97%E6%B5%B7/avatar_hu_1525a41a409e05cc.jpg" />



  

<meta property="og:type" content="website" />
<meta property="og:site_name" content="NKD AI Lab" />
<meta property="og:url" content="https://nkdailab.github.io/en/author/%E4%BD%95%E5%BF%97%E6%B5%B7/" />
<meta property="og:title" content="何志海 | NKD AI Lab" />
<meta property="og:description" content="&lt;b&gt;Ying Shen&lt;/b&gt;&lt;/br&gt;&lt;t&gt;12132139@mail.sustech.edu.cn&lt;/t&gt;&lt;/br&gt;" /><meta property="og:image" content="https://nkdailab.github.io/en/author/%E4%BD%95%E5%BF%97%E6%B5%B7/avatar_hu_1525a41a409e05cc.jpg" /><meta property="og:locale" content="en-us" />

  










  
  
  

  
  
    <link rel="alternate" href="/en/author/%E4%BD%95%E5%BF%97%E6%B5%B7/index.xml" type="application/rss+xml" title="NKD AI Lab" />
  

  


  
  <title>何志海 | NKD AI Lab</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="e636e7db9f55c48b97b93fffc09401a8" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.4fef3e534144e9903491f0cc6527eccd.js"></script>

  




  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/en/">NKD AI Lab</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/en/">NKD AI Lab</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/en/tour"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/en/event"><span>Research</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/en/people"><span>People</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/en/publication"><span>Publications</span></a>
          </li>

          
          

          

          
          
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/en/post"><span>News</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        
          
        

        
        
        

        
        
        

        
        
        <li class="nav-item dropdown i18n-dropdown">
          <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown"
             aria-haspopup="true" aria-label="Languages">
            <i class="fas fa-globe mr-1" aria-hidden="true"></i><span class="d-none d-lg-inline">English</span></a>
          <div class="dropdown-menu">
            <div class="dropdown-item dropdown-item-active">
              <span>English</span>
            </div>
            
            <a class="dropdown-item" href="https://nkdailab.github.io/author/%E4%BD%95%E5%BF%97%E6%B5%B7/">
              <span>中文 (简体)</span>
            </a>
            
          </div>
        </li>
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    




<section id="profile-page" class="pt-5">
  <div class="container">
    
    
    
      
      
      
      









  










<div class="row">
  <div class="col-12 col-lg-4">
    <div id="profile">

      
      
      <img class="avatar avatar-circle"
           width="270" height="270"
           src="/en/author/%E4%BD%95%E5%BF%97%E6%B5%B7/avatar_hu_1525a41a409e05cc.jpg" alt="何志海">
      

      <div class="portrait-title">

        <h2>何志海</h2>

        <h3><b>Prof. Zhihai He</b></br>Chair Professor of SUSTech</br>IEEE Fellow</br><t><a href="mailto:hezh@sustech.edu.cn">hezh@sustech.edu.cn</a></t></br>Office 410, South Tower, CoE Building</br></h3>

        
        <h3>
          
          <span>Department of Electronic and Electrical Engineering, Southern University of Science and Technology</span>
          
        </h3>
        
      </div>

      <ul class="network-icon" aria-hidden="true">
        
        
        
        
        
        
        
        
          
        
        <li>
          <a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=wtr6OgkAAAAJ" target="_blank" rel="noopener" aria-label="google-scholar">
            <i class="ai ai-google-scholar big-icon"></i>
          </a>
        </li>
        
      </ul>

    </div>
  </div>
  <div class="col-12 col-lg-8">

    
    

    <div class="article-style">
      <p>Professor He is a Chair Professor in the Department of Electronic Engineering at the Southern University of Science and Technology, IEEE Fellow (2015). Prior to returning to China full-time in June 2021, he served as a Chair Professor in the Department of Electronic Engineering at the University of Missouri, USA. His research interests Generative visual AI, inference and control optimization for multimodal large models, health guardian robots, AI agents. From 2019 to 2025, he has been consecutively listed on Stanford University&rsquo;s World&rsquo;s Top 2% Scientists Lifetime Scientific Impact Rankings. He possesses extensive experience in the industrialization of scientific research achievements in the fields of industrial AI inspection and AI-based home-based healthcare and elderly care. As the principal investigator, he has undertaken key projects funded by the National Natural Science Foundation of China and the Tianyuan Mathematical and Intelligence + Cross-disciplinary Key Special Program of the National Natural Science Foundation of China. He has been honored with awards such as the Best Paper Award from the IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT) international journal and the Wu Wenjun AI Technological Invention Award from the Chinese Association for Artificial Intelligence.</p>
<h3 id="research-interests"><strong>Research Interests</strong></h3>
<ul>
<li>Generative Visual AI</li>
<li>Multimodal Large Model Inference &amp; Control Optimization</li>
<li>Health Guardian Robots</li>
<li>AI Agents</li>
</ul>
<h3 id="open-positions"><strong>Open Positions</strong></h3>
<p>Prof. Zhihai He&rsquo;s Research Group is actively recruiting Postdoctoral Fellows and Ph.D. students specializing in Generative Visual AI, Multimodal Large Model Reasoning &amp; Control Optimization, Health Guardian Robots, and AI Agents. We also warmly welcome visiting scholars and exchange students from domestic and international universities and research institutions. Interested candidates are invited to send their CVs to: <a href="mailto:hezh@sustech.edu.cn">hezh@sustech.edu.cn</a>. Contact Address: Unit 434, South Building, School of Engineering, Southern University of Science and Technology, 1088 Xueyuan Avenue, Nanshan District, Shenzhen, Guangdong Province, Tel: +86 13602642426</p>
<h3 id="work-experience"><strong>Work Experience</strong></h3>
<ul>
<li>(2021 - Present) Chair Professor, Southern University of Science and Technology, Shenzhen</li>
<li>(2013 - 2021) Professor, University of Missouri, Columbia</li>
<li>(2009 - 2013) Associate Professor, University of Missouri, Columbia</li>
<li>(2003 - 2009) Assistant Professor, University of Missouri, Columbia</li>
<li>(Summer, 2005) Summer Faculty Fellow, Air Force Research Lab, Wright-Pattern Air Force Base, Dayton OH</li>
<li>(2001 - 2003) Research Engineer, David Sarnoff Research Center (Sarnoff Co.),	Princeton NJ.</li>
</ul>
<h3 id="personal-honors"><strong>Personal Honors</strong></h3>
<ul>
<li>(2025) Second Prize of the 2024 WU WEN JUN AI SCIENCE &amp; TECHNOLOGY AWARD for Technological Invention. (Chinese Association for Artificial Intelligence，CAAI)</li>
<li>(2021) Shenzhen Overseas High-level Talents</li>
<li>(2017) Missouri Honors Engineering Senior Faculty Research Award</li>
<li>(2015) IEEE Fellow</li>
<li>(2010) IEEE Transactions on Circuits and Systems for Video Technology Outstanding Associate Editor Award</li>
<li>(2009) Provost&rsquo;s Outstanding Junior Faculty Research and Creative Activity Award</li>
<li>(2008) Missouri Honors Engineering Junior Faculty Research Award</li>
<li>(2004) 2004 SPIE VCIP Young Investigator Award</li>
<li>(2002) IEEE Transactions on Circuits and Systems for Video Technology Best Paper Award for Year 2002</li>
</ul>
<h3 id="personal-activities"><strong>Personal Activities</strong></h3>
<ul>
<li>Associate Editor, IEEE Transactions on Multimedia, 2009 – 2013</li>
<li>Associate Editor, Journal of Visual Communication and Image Representation, June 2009 – Present.</li>
<li>Associate Editor, IEEE Transactions on Circuit and System for Video Technologies, 2009 -2011.</li>
<li>Guest Editor, IEEE Transactions on Circuit and System for Video Technologies, special issue on advanced technologies for video surveillance, 2010</li>
<li>Session chair, International Conference on Image Processing, Orlando, FL, 2012.</li>
<li>Conference tutorial, Visual Communication and Image Processing Conference, San Diego, 2012</li>
<li>Special Session Chair, Visual Communications and Image Processing, 2013</li>
<li>International Liaison Chair, Visual Communications and Image Processing, 2010</li>
<li>NSF Review Panel, CISE Creative IT, 2009</li>
<li>Technical Program Review Committee, IEEE International Symposium on Circuits and Systems 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016</li>
<li>Co-Chair, International Symposium on Multimedia over Wireless, Hawaii, 2007</li>
<li>TPC member, Multimedia Systems and Applications, SPIE Electronic Imaging, 2007</li>
<li>Session Chair, SPIE Visual Communication and Image Processing, 2007</li>
<li>TPC member, IEEE Globecom 2007 Signal Processing Symposium</li>
<li>Vice Chair, International Symposium on Multimedia over Wireless, WirelessCom 2005, Maui, Hawaii, USA, June 13-16, 2005</li>
<li>Member, Award Committee, IEEE Communication Society</li>
<li>Member, Technical Program Committee, 2nd International Mobile Multimedia Communications Conference</li>
<li>Member, Technical Program Committee, International Conference on Communication (ICC), 2005</li>
<li>Member, Technical Program Committee, ITCom, 2004</li>
<li>Member, Technical Program Committee, International Conference on Image Processing, Singapore, 2004</li>
<li>Member, IEEE Circuits and Systems Society Visual Signal Processing and Communication Technical Committee, 2002 present</li>
<li>Technical Program Committee Member, International Conference on Information Technology: Research and Education, 2003</li>
<li>Member, Technical Review Committee, IEEE International Symposium on Circuits and Systems (ISCAS) 2003, 2004, 2005, 2006</li>
<li>Member, Technical Program Committee, IEEE Asia-Pacific Conference on Circuits and Systems, Bali, Indonesia, 2002</li>
<li>Session organizer and chair, SPIE EI 2006, PCS 2006, Beijing</li>
</ul>
<h3 id="projects"><strong>Projects</strong></h3>
<ul>
<li>NSFC Special Fund (Tianyuan Fund for Mathematics): Research on Theories and Novel High-Resolution Imaging Methods for Non-Invasive Hemodynamics. Role: Co-Principal Investigator (Co-PI) | Period: 2025.01 – 2026.12</li>
<li>NSFC Key Program: Theories and Methods for Screen Hybrid Content Coding Based on Multi-Agent Collaborative Learning. Role: Principal Investigator (PI) | Period: 2024.01 – 2028.12</li>
<li>SenSE: Wearable hybrid biochemical and biophysical sensing systems integrated with robust artificial intelligence for monitoring COVID-19 patients, National Science Foundation, 09/1/2020 – 08/31/2023, PI, $737,000.00; Shared Credit: 35%</li>
<li>CPS: Synergy: Cyber-Physical Sensing, Modeling, and Control with Augmented Reality for Smart Manufacturing Workforce Training and Operations Management. National Science Foundation, 02/1/2017 – 01/31/2020, PI, $340,000.00; Shared Credit: 100%</li>
<li>NSF-USIgnite: Focus Area 1: A GENI-Enabled Virtual Reality System for ImmersiveOnline Social Learning of Youth with Autism Spectrum Disorders. National Science Foundation, 02/1/2017 – 01/31/2020, PI, $690,000.00; Shared Credit: 40%</li>
<li>NSF-REU Site: Research in Consumer Application Networking Technologies. National Science Foundation, 01/1/2017 – 12/31/2019, Co-PI, $300,000.00; Shared Credit: 20%</li>
<li>CyberSEES: Collaborative Research: Cyber-infrastructure and Technologies to Support Large-Scale Wildlife Monitoring and Research for Wildlife and Ecology Sustainability, National Science Foundation, 11/2015 – 10/2018, PI, $689,000.00; Shared Credit: 45%</li>
<li>CPS: Synergy: Collaborative Research: Cyber-Physical Sensing, Modeling, and Control for Large-Scale Wastewater Reuse and Algal Biomass Production. National Science Foundation, 09/2015 to 08/2018, PI, $670,000.00; Shared Credit: 40%</li>
<li>Coulter Biomedical Research Award: Down the Hatch Solution – Automated Vision Analysis and Cloud-Based Content Management for Precision Diagnosis of Dysphagia Diseases. Coulter Foundation for biomedical innovation and commercialization, 10/2016 to 09/2017, Engineering PI, $110,000.00; Shared Credit: 30%</li>
<li>Object recognition and segmentation. TCL Research America, 11/01/2013 – Oct/31/2018; PI, $300K; Shared Credit: 100%.</li>
<li>Collaborative Research: ABI Innovation: Computational and Informatics Tools for Supporting Collaborative Wildlife Monitoring and Research. National Science Foundation, 08/2011 – 07/2014; PI, $898 K (Project total: $1.45M); Shared Credit: 40%</li>
<li>Collaborative Research: Processes Determining Abundance of Terrestrial Wildlife Communities Across Large Scales. National Science Foundation, 06/01/2011 – 05/31/2014, PI, $374 K; Shared Credit: 50%</li>
<li>Suspicious Activity Analysis for Force Protection. Fort Leonard Wood Institute / Amy Research Lab, 10/2009 – 09/2010. PI, $489K; Shared Credit: 35%</li>
<li>CPS: Medium: Active Heterogeneous Sensing for Fall Detection and Fall Risk Assessment. National Science Foundation, 09/01/2009 – 08/31/2012. Co-PI, $1.4M; Shared Credit: 20%</li>
<li>NURI: Hierarchical Contextual Image Analysis for Global Awareness. National Geospatial Intelligence Agency, 07/01/2010 – 06/30/2012, Co-PI, $290,000; Shard Credit: 45%</li>
<li>LWI: Human Detection in Convoy Vehicle for Battlefield Safety. Fort Leonard Wood Institute / Amy Research Lab, 09/01/2010 – 08/31/2011. Co-PI, $485,000; Shared Credit: 45%</li>
<li>Cooperative Information Fusion for IED Related Suspicious Activity Detection.Fort Leonard Wood Institute / Amy Research Lab, 09/2008 – 08/2009. Co-PI, $474K, Shared Credit: 30%</li>
<li>NIH R21 Automated Activity Analysis for Eldercare. National Institute of Health, 07/2007 – 06/2009. PI, $285K, Shared Credit: 50</li>
<li>HCC: Elder-Centered Recognition Technology for the Assessment of Physical Function. National Science Foundation, 09/2007 – 08/2010. Co-PI, $900K, Shared Credit: 20%</li>
<li>DeerNet – Wireless sensor networks for wildlife behavior monitoring, interaction modeling, and disease tracking. National Science Foundation, 09/2005 – 08/2008. PI, $480K. Shared Credit: 60%</li>
<li>JPEG2000 Temporal Extension. Bos Allen Hamilton, 11/2007 – 10/2009. Co-PI, $93K, Shared Credit: 80%</li>
<li>ITR: Technological intervention for elderly with cognitive and mobility impairments. National Science Foundation, 11/2004 – 10/2008. Co-PI, $1.2M, Shared Credit: 10%</li>
<li>Technology to enhance aging in place at TigerPlace. Federal Administration on Aging, 09/05 08/07. Co-PI, $979,104. Shared Credit: 2%</li>
<li>Automated geospatial image processing. National Geospatial Intelligence Agency, 07/06 06/08. Co-PI, $1.75M. Shared Credit: 8%</li>
<li>Intelligent Video Processing for Persistent Aerial Surveillance. National Geospatial Intelligence Agency, 02/08 01/10. Co-PI, $1.65M. Shared Credit: 10%</li>
<li>Prime Fund for DeerNet – Wireless sensor networks for wildlife behavior monitoring, interaction modeling, and disease tracking. University of Missouri PRIME Matching Fund, 09/2005 – 08/2008. PI, $42K, Shared Credit: 100%</li>
<li>Lifetime maximization for wireless video sensor network. University of Missouri Research Board, 02/2004 – 08/2005. PI, $27,800. Shared Credit: 100%</li>
</ul>
<h3 id="representative-papers"><strong>Representative Papers</strong></h3>
<ul>
<li>Yi Zhang, Chun-Wun Cheng, Junyi He, Zhihai He, Carola-Bibiane Schönlieb, Yuyan Chen, Angelica I Aviles-Rivero. &ldquo;Cross-Modal Few-Shot Learning with Second-Order Neural Ordinary Differential Equations.&quot;[J] AAAI Conference on Artificial Intelligence (AAAI2025). (Oral paper).</li>
<li>Siqi Wu, Yinda Chen, Dong Liu, Zhihai He. &quot; Conditional Latent Coding with Learnable Synthesized Reference for Deep Image Compression.&quot;[J] AAAI Conference on Artificial Intelligence (AAAI2025). (Oral paper).</li>
<li>Yi Zhang, Ke Yu, Siqi Wu, Zhihai He. &ldquo;Conceptual Codebook Learning for Vision-Language Models&rdquo;[J]. European Conference on Computer Vision (ECCV 2024).</li>
<li>Tushun Tang, Shuoshuo Chen, Zhihe Lu, Xinchao Wang, Zhihai He. &ldquo;Dual-Path Adversarial Lifting for Domain Shift Correction in Online Test-time Adaptation&rdquo;[J]. European Conference on Computer Vision (ECCV 2024).</li>
<li>Yi Zhang, Ke Yu, Angelica I Aviles-Rivero, Jiyuan Jia, Yushun Tang, Zhihai He. &ldquo;Training-Free Feature Reconstruction with Sparse Optimization for Vision-Language Models&rdquo;[J]. Proceedings of the 32nd ACM International Conference on Multimedia, 2024. 4387-4396</li>
<li>Yushun Tang, Shuoshuo Chen, Jiyuan Jia, Yi Zhang, Zhihai He. &ldquo;Domain-Conditioned Transformer for Fully Test-time Adaptation.&quot;[J] Proceedings of the 32nd ACM International Conference on Multimedia, 2024. 6260-6269.</li>
<li>Zhehan Kan, Shuoshuo Chen, Ce Zhang, Yushun Tang, Zhihai He, &ldquo;Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation.&rdquo; 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5537-5546, 17-24 June 2023.</li>
<li>Yushun Tang, Ce Zhang, Heng Xu, Shuoshuo Chen, Jie Cheng, Luziwei Leng, Qinghai Guo, Zhihai He, &ldquo;Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation.&rdquo;  In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3728-3738. 2023.17-24 June 2023.</li>
<li>Zhehan Kan, Shuoshuo Chen, Zeng Li, Zhihai He, &ldquo;Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation.&rdquo; Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part V. Cham: Springer Nature Switzerland, 2022.</li>
<li>Shichao Kan, Yigang Cen, and Zhihai He, Relative Order Analysis and Optimization for Unsupervised Learning of Discriminative Features, IEEE Proceedings of Computer Vision and Pattern Recognition (CVPR), June 2021.</li>
<li>Hao Sun and Zhihai He, “Reciprocal learning networks for human trajectory prediction,” IEEE Proceedings of Computer Vision and Pattern Recognition (CVPR), June 2020 (Oral paper).</li>
<li>Yang Li, Zhiqun Zhao, Yigang Cen, and Zhihai He, Snowball: Iterative Model Evolution and Confident Sample Discovery for Semi-Supervised Learning on Very Small Labeled Datasets, accepted by IEEE Transactions on Multimedia, May 2020.</li>
<li>Jianhe Yuan and Zhihai He, “Ensemble generative cleaning for adversarial defense of deep neural networks,” IEEE Proceedings of Computer Vision and Pattern Recognition (CVPR), June 2020.</li>
<li>Kan, Shichao, Yigang Cen, Zhihai He, Zhi Zhang, Linna Zhang, and Yanhong Wang. &ldquo;Supervised deep feature embedding with handcrafted feature.&rdquo; IEEE Transactions on Image Processing 28, no. 12 (2019): 5809-5823.</li>
<li>Zhi Zhang, Zhihai He, and Wenmin Cao, Animal Detection from Highly Cluttered Natural Scenes Using Spatiotemporal Object Region Proposals and Patch Verification, IEEE Transaction on Multimedia, Vol. 18, No. 10, pp. 2079-2092, July 2016.</li>
<li>Chenglin Li, Hongkai Xiong, Junni Zou, Zhihai He, &ldquo;Joint Source and Flow Optimization for Scalable Video Multi-rate Multicast over Hybrid Wired/Wireless Coded Networks&rdquo;, IEEE Transactions on Circuits and Systems for Video Technology, Vol. 21, No. 5, pp. 550-564, May 2011.</li>
<li>Zhou, Zhongna, Xi Chen, Yu-Chia Chung, Zhihai He, Tony X. Han, and James M. Keller. &ldquo;Activity analysis, summarization, and visualization for indoor human activity monitoring.&rdquo; IEEE transactions on circuits and systems for video technology 18, no. 11 (2008): 1489-1498.</li>
<li>He, Zhihai, and Sanjit K. Mitra. &ldquo;A linear source model and a unified rate control algorithm for DCT video coding.&rdquo; IEEE transactions on Circuits and Systems for Video Technology 12, no. 11 (2002): 970-982.</li>
<li>He, Zhihai, Jianfei Cai, and Chang Wen Chen. &ldquo;Joint source channel rate-distortion analysis for adaptive mode selection and rate control in wireless video coding.&rdquo; IEEE Transactions on circuits and systems for video technology 12, no. 6 (2002): 511-523.</li>
<li>He, Zhihai, and Sanjit K. Mitra. &ldquo;A unified rate-distortion analysis framework for transform coding.&rdquo; IEEE Transactions on Circuits and Systems for Video Technology 11, no. 12 (2001): 1221-1236. (Best Paper)</li>
</ul>

    </div>

    <div class="row">

      

      
      <div class="col-md-7">
        <div class="section-subheading">Education</div>
        <ul class="ul-edu fa-ul mb-0">
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">Ph.D. in Electrical and Computer Engineering, 1998-2001</p>
              <p class="institution">University of California, Santa Barbara</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">M.S. in Mathematics, 1994-1997</p>
              <p class="institution">Institute of Computational Mathematics, Chinese Academy of Sciences</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">B.S. in Mathematics, 1990-1994</p>
              <p class="institution">Beijing Normal University</p>
            </div>
          </li>
          
        </ul>
      </div>
      

    </div>
  </div>
</div>

    

    
    
    
  </div>
</section>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    © 2025 Me. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>





  <p class="powered-by">
    
    
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.da259f97ed0f170b3547d57d1c732d58.js"></script>




  

  
  

  






  <script src="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js" integrity="" crossorigin="anonymous"></script>



































<script id="page-data" type="application/json">{"use_headroom":true}</script>


  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>










<script src="/en/js/wowchemy.min.e166a4f802c5f09237cc72919197d83b.js"></script>



  <script src="/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js" type="module"></script>




  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.9c0e895144aef5a693008b5c5d450147.js" type="module"></script>


















</body>
</html>
