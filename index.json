
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Zhihai He , chair professor of Department of Electronics of Southern University of Science and Technology, chair scholar of Changjiang Scholar (2023), the Pearl River Talents of Guangdong Province (2022), Shenzhen Overseas High level Talents (2021), IEEE Fellow (2015). Before returning to China full-time in 2021, he worked for 18 years in the Department of Electronic Engineering at the University of Missouri in the United States (2003-2021). Before leaving, he was a tenured full professor in the department and a chair professor at Robert Lee Tatum. In 2001, he obtained a doctoral degree in Electronic Engineering from the University of California, Santa Barbara. Since 2003, long-term and in-depth cutting-edge research has been conducted on artificial intelligence, the Internet of Things, and Smart Cyber Physical Systems. I have been engaged in research on multimedia communication, machine vision, the Internet of Things, and artificial intelligence for a long time. The research results have been successfully applied in fields such as intelligent manufacturing, intelligent elderly care, intelligent transportation, ecological environment, remote special education and training. We have undertaken over ten key research projects from the National Science Foundation (NSF), Department of Defense (DOD), and National Institutes of Health (NIH), with a total funding of over 25 million US dollars. Published over 180 high-quality papers and won important awards such as IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) Best Paper and SPIE Young Scientist in 2002. Selected for the World’s Top 2% Scientists Lifetime Science Impact Rankings and Annual Science Impact Rankings at Stanford University from 2019 to 2022.\nResearch Interests Machine Learning Computer Vision Artificial Intelligence of Things Intelligent Information Physical System Multimedia Network Communication Intelligent Manufacturing Industrial AI Inspection Smart Health and Smart Ecology Work Experience (2021 - Present) Chair Professor, Southern University of Science and Technology, Shenzhen (2013 - 2021) Professor, University of Missouri, Columbia (2009 - 2013) Associate Professor, University of Missouri, Columbia (2003 - 2009) Assistant Professor, University of Missouri, Columbia (Summer, 2005) Summer Faculty Fellow, Air Force Research Lab, Wright-Pattern Air Force Base, Dayton OH (2001 - 2003) Research Engineer, David Sarnoff Research Center (Sarnoff Co.),\tPrinceton NJ. Personal Honors (2022) Guangdong Pearl River Talents Program Introduces High-Level Talents (2021) Certified for Overseas High-Caliber Personnel in Shenzhen (2019) Robert Lee Tantum Distinguished Professor (2017) Missouri Honors Engineering Senior Faculty Research Award (2015) IEEE Fellow (2010) IEEE Transactions on Circuits and Systems for Video Technology Outstanding Associate Editor Award (2009) Provost’s Outstanding Junior Faculty Research and Creative Activity Award (2008) Missouri Honors Engineering Junior Faculty Research Award (2006) Second Place in competition for IEEE Transactions on Circuits and Systems for Video Technology Best Paper Award (2004) 2004 SPIE VCIP Young Investigator Award (2002) IEEE Transactions on Circuits and Systems for Video Technology Best Paper Award for Year 2002 Personal Activities Associate Editor, IEEE Transactions on Multimedia, 2009 – 2013 Associate Editor, Journal of Visual Communication and Image Representation, June 2009 – Present. Associate Editor, IEEE Transactions on Circuit and System for Video Technologies, 2009 -2011. Guest Editor, IEEE Transactions on Circuit and System for Video Technologies, special issue on advanced technologies for video surveillance, 2010 Session chair, International Conference on Image Processing, Orlando, FL, 2012. Conference tutorial, Visual Communication and Image Processing Conference, San Diego, 2012 Special Session Chair, Visual Communications and Image Processing, 2013 International Liaison Chair, Visual Communications and Image Processing, 2010 NSF Review Panel, CISE Creative IT, 2009 Technical Program Review Committee, IEEE International Symposium on Circuits and Systems 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016 Co-Chair, International Symposium on Multimedia over Wireless, Hawaii, 2007 TPC member, Multimedia Systems and Applications, SPIE Electronic Imaging, 2007 Session Chair, SPIE Visual Communication and Image Processing, 2007 TPC member, IEEE Globecom 2007 Signal Processing Symposium Vice Chair, International Symposium on Multimedia over Wireless, WirelessCom 2005, Maui, Hawaii, USA, June 13-16, 2005 Member, Award Committee, IEEE Communication Society Member, Technical Program Committee, 2nd International Mobile Multimedia Communications Conference Member, Technical Program Committee, International Conference on Communication (ICC), 2005 Member, Technical Program Committee, ITCom, 2004 Member, Technical Program Committee, International Conference on Image Processing, Singapore, 2004 …","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e636e7db9f55c48b97b93fffc09401a8","permalink":"https://nkdailab.github.io/author/%E4%BD%95%E5%BF%97%E6%B5%B7/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E4%BD%95%E5%BF%97%E6%B5%B7/","section":"authors","summary":"Zhihai He , chair professor of Department of Electronics of Southern University of Science and Technology, chair scholar of Changjiang Scholar (2023), the Pearl River Talents of Guangdong Province (2022), Shenzhen Overseas High level Talents (2021), IEEE Fellow (2015). Before returning to China full-time in 2021, he worked for 18 years in the Department of Electronic Engineering at the University of Missouri in the United States (2003-2021). Before leaving, he was a tenured full professor in the department and a chair professor at Robert Lee Tatum. In 2001, he obtained a doctoral degree in Electronic Engineering from the University of California, Santa Barbara. Since 2003, long-term and in-depth cutting-edge research has been conducted on artificial intelligence, the Internet of Things, and Smart Cyber Physical Systems. I have been engaged in research on multimedia communication, machine vision, the Internet of Things, and artificial intelligence for a long time. The research results have been successfully applied in fields such as intelligent manufacturing, intelligent elderly care, intelligent transportation, ecological environment, remote special education and training. We have undertaken over ten key research projects from the National Science Foundation (NSF), Department of Defense (DOD), and National Institutes of Health (NIH), with a total funding of over 25 million US dollars. Published over 180 high-quality papers and won important awards such as IEEE Transactions on Circuits and Systems for Video Technology (TCSVT) Best Paper and SPIE Young Scientist in 2002. Selected for the World’s Top 2% Scientists Lifetime Science Impact Rankings and Annual Science Impact Rankings at Stanford University from 2019 to 2022.\n","tags":null,"title":"何志海","type":"authors"},{"authors":null,"categories":null,"content":"He Junyi, undergraduate student in Information Engineering at Southern University of Science and Technology. Currently engaged in studies and research related to machine learning, focusing on developing skills and knowledge in this evolving field.\nResearch Interests Machine Learning Pre-trained Vision-Language Model Personal Honors 2022 Second Prize of Excellent Student Scholarship, SUSTech ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"655595ffef031edfcb28c52a4210876c","permalink":"https://nkdailab.github.io/author/%E4%BD%95%E6%B5%9A%E4%BA%A6/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E4%BD%95%E6%B5%9A%E4%BA%A6/","section":"authors","summary":"He Junyi, undergraduate student in Information Engineering at Southern University of Science and Technology. Currently engaged in studies and research related to machine learning, focusing on developing skills and knowledge in this evolving field.\n","tags":null,"title":"何浚亦","type":"authors"},{"authors":null,"categories":null,"content":"Ke Yu, undergraduate student in Department of Electronics of Southern University of Science and Technology.\nResearch Interests Few-Shot Learning of Vision-Language Model Projects An Intelligent Health System Based on Human Pose Estimation, in Climbing Project of Guangdong Province, 2023. Paper Xueting Hu, Ce Zhang, Yi Zhang, Bowen Hai, Ke Yu, and Zhihai He. Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation. In IEEE/CVF Winter Conference on Applications of Computer Vision (WACV ), 2024. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3db98ea2913ac5b6ed15efb705aecc1d","permalink":"https://nkdailab.github.io/author/%E4%BD%99%E5%8F%AF/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E4%BD%99%E5%8F%AF/","section":"authors","summary":"Ke Yu, undergraduate student in Department of Electronics of Southern University of Science and Technology.\nResearch Interests Few-Shot Learning of Vision-Language Model Projects An Intelligent Health System Based on Human Pose Estimation, in Climbing Project of Guangdong Province, 2023. Paper Xueting Hu, Ce Zhang, Yi Zhang, Bowen Hai, Ke Yu, and Zhihai He. Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation. In IEEE/CVF Winter Conference on Applications of Computer Vision (WACV ), 2024. ","tags":null,"title":"余可","type":"authors"},{"authors":null,"categories":null,"content":"Research Interests Machine Learning Computer Vision Few-shot Learning Large Model Paper Liu Q, Zhao Z, Cao W, et al. Residual proportion multilayer perceptron for few-shot classification[C]//2021 IEEE International Conference on Multimedia \u0026amp; Expo Workshops (ICMEW). IEEE, 2021: 1-6. Liu Q, Cao W. Geometric algebra graph neural network for cross-domain few-shot classification[J]. Applied Intelligence, 2022, 52(11): 12422-12435. Zhao Z, Liu Q, Cao W, et al. Self-guided information for few-shot classification[J]. Pattern Recognition, 2022, 131: 108880. Liu Q, Chen Y, Cao W. Dual-domain reciprocal learning design for few-shot image classification[J]. Neural Computing and Applications, 2023: 1-14. Liu Q, Cao W, He Z. Cycle Optimization Metric Learning for Few-Shot Classification[J]. Pattern Recognition, 2023: 109468. Zhang R, Liu Q. Learning with few samples in deep learning for image classification, a mini-review[J]. Frontiers in Computational Neuroscience, 2023. Patent *Vehicle detection method, device and computer-readable storage medium, He Zhiquan, Liu Qifan, Cao Wenming, patent number: ZL 2019 1 0029834.8 *Progressive deep convolutional network image recognition method and device based on wavelet transform, He Zhiquan, Cao Wenming, Liu Qifan, patent number: ZL 2019 1 0783600.2 *Compression transmission method, system and computer-readable storage medium for image data, He Zhiquan, Cao Wenming, Liu Qifan, patent number: ZL 2019 1 0811971.7 *An OCR recognition method and device based on deep neural network, Cao Wenming, Liu Qifan, He Zhiquan, patent number: ZL 2019 1 0904514.2\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6188ff147fb318423f3e4157cf21a324","permalink":"https://nkdailab.github.io/author/%E5%88%98%E5%90%AF%E5%87%A1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%88%98%E5%90%AF%E5%87%A1/","section":"authors","summary":"Research Interests Machine Learning Computer Vision Few-shot Learning Large Model Paper Liu Q, Zhao Z, Cao W, et al. Residual proportion multilayer perceptron for few-shot classification[C]//2021 IEEE International Conference on Multimedia \u0026 Expo Workshops (ICMEW). IEEE, 2021: 1-6. Liu Q, Cao W. Geometric algebra graph neural network for cross-domain few-shot classification[J]. Applied Intelligence, 2022, 52(11): 12422-12435. Zhao Z, Liu Q, Cao W, et al. Self-guided information for few-shot classification[J]. Pattern Recognition, 2022, 131: 108880. Liu Q, Chen Y, Cao W. Dual-domain reciprocal learning design for few-shot image classification[J]. Neural Computing and Applications, 2023: 1-14. Liu Q, Cao W, He Z. Cycle Optimization Metric Learning for Few-Shot Classification[J]. Pattern Recognition, 2023: 109468. Zhang R, Liu Q. Learning with few samples in deep learning for image classification, a mini-review[J]. Frontiers in Computational Neuroscience, 2023. Patent *Vehicle detection method, device and computer-readable storage medium, He Zhiquan, Liu Qifan, Cao Wenming, patent number: ZL 2019 1 0029834.8 *Progressive deep convolutional network image recognition method and device based on wavelet transform, He Zhiquan, Cao Wenming, Liu Qifan, patent number: ZL 2019 1 0783600.2 *Compression transmission method, system and computer-readable storage medium for image data, He Zhiquan, Cao Wenming, Liu Qifan, patent number: ZL 2019 1 0811971.7 *An OCR recognition method and device based on deep neural network, Cao Wenming, Liu Qifan, He Zhiquan, patent number: ZL 2019 1 0904514.2\n","tags":null,"title":"刘启凡","type":"authors"},{"authors":null,"categories":null,"content":"Xiyuan Liu, a sophomore of Department of Electronics of Southern University of Science and Technology, a member of NKD-AI Lab and a member of Shenzhen middle school dance company(2016-2019), is interested in many fields, like Chinese classic dance, Chinese folk dance, show jumping, dressage, public speaking, debating, jogging, skipping, swimming, badminton, frisbee and tennis.\nResearch Interests Virtual Technology Computer Vision Work Experience (2023) Intern at Private Banking Department of China Merchants Bank Personal Honors (2023) 桃李杯艺术展演独舞《鸣》表演金奖 (2023) 桃李杯艺术展演独舞《良宵》表演金奖 (2023) “舞蹈大赛”全国网络舞蹈大赛《良宵》获特金奖 (2023) “舞蹈大赛”全国网络舞蹈大赛《鸣》获特金奖 (2023) 南方科技大学优秀团员 (2023) 第9届中国国际“互联网+”创新创业大赛南方科技大学校内赛高教主赛道优胜奖 (2023) 广东省马术公开赛盛装舞步初一级团体第一 (2023) 南方科技大学“生医工杯”英语演讲大赛第二名 (2023) 第一届“思辨展风采，青春筑未来”书院辩论赛亚军 (2023) “外研社·国才杯”英语演讲大赛南科大初赛二等奖 Personal Activities Southern University of Science and Technology 2023 Sichuan Province Recruitment Lecture Speaker, 2023 Projects A human-machine intention expression and knowledge learning system based on large models ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c287bed3b7b8e956a9b90f9a18f0868a","permalink":"https://nkdailab.github.io/author/%E5%88%98%E5%A4%95%E5%AA%9B/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%88%98%E5%A4%95%E5%AA%9B/","section":"authors","summary":"Xiyuan Liu, a sophomore of Department of Electronics of Southern University of Science and Technology, a member of NKD-AI Lab and a member of Shenzhen middle school dance company(2016-2019), is interested in many fields, like Chinese classic dance, Chinese folk dance, show jumping, dressage, public speaking, debating, jogging, skipping, swimming, badminton, frisbee and tennis.\n","tags":null,"title":"刘夕媛","type":"authors"},{"authors":null,"categories":null,"content":"Siyi Liu , Master of Department of Electronics of Southern University of Science and Technology, Undergraduate Graduate of the Department of Communication Engineering,of Shenzhen University , with a research focus on Machine Learning, Computer Vision, Multi-modality, Text-to-Image Synthesis and Image Compression.\nResearch Interests Machine Learning Computer Vision Multi-modality Text-to-Image Synthesis Image Compression Personal Honors (2023) Outstanding Graduate of Shenzhen University (2023) Honors Bachelor’s Degree of Shenzhen University ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"fae9828e328a0015025dd442fb5ca600","permalink":"https://nkdailab.github.io/author/%E5%88%98%E6%80%9D%E6%80%A1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%88%98%E6%80%9D%E6%80%A1/","section":"authors","summary":"Siyi Liu , Master of Department of Electronics of Southern University of Science and Technology, Undergraduate Graduate of the Department of Communication Engineering,of Shenzhen University , with a research focus on Machine Learning, Computer Vision, Multi-modality, Text-to-Image Synthesis and Image Compression.\n","tags":null,"title":"刘思怡","type":"authors"},{"authors":null,"categories":null,"content":"Ziqiong Liu, master student of Department of Electronics of Southern University of Science and Technology, specializes in Electronic Science and Technology.\nResearch Interests Machine Learning Computer Vision ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"956fd1e019236bc593c096208a115068","permalink":"https://nkdailab.github.io/author/%E5%88%98%E7%B4%AB%E7%90%BC/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%88%98%E7%B4%AB%E7%90%BC/","section":"authors","summary":"Ziqiong Liu, master student of Department of Electronics of Southern University of Science and Technology, specializes in Electronic Science and Technology.\nResearch Interests Machine Learning Computer Vision ","tags":null,"title":"刘紫琼","type":"authors"},{"authors":null,"categories":null,"content":"Bingyan Wu, master student of Department of Electronics of Southern University of Science and Technology.\nResearch Interests Computer Vision Machine Learning ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"731b603320c290b3f8eb61357bdd3d05","permalink":"https://nkdailab.github.io/author/%E5%90%B4%E5%86%B0%E5%B2%A9/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B4%E5%86%B0%E5%B2%A9/","section":"authors","summary":"Bingyan Wu, master student of Department of Electronics of Southern University of Science and Technology.\nResearch Interests Computer Vision Machine Learning ","tags":null,"title":"吴冰岩","type":"authors"},{"authors":null,"categories":null,"content":"Siqi Wu, graduate student in Department of Electrical and Computer Engineering of University of Missouri.\nResearch Interests Image Compression Paper Hadeel Alqadi, Majid Bani Yaghoub, Siqi Wu, Sindhu Balakumar, and Alex Francisco. Prospective Spatial–Temporal Clusters of COVID-19 in Local Communities: Case Study of Kansas City, Missouri, United States. Epidemiology and Infection. 2022. 1-24. Hadeel Alqadi, Majid Bani Yaghoub, Sindhu Balakumar, Siqi Wu, and Alex Francisco. Assessment of Retrospective COVID-19 Spatial Clusters with Respect to Demographic Factors: Case Study of Kansas City, Missouri, United States. Int. J. Environ. Res. Public Health. 2021. 18(21), 11496. Siqi Wu, Chang Chen, Zhiwei Xiong, Xuejin Chen, Xiaoyan Sun. Uncertainty-Aware Label Rectification for Domain Adaptive Mitochondria Segmentation. MICCAI. 2021. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"950a1eb53b0b844604430d349980b76d","permalink":"https://nkdailab.github.io/author/%E5%90%B4%E6%80%9D%E5%A5%87/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B4%E6%80%9D%E5%A5%87/","section":"authors","summary":"Siqi Wu, graduate student in Department of Electrical and Computer Engineering of University of Missouri.\nResearch Interests Image Compression Paper Hadeel Alqadi, Majid Bani Yaghoub, Siqi Wu, Sindhu Balakumar, and Alex Francisco. Prospective Spatial–Temporal Clusters of COVID-19 in Local Communities: Case Study of Kansas City, Missouri, United States. Epidemiology and Infection. 2022. 1-24. Hadeel Alqadi, Majid Bani Yaghoub, Sindhu Balakumar, Siqi Wu, and Alex Francisco. Assessment of Retrospective COVID-19 Spatial Clusters with Respect to Demographic Factors: Case Study of Kansas City, Missouri, United States. Int. J. Environ. Res. Public Health. 2021. 18(21), 11496. Siqi Wu, Chang Chen, Zhiwei Xiong, Xuejin Chen, Xiaoyan Sun. Uncertainty-Aware Label Rectification for Domain Adaptive Mitochondria Segmentation. MICCAI. 2021. ","tags":null,"title":"吴思奇","type":"authors"},{"authors":null,"categories":null,"content":"Research Interests Machine Learning Computer Vision Transfer Learning Domain Adaptation Work Experience (2020 - Present) Research Intern, Huawei, Shenzhen Personal Activities Reviewer, ECCV 2022 Paper Tang Y, Zhang C, Xu H, et al. Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3728-3738. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6592848b6574fb09ed32ece62aa80b97","permalink":"https://nkdailab.github.io/author/%E5%94%90%E9%9B%A8%E9%A1%BA/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%94%90%E9%9B%A8%E9%A1%BA/","section":"authors","summary":"Research Interests Machine Learning Computer Vision Transfer Learning Domain Adaptation Work Experience (2020 - Present) Research Intern, Huawei, Shenzhen Personal Activities Reviewer, ECCV 2022 Paper Tang Y, Zhang C, Xu H, et al. Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3728-3738. ","tags":null,"title":"唐雨顺","type":"authors"},{"authors":null,"categories":null,"content":"Yangxing Shang, is dedicated to becoming a artists in Robotics.\nResearch Interests Legged robot combined with perceptual motion control Personal Activities Founded a robotics company and received investment from MiraclePlus ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"39c1d79a9d3f90d94b33ea1a980a993f","permalink":"https://nkdailab.github.io/author/%E5%B0%9A%E9%98%B3%E6%98%9F/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%B0%9A%E9%98%B3%E6%98%9F/","section":"authors","summary":"Yangxing Shang, is dedicated to becoming a artists in Robotics.\nResearch Interests Legged robot combined with perceptual motion control Personal Activities Founded a robotics company and received investment from MiraclePlus ","tags":null,"title":"尚阳星","type":"authors"},{"authors":null,"categories":null,"content":"Bowen Liao, master student of Department of Electronics of Southern University of Science and Technology, specializes in Computer Vision and Machine Learning.\nResearch Interests Computer Vision Machine Learning ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"fc1adf4ec003db22daa0515ee8ac571d","permalink":"https://nkdailab.github.io/author/%E5%BB%96%E5%8D%9A%E9%97%BB/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%BB%96%E5%8D%9A%E9%97%BB/","section":"authors","summary":"Bowen Liao, master student of Department of Electronics of Southern University of Science and Technology, specializes in Computer Vision and Machine Learning.\nResearch Interests Computer Vision Machine Learning ","tags":null,"title":"廖博闻","type":"authors"},{"authors":null,"categories":null,"content":"Research Interests Machine Learning Computer Vision Vision-Language Few-shot Learning Visual Reasoning Work Experience (2021 - Present) Research Assistant, AI Lab, Sustech, Shenzhen (2020 - 2021) Lecture, Neusoft Institute Guangdong, Foshan (2018 - 2020) Software Engineer, SAP, Shanghai (2016 - 2018) Software Engineer, The University of Southern Mississippi Paper Yi Zhang, Ce Zhang, Ke Yu, Yushun Tang, Zhihai He. Concept-Guided Prompt Learning for Generalization in Vision-Language Models. AAAI2024. Yi Zhang, Ce Zhang, Zihan Liao, Yushun Tang, Zhihai He. BDC-Adapter: Brownian Distance Covariance for Better Vision-Language Reasoning. British Machine Vision Conference 2023 (BMVC2023). Xueting Hu, Ce Zhang, Yi Zhang, Ke Yu, Zhihai He. Learn to Adapt CLIP for Few-Shot Monocular Depth Estimation. Submitted to Winter Conference on Computer Vision (WACV), 2024. (Project Lead) Yi Zhang, Ce Zhang, Xueting Hu, Zhihai He. Unsupervised Prototype Adapter for Vision-Language Models. The 6th Chinese Conference on Pattern Recognition and Computer Vision (PRCV2023). Yi Zhang, Ce Zhang, Yushun Tang, Zhihai He. Cross-Model concept learning and reference for Vision-Language\tModels. Neurocomputing. (Under review) Yi Zhang, Ce Zhang, Zhihai He. Distribution Learning Adapter for Vision-Language Models. (Preprint) Yushun Tang, Shuoshuo Chen, Zhehan Kan, Yi Zhang, Qinghai Guo, Zhihai He. Learning Visual Conditioning Tokens to Clean Up Domain Shift for Fully Test-Time Adaptation. IEEE Transactions on Circuits and Systems for Video Technology(TCSVT) (Under review) ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"27523689934ba3c3f28cc28b6e9ef44c","permalink":"https://nkdailab.github.io/author/%E5%BC%A0%E6%AF%85/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%BC%A0%E6%AF%85/","section":"authors","summary":"Research Interests Machine Learning Computer Vision Vision-Language Few-shot Learning Visual Reasoning Work Experience (2021 - Present) Research Assistant, AI Lab, Sustech, Shenzhen (2020 - 2021) Lecture, Neusoft Institute Guangdong, Foshan (2018 - 2020) Software Engineer, SAP, Shanghai (2016 - 2018) Software Engineer, The University of Southern Mississippi Paper Yi Zhang, Ce Zhang, Ke Yu, Yushun Tang, Zhihai He. Concept-Guided Prompt Learning for Generalization in Vision-Language Models. AAAI2024. Yi Zhang, Ce Zhang, Zihan Liao, Yushun Tang, Zhihai He. BDC-Adapter: Brownian Distance Covariance for Better Vision-Language Reasoning. British Machine Vision Conference 2023 (BMVC2023). Xueting Hu, Ce Zhang, Yi Zhang, Ke Yu, Zhihai He. Learn to Adapt CLIP for Few-Shot Monocular Depth Estimation. Submitted to Winter Conference on Computer Vision (WACV), 2024. (Project Lead) Yi Zhang, Ce Zhang, Xueting Hu, Zhihai He. Unsupervised Prototype Adapter for Vision-Language Models. The 6th Chinese Conference on Pattern Recognition and Computer Vision (PRCV2023). Yi Zhang, Ce Zhang, Yushun Tang, Zhihai He. Cross-Model concept learning and reference for Vision-Language\tModels. Neurocomputing. (Under review) Yi Zhang, Ce Zhang, Zhihai He. Distribution Learning Adapter for Vision-Language Models. (Preprint) Yushun Tang, Shuoshuo Chen, Zhehan Kan, Yi Zhang, Qinghai Guo, Zhihai He. Learning Visual Conditioning Tokens to Clean Up Domain Shift for Fully Test-Time Adaptation. IEEE Transactions on Circuits and Systems for Video Technology(TCSVT) (Under review) ","tags":null,"title":"张毅","type":"authors"},{"authors":null,"categories":null,"content":"I’m Ce Zhang and I’m currently pursuing my Master’s degree in Machine Learning at CMU and looking forward to graduating in December 2024. Before this, I earned my B.Eng. in Communication Engineering from Southern University of Science and Technology (SUSTech). My current research interest lie in vision-language models and scene understanding.\nVisit the personal homepage for more information: https://zhangce01.github.io/\nResearch Interests Computer Vision Machine Learning Personal Honors Top 10 Summa Cum Laude Graduates, Southern University of Science and Technology, June 2023 National Scholarship, Ministry of Education of the People’s Republic of China, Novermber 2022 Paper HiKER-SGG: Hierarchical Knowledge Enhanced Robust Scene Graph Generation Ce Zhang, Simon Stepputtis, Joseph Campbell, Katia Sycara, Yaqi Xie NeurIPS 2023 New Frontiers in Graph Learning Workshop. Submitted to CVPR 2024 Critical Sampling for Robust Evolution Operator Learning of Unknown Dynamical Systems Ce Zhang, Kailiang Wu, Zhihai He IEEE Transactions on Artificial Intelligence, 2023; Also at First Workshop on Out-of-Distribution Generalization in Robotics at CoRL 2023. BDC-Adapter: Brownian Distance Covariance for Better Vision-Language Reasoning Yi Zhang*, Ce Zhang*, Zihan Liao, Yushun Tang, Zhihai He (*Equal contribution) British Machine Vision Conference (BMVC), 2023. Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation Yushun Tang, Ce Zhang, Heng Xu, Shuoshuo Chen, Jie Cheng, Luziwei Leng, Qinghai Guo, Zhihai He IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation Zhehan Kan, Shuoshuo Chen, Ce Zhang, Yushun Tang, Zhihai He IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation Xueting Hu, Ce Zhang, Yi Zhang, Bowen Hai, Ke Yu, Zhihai He IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024. Unsupervised Prototype Adapter for Vision-Languange Models Yi Zhang, Ce Zhang, Xueting Hu, Zhihai He Chinese Conference on Pattern Recognition and Computer Vision (PRCV), 2023. Graduation Destination M.Sc. in Machine Learning program, Carnegie Mellon University ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8002f3fe9913c00356161066c75bdec1","permalink":"https://nkdailab.github.io/author/%E5%BC%A0%E7%AD%96/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%BC%A0%E7%AD%96/","section":"authors","summary":"I’m Ce Zhang and I’m currently pursuing my Master’s degree in Machine Learning at CMU and looking forward to graduating in December 2024. Before this, I earned my B.Eng. in Communication Engineering from Southern University of Science and Technology (SUSTech). My current research interest lie in vision-language models and scene understanding.\n","tags":null,"title":"张策","type":"authors"},{"authors":null,"categories":null,"content":"Jingjun Xu, a sophomore majoring in information engineering at the Electronics Department of Southern University of Science and Technology.\nResearch Interests Machine Learning Personal Honors Third-class scholarship for outstanding students Third place of Guangdong Province in the National Mathematical Modeling Contest for College students ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6dc33cbde403b1b15437709e303f1013","permalink":"https://nkdailab.github.io/author/%E5%BE%90%E5%A9%A7%E7%8F%BA/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%BE%90%E5%A9%A7%E7%8F%BA/","section":"authors","summary":"Jingjun Xu, a sophomore majoring in information engineering at the Electronics Department of Southern University of Science and Technology.\nResearch Interests Machine Learning Personal Honors Third-class scholarship for outstanding students Third place of Guangdong Province in the National Mathematical Modeling Contest for College students ","tags":null,"title":"徐婧珺","type":"authors"},{"authors":null,"categories":null,"content":"Heng Xu, Master Student in Department of Electronic and Electrical Engineering of Southern University of Science and Technology.\nResearch Interests Learned Image Compression Work Experience (2021 – 2023) Teaching Assistant of Digital Signal Processing, Southern University of Science and Technology, Shenzhen Paper Yushun Tang, Ce Zhang, Heng Xu, Shuoshuo Chen, Jie Cheng, Luziwei Leng, Qinghai Guo, Zhihai He, “Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation. arXiv preprint arXiv:2303.00914, 2023. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e5cda4527eaeea89eaa9f3c443c2d050","permalink":"https://nkdailab.github.io/author/%E5%BE%90%E8%A1%A1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%BE%90%E8%A1%A1/","section":"authors","summary":"Heng Xu, Master Student in Department of Electronic and Electrical Engineering of Southern University of Science and Technology.\nResearch Interests Learned Image Compression Work Experience (2021 – 2023) Teaching Assistant of Digital Signal Processing, Southern University of Science and Technology, Shenzhen Paper Yushun Tang, Ce Zhang, Heng Xu, Shuoshuo Chen, Jie Cheng, Luziwei Leng, Qinghai Guo, Zhihai He, “Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation. arXiv preprint arXiv:2303.00914, 2023. ","tags":null,"title":"徐衡","type":"authors"},{"authors":null,"categories":null,"content":"Li Ruoyi, Master’s student in the Department of Electronic and Electrical Engineering at the Southern University of Science and Technology, specializing in the Artificial Intelligence Laboratory.\nResearch Interests Open-world robot autonomy perception Work Experience (2023) (Internship) Beijing Kuaishou Technology Co., Ltd. - Client Development Engineer, Beijing. (2023) (Internship) Huawei Technologies Co., Ltd. - General Software Development Engineer, Shenzhen. Personal Honors 2022 Southern University of Science and Technology Excellent Communist Youth League Cadre. Personal Activities Served as the Secretary of the Communist Youth League Branch in the Department of Electronic and Electrical Engineering at the Southern University of Science and Technology. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"32663ab7a2991370bbff0f3e0cb281de","permalink":"https://nkdailab.github.io/author/%E6%9D%8E%E8%8B%A5%E6%80%A1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%9D%8E%E8%8B%A5%E6%80%A1/","section":"authors","summary":"Li Ruoyi, Master’s student in the Department of Electronic and Electrical Engineering at the Southern University of Science and Technology, specializing in the Artificial Intelligence Laboratory.\nResearch Interests Open-world robot autonomy perception Work Experience (2023) (Internship) Beijing Kuaishou Technology Co., Ltd. - Client Development Engineer, Beijing. (2023) (Internship) Huawei Technologies Co., Ltd. - General Software Development Engineer, Shenzhen. Personal Honors 2022 Southern University of Science and Technology Excellent Communist Youth League Cadre. Personal Activities Served as the Secretary of the Communist Youth League Branch in the Department of Electronic and Electrical Engineering at the Southern University of Science and Technology. ","tags":null,"title":"李若怡","type":"authors"},{"authors":null,"categories":null,"content":"Jing Li, graduate student of Department of Biomedical Engineering of Central South University.\nResearch Interests Speech signal processing Deep Learning Personal Honors (2022) Outstanding Youth League Member (2023) Outstanding Student Paper Zhongchao Huang, Jing Li, Hongwen Zhong, Bo Tian*. Nucleic acid amplification strategies for volume-amplified magnetic nanoparticle detection assay[J].Frontiers in Bioengineering and Biotechnology, 2022. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"af6a13032e1132d710d0901d434d5b1f","permalink":"https://nkdailab.github.io/author/%E6%9D%8E%E9%9D%99/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%9D%8E%E9%9D%99/","section":"authors","summary":"Jing Li, graduate student of Department of Biomedical Engineering of Central South University.\nResearch Interests Speech signal processing Deep Learning Personal Honors (2022) Outstanding Youth League Member (2023) Outstanding Student Paper Zhongchao Huang, Jing Li, Hongwen Zhong, Bo Tian*. Nucleic acid amplification strategies for volume-amplified magnetic nanoparticle detection assay[J].Frontiers in Bioengineering and Biotechnology, 2022. ","tags":null,"title":"李静","type":"authors"},{"authors":null,"categories":null,"content":"Ke Yang , Master of Department of Electronics of Southern University of Science and Technology, Undergraduate Graduate of the Department of Computer Science and Technology,of Hunan University of Technology and Business , with a research focus on Machine Learning, Computer Vision.\nResearch Interests Machine Learning\nComputer Vision\nPersonal Honors (2022) Outstanding Graduate of Hunan university of Technology and Business ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f5208e78cff79924b56d0152c06e1ad5","permalink":"https://nkdailab.github.io/author/%E6%9D%A8%E7%A7%91/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%9D%A8%E7%A7%91/","section":"authors","summary":"Ke Yang , Master of Department of Electronics of Southern University of Science and Technology, Undergraduate Graduate of the Department of Computer Science and Technology,of Hunan University of Technology and Business , with a research focus on Machine Learning, Computer Vision.\n","tags":null,"title":"杨科","type":"authors"},{"authors":null,"categories":null,"content":"Ying Shen , master’s student of Department of Electronics of Southern University of Science and Technology.\nResearch Interests Machine Learning Sound Event Detection Human Activity Recognition Graduation Destination Senior Chassis Engineer, BYD Company Limited, Shenzhen ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"369e00d80d9df9eff8dc96bc2ab22fb9","permalink":"https://nkdailab.github.io/author/%E6%B2%88%E6%BB%A2/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%B2%88%E6%BB%A2/","section":"authors","summary":"Ying Shen , master’s student of Department of Electronics of Southern University of Science and Technology.\nResearch Interests Machine Learning Sound Event Detection Human Activity Recognition Graduation Destination Senior Chassis Engineer, BYD Company Limited, Shenzhen ","tags":null,"title":"沈滢","type":"authors"},{"authors":null,"categories":null,"content":"Bowen Hai , master’s student of Department of Electronics of Southern University of Science and Technology.\nResearch Interests Machine Learning Image/Video Compression Recommendation System Work Experience (2023) AI Engineer Intern,Honor Device Company Shenzhen Paper Xueting Hu, Ce Zhang, Yi Zhang, Bowen Hai, Ke Yu, Zhihai He, “Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation”. arXiv:2311.01034, 2023. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"73ca0e2397bbeed610dfe3b5ca81cfe3","permalink":"https://nkdailab.github.io/author/%E6%B5%B7%E5%8D%9A%E6%96%87/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%B5%B7%E5%8D%9A%E6%96%87/","section":"authors","summary":"Bowen Hai , master’s student of Department of Electronics of Southern University of Science and Technology.\nResearch Interests Machine Learning Image/Video Compression Recommendation System Work Experience (2023) AI Engineer Intern,Honor Device Company Shenzhen Paper Xueting Hu, Ce Zhang, Yi Zhang, Bowen Hai, Ke Yu, Zhihai He, “Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation”. arXiv:2311.01034, 2023. ","tags":null,"title":"海博文","type":"authors"},{"authors":null,"categories":null,"content":"Yijia Wang, undergraduate student of Department of Electronic and Electrical Engineering of Southern University of Science and Technology.\nResearch Interests Computer Vision Personal Activities First-class scholarship for outstanding students of Southern University of Science and Technology in 2023 Projects Climbing Plan (University Students Innovation and Entrepreneurship Project in Guangdong Province): A human-machine intention expression and knowledge learning system based on large models, 11/14/2023 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4c8c78afd83a011d71a9edf1762e7691","permalink":"https://nkdailab.github.io/author/%E7%8E%8B%E4%B8%80%E5%98%89/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E7%8E%8B%E4%B8%80%E5%98%89/","section":"authors","summary":"Yijia Wang, undergraduate student of Department of Electronic and Electrical Engineering of Southern University of Science and Technology.\nResearch Interests Computer Vision Personal Activities First-class scholarship for outstanding students of Southern University of Science and Technology in 2023 Projects Climbing Plan (University Students Innovation and Entrepreneurship Project in Guangdong Province): A human-machine intention expression and knowledge learning system based on large models, 11/14/2023 ","tags":null,"title":"王一嘉","type":"authors"},{"authors":null,"categories":null,"content":"Junyang Ji is a master of Tsinghua University in Electronic and Information Engineering (2023) and now is preparing to pursue a joint Ph.D. program between Tsinghua University and Southern University of Science and Technology from 2024.\nResearch Interests Computer Vision Machine Learning Personal Honors (2021) National Third Prize for Graduate Mathematical Modeling (2021) Tsinghua Shenzhen International Graduate School (SIGS) Second Prize Scholarship (2019, 2017) Harbin Institute of Technology (HIT) Second Prize Scholarship ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"b73ee2e46bf7ee73263f9be8cb10b2b1","permalink":"https://nkdailab.github.io/author/%E7%BA%AA%E4%BF%8A%E9%98%B3/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E7%BA%AA%E4%BF%8A%E9%98%B3/","section":"authors","summary":"Junyang Ji is a master of Tsinghua University in Electronic and Information Engineering (2023) and now is preparing to pursue a joint Ph.D. program between Tsinghua University and Southern University of Science and Technology from 2024.\n","tags":null,"title":"纪俊阳","type":"authors"},{"authors":null,"categories":null,"content":"Xueting Hu, a master’s student in the Department of Electronic and Electrical Engineering at the School of Engineering, Southern University of Science and Technology, graduated with a bachelor’s degree from Wuhan Institute of Automation, China University of Geosciences. Main research areas include large-scale visual language models, out of distribution detection, and more.\nResearch Interests Vision Language Models Computer Vision Few-shot Learning Personal Honors (2019) President’s scholarship for excellence in China University of Geosciences Paper Xueting Hu, Ce Zhang, Yi Zhang, Ke Yu, Zhihai He. Learn to Adapt CLIP for Few-Shot Monocular Depth Estimation. IEEE Winter Conference on Applications of Computer Vision (WACV), 2024. Yi Zhang, Ce Zhang, Xueting Hu, Zhihai He. Unsupervised Prototype Adapter for Vision-Language Models. The 6 th Chinese Conference on Pattern Recognition and Computer Vision (PRCV), 2023. Guochao Zhang, Xueting Hu, Yantao Wei, Weijia Cao, Huang Yao, Xueyang Zhang, Keyi Song. Nonlocal Correntropy Matrix Representation for Hyperspectral Image Classification. IEEE Geoscience and Remote Sensing Letters (GRSL), 2023. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"dc7132d8d70c74e65910ba985df3ce4d","permalink":"https://nkdailab.github.io/author/%E8%83%A1%E9%9B%AA%E5%A9%B7/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E8%83%A1%E9%9B%AA%E5%A9%B7/","section":"authors","summary":"Xueting Hu, a master’s student in the Department of Electronic and Electrical Engineering at the School of Engineering, Southern University of Science and Technology, graduated with a bachelor’s degree from Wuhan Institute of Automation, China University of Geosciences. Main research areas include large-scale visual language models, out of distribution detection, and more.\n","tags":null,"title":"胡雪婷","type":"authors"},{"authors":null,"categories":null,"content":"Xinhua Fan, graduate student of Department of Biomedical Engineering of Central South University.\nResearch Interests Speech signal processing Deep Learning Personal Honors (2022) Outstanding Student ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bac2091007ad984c34c485cfcb0927d4","permalink":"https://nkdailab.github.io/author/%E8%8C%83%E6%98%95%E5%8D%8E/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E8%8C%83%E6%98%95%E5%8D%8E/","section":"authors","summary":"Xinhua Fan, graduate student of Department of Biomedical Engineering of Central South University.\nResearch Interests Speech signal processing Deep Learning Personal Honors (2022) Outstanding Student ","tags":null,"title":"范昕华","type":"authors"},{"authors":null,"categories":null,"content":"Research Interests Machine Learning Computer Vision ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e9ce83e4c239bb1ff75521424a1e230f","permalink":"https://nkdailab.github.io/author/%E8%B4%BE%E7%BA%AA%E6%BA%90/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E8%B4%BE%E7%BA%AA%E6%BA%90/","section":"authors","summary":"Research Interests Machine Learning Computer Vision ","tags":null,"title":"贾纪源","type":"authors"},{"authors":null,"categories":null,"content":"Research Interests Image Compression Few-Shot Learning Paper Zhao Z, Liu Q, Cao W, et al. Self-guided information for few-shot classification[J]. Pattern Recognition, 2022, 131: 108880. Liu Q, Zhao Z, Cao W, et al. Residual proportion multilayer perceptron for few-shot classification[C]//2021 IEEE International conference on multimedia \u0026amp; expo workshops (ICMEW). IEEE, 2021: 1-6. Xiong M, Cao W, Zhao Z. Dual-model Collaborative Learning with Knowledge Clustering for Few-shot Image Classification[J]. Multimedia Tools and Applications, 2023: 1-20. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f70bb9260f13c53d9bbcf460fc6ba7a2","permalink":"https://nkdailab.github.io/author/%E8%B5%B5%E4%B9%8B%E8%83%BD/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E8%B5%B5%E4%B9%8B%E8%83%BD/","section":"authors","summary":"Research Interests Image Compression Few-Shot Learning Paper Zhao Z, Liu Q, Cao W, et al. Self-guided information for few-shot classification[J]. Pattern Recognition, 2022, 131: 108880. Liu Q, Zhao Z, Cao W, et al. Residual proportion multilayer perceptron for few-shot classification[C]//2021 IEEE International conference on multimedia \u0026 expo workshops (ICMEW). IEEE, 2021: 1-6. Xiong M, Cao W, Zhao Z. Dual-model Collaborative Learning with Knowledge Clustering for Few-shot Image Classification[J]. Multimedia Tools and Applications, 2023: 1-20. ","tags":null,"title":"赵之能","type":"authors"},{"authors":null,"categories":null,"content":"Weiye Qian, undergraduate student in Department of Electric and Electrical Engineering of Southern University of Science and Technology.\nProjects Climbing Plan (University Students Innovation and Entrepreneurship Project in Guangdong Province): A human-machine intention expression and knowledge learning system based on large models, 11/14/2023 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6a0d2fafd975706e51bc7d73f323e071","permalink":"https://nkdailab.github.io/author/%E9%92%B1%E4%BC%9F%E7%83%A8/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%92%B1%E4%BC%9F%E7%83%A8/","section":"authors","summary":"Weiye Qian, undergraduate student in Department of Electric and Electrical Engineering of Southern University of Science and Technology.\nProjects Climbing Plan (University Students Innovation and Entrepreneurship Project in Guangdong Province): A human-machine intention expression and knowledge learning system based on large models, 11/14/2023 ","tags":null,"title":"钱伟烨","type":"authors"},{"authors":null,"categories":null,"content":"Zhehan Kan , Master’s degree graduates of Southern University of Science and Technology in 2023.\nResearch Interests Machine Learning Computer Vision Multimodal Large Language Models (MLLMs) Work Experience (2022) Research Intern, XRLab, Alibaba Damo Academy, Beijing (2023-Present) Research Intern, PengCheng Lab, Shenzhen Personal Honors (2023) Outstanding Graduate Student of Southern University of Science and Technology. Personal Activities Reviewer, European Conference on Computer Vision 2022 Reviewer, CAAI Transactions on Intelligence Technology, 2023 Paper Zhehan Kan, Xueting Hu, Zihan Liao, Ke Yu, Shuoshuo Chen, Zhihai He. Cross-Constrained Progressive Inference for 3D Hand Pose Estimation. Association for the Advancement of Artificial Intelligence (AAAI), 2024. Zhehan Kan, Shuoshuo Chen, Ce Zhang, Zhihai He. Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. Zhehan Kan, Shuoshuo Chen, Zeng Li, Zhihai He. Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation. European Conference on Computer Vision (ECCV ), 2022. Graduation Destination Ph.D. in Tsinghua University ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"1c2ab05a6ac8f52e4953fc68117b776d","permalink":"https://nkdailab.github.io/author/%E9%98%9A%E5%93%B2%E6%B6%B5/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%98%9A%E5%93%B2%E6%B6%B5/","section":"authors","summary":"Zhehan Kan , Master’s degree graduates of Southern University of Science and Technology in 2023.\nResearch Interests Machine Learning Computer Vision Multimodal Large Language Models (MLLMs) Work Experience (2022) Research Intern, XRLab, Alibaba Damo Academy, Beijing (2023-Present) Research Intern, PengCheng Lab, Shenzhen Personal Honors (2023) Outstanding Graduate Student of Southern University of Science and Technology. Personal Activities Reviewer, European Conference on Computer Vision 2022 Reviewer, CAAI Transactions on Intelligence Technology, 2023 Paper Zhehan Kan, Xueting Hu, Zihan Liao, Ke Yu, Shuoshuo Chen, Zhihai He. Cross-Constrained Progressive Inference for 3D Hand Pose Estimation. Association for the Advancement of Artificial Intelligence (AAAI), 2024. Zhehan Kan, Shuoshuo Chen, Ce Zhang, Zhihai He. Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. Zhehan Kan, Shuoshuo Chen, Zeng Li, Zhihai He. Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation. European Conference on Computer Vision (ECCV ), 2022. Graduation Destination Ph.D. in Tsinghua University ","tags":null,"title":"阚哲涵","type":"authors"},{"authors":null,"categories":null,"content":"Have graduated.\nResearch Interests Computer Vision Graduation Destination Shenzhen Yifang Lianchuang Technology Co., Ltd. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"cd103bb22e173e79aa979a12f93936a8","permalink":"https://nkdailab.github.io/author/%E9%99%88%E5%BA%86%E5%8D%97/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%99%88%E5%BA%86%E5%8D%97/","section":"authors","summary":"Have graduated.\nResearch Interests Computer Vision Graduation Destination Shenzhen Yifang Lianchuang Technology Co., Ltd. ","tags":null,"title":"陈庆南","type":"authors"},{"authors":null,"categories":null,"content":"I’m Shuoshuo Chen (陈烁硕), a third-year Master student in the Department of Electronic and Electrical Engineering at Southern University of Science and Technology, advised by Professor Zhihai He. My research interests focus on the generalization capability of machine learning models for vision tasks.\nResearch Interests Machine Learning Computer Vision Personal Honors (2021) Excellent Graduate of Southern University of Science and Technology (2018-2020) Merit Student Scholarship Paper Zhehan Kan, Shuoshuo Chen, Ce Zhang, Yushun Tang and Zhihai He, “Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. Yushun Tang, Ce Zhang, Heng Xu, Shuoshuo Chen, Jie Cheng, Luziwei Leng, Qinghai Guo, Zhihai He,“Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. Zhehan Kan, Shuoshuo Chen, Zeng Li and Zhihai He, “Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation,” in European Conference on Computer Vision (ECCV), 2022. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"88a703101b1defbd6909ab126a326933","permalink":"https://nkdailab.github.io/author/%E9%99%88%E7%83%81%E7%A1%95/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%99%88%E7%83%81%E7%A1%95/","section":"authors","summary":"I’m Shuoshuo Chen (陈烁硕), a third-year Master student in the Department of Electronic and Electrical Engineering at Southern University of Science and Technology, advised by Professor Zhihai He. My research interests focus on the generalization capability of machine learning models for vision tasks.\n","tags":null,"title":"陈烁硕","type":"authors"},{"authors":null,"categories":null,"content":"Weiming Chen received the B.Eng. degree in mechanical design manufacture and automation, and the M.Sc. degree in electronic science and technology from Xidian University, Xi’an, China, in 2019, and 2023. He is currently pursuing the Ph.D. degree in Intelligent Manufacturing and Robotics from Southern University of Science and Technology, Shenzhen, China. His research interests include machine learning, computer vision, multi modality, AIGC, text-to-image synthesis, diffusion model, object detection, and remote sensing.\nVisit his personal homepage for more information (https://www.weimingchen.net).\nResearch Interests Machine Learning Computer Vision Multi Modality AIGC Text-to-Image Synthesis Diffusion Model Object Detection Remote Sensing Projects Visual Annotation Platform (VAP) Research on Key Technologies of Adaptive Multi Domain Image Data Automatic Annotation Publication Weiming Chen, Bing Han, Xinbo Gao (2023). Oriented Ship Detection Based on Expansion Deformation Rotation Representation. 2023 3rd International Conference on Frontiers of Electronics, Information and Computation Technologies (ICFEICT): 621-627. DOI: 10.1109/ICFEICT59519.2023.00108. Zheng Yang, Bing Han, Weiming Chen, Xinbo Gao (2023). Learn to Encode Heterogeneous Data: A Heterogeneous Aware Network for Multi-Future Trajectory Prediction. International Joint Conference on Neural Networks (IJCNN), Queensland, Australia. Bing Han, Weiming Chen, Yang Zhou, Haitong Wang, Weixiong Zhao (2023). 光学遥感影像数据处理平台V1.0. 中国, 计算机软件著作权. 登记号: 2023SR0674142, 登记日期: 2023年6月15日. (已授权). Yang Zhou, Bing Han, Xinbo Gao, Zheng Yang, Weiming Chen (2023). Domain Adaptive Object Detection Based on Attention Mechanism and Cycle Domain Triplet Loss. ACTA AUTOMATICA SINICA. (published online). Bing Han, Weiming Chen, Ping Wang, Yannan Xiong, Yang Zhou, Weixiong Zhao (2023). 视觉影像标注平台V1.0. 中国, 计算机软件著作权. 登记号: 2023SR0432943, 登记日期: 2023年4月3日. (已授权). Zheng Yang, Bing Han, Weiming Chen, Xinbo Gao (2022). TMDiMP: Temporal memory guided discriminative tracker for UAV object tracking. Remote Sensing, 14(24): 6351. DOI: 10.3390/rs14246351. Weiming Chen, Bing Han, Zheng Yang, Xinbo Gao (2022). MSSDet: Multi-Scale Ship-Detection Framework in Optical Remote-Sensing Images and New Benchmark. Remote Sensing, 14(21): 5460. DOI: 10.3390/rs14215460. Bing Han, Weiming Chen, Xinbo Gao, Zheng Yang, Xiaoyue Huang (2022). 基于联合递归特征金字塔的多尺度目标检测方法. 中国, 发明专利. 申请号: 202211339440.0, 申请日期: 2022年10月29日. (在审查). Bing Han, Zheng Yang, Xinbo Gao, Weiming Chen, Xiaoyue Huang (2022). 基于序列感知与特征增强的无人机视角目标跟踪方法. 中国, 发明专利. 申请号: 202211194947.1, 申请日期: 2022年9月27日. (在审查). Bing Han, Zheng Yang, Xinbo Gao, Weiming Chen, Xiaoyue Huang (2022). 基于异构数据关联挖掘与度量学习的智能体轨迹预测方法. 中国, 发明专利. 申请号: 202211163069.7, 申请日期: 2022年9月23日. (在审查). Bing Han, Lu Gao, Zheng Yang, Weiming Chen, Xiaoyue Huang (2022). 基于点标注数据的病理图像分割方法. 中国, 发明专利. 申请号: 202210569641.3. 申请日期: 2022年5月24日. (在审查). ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3fc097de1b4c25c640c60e6ff9c933c8","permalink":"https://nkdailab.github.io/author/%E9%99%88%E7%8E%AE%E9%93%AD/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%99%88%E7%8E%AE%E9%93%AD/","section":"authors","summary":"Weiming Chen received the B.Eng. degree in mechanical design manufacture and automation, and the M.Sc. degree in electronic science and technology from Xidian University, Xi’an, China, in 2019, and 2023. He is currently pursuing the Ph.D. degree in Intelligent Manufacturing and Robotics from Southern University of Science and Technology, Shenzhen, China. His research interests include machine learning, computer vision, multi modality, AIGC, text-to-image synthesis, diffusion model, object detection, and remote sensing.\n","tags":null,"title":"陈玮铭","type":"authors"},{"authors":null,"categories":null,"content":"AAAI, short for The Association for Advancement of Artificial Intelligence, is one of the most important international conferences in the field of Artificial Intelligence, hosted by the International Association for Artificial Intelligence, and recommended by the Chinese Computer Federation (CCF) as a Class A conference. AAAI AAAI 2025 received 12,957 submissions and 3032 papers were accepted, with an acceptance rate of 23.4%, of which the Oral Presentation acceptance rate was 4.6%.AAAI 2025 was held on 25 February - 4 March 2025 in Philadelphia, Pennsylvania, USA.\n《Cross-Modal Few-Shot Learning with Second-Order Neural Ordinary Differential Equations》\nAuthors Yi Zhang (Harbin Institute of Technology, Southern University of Science and Technology), Chun-Wun Cheng (University of Cambridge), Junyi He (Southern University of Science and Technology), Zhihai He (Southern University of Science and Technology), Carola-Bibiane Schönlieb (University of Cambridge), Yuyan Chen (Fudan University), Angelica I Aviles-Rivero (Tsinghua University)\nBrief introduction Yi Zhang, a PhD student in the class of 2021 at the Department of Electronic and Electrical Engineering, Southern University of Science and Technology, proposes an innovative method SONO in the field of cross-modal small-sample learning, which significantly improves the model’s generalisation ability in few-sample scenarios through second-order God-frequent differential equations, and effectively solves the overfitting problem due to the scarcity of data in the traditional method. With the rapid development of multimodal AI technology, how to make the model achieve cross-modal (e.g., image-text) efficient learning under a very small number of labelled samples has become a key challenge. Existing methods generally face bottlenecks such as high risk of overfitting, high consumption of computational resources, and insufficient cross-modal alignment capability. The research team innovatively introduces the second-order God’s frequent differential equation into the cross-modal learning framework, enhances the model expression ability through continuous dynamic feature optimisation, and combines the ‘text-as-image’ data enhancement strategy to effectively expand the training data by using the graphic-text correlation feature of CLIP model. Experiments show that the classification accuracy of this method on 11 benchmark datasets, such as ImageNet, is significantly better than that of the existing optimal method for small samples, and shows potential application in data-scarce scenarios, such as medical images. This paper is the result of research conducted by Yi Zhang, a PhD student from the Department of Electronics, SUSTech, class of 2021, during his visit to the University of Cambridge, UK, under the supervision of Professor Zhihai He Chair of SUSTech and Assistant Professor Angelica I. Aviles-Rivero, Tsinghua University Qiu Chengtong Mathematical Sciences Centre, during her tenure as a Senior Associate Researcher at the University of Cambridge, and in collaboration with the research institutes of SUSTech, the Cambridge University Department of Applied Department of Mathematics and Theoretical Physics, University of Cambridge, Tsinghua University’s Chuchengtong Centre for Mathematical Sciences, Shanghai Key Laboratory of Data Science and other research institutions. Yi Zhang, a joint PhD candidate of SUSTech and Harbin Institute of Technology, is the first author of this paper, while Junhuan Zheng, a PhD student of Cambridge University, Junyi He, an undergraduate student of SUSTech in the class of 2021, Prof. Carola-Bibiane Schönlieb of Cambridge University, and Yuyan Chen, a PhD student of the Shanghai Key Laboratory of Data Science of Fudan University are the authors of this paper, as well as Zhi-Hai He, a chair professor of the Department of Electronics of SUSTech, Angelica I. Aviles-Rivero, Assistant Professor at the Qiu Chengtong Centre for Mathematical Sciences, Tsinghua University, are the corresponding authors of this paper. NUST doctoral student Yi Zhang and undergraduate student Jun He are also from Zhihai He’s group.\nPaper link: https://arxiv.org/abs/2412.15813 Funding information: This work was supported by the National Natural Science Foundation of China under Key Project No. 62331014.\n《Conditional Latent Coding with Learnable Synthesized Reference for Deep Image Compression》\nAuthors Siqi Wu (University of Missouri), Yinda Chen (University of Science and Technology of China), Dong Liu (University of Science and Technology of China), Zhihai He (Southern University of Science and Technology)\nBrief introduction Siqi Wu, a PhD student in the Department of Electrical and Computer Engineering, University of Missouri, USA, class of 2022, has proposed a conditional latent coding method based on learnable synthetic references to improve the efficiency of deep image compression in collaboration with the University of Science and Technology of China (USTC) during …","date":1740528000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1740528000,"objectID":"235108c165bae6c48f0b4c9e042a3472","permalink":"https://nkdailab.github.io/post/2025.3.6/","publishdate":"2025-02-26T00:00:00Z","relpermalink":"/post/2025.3.6/","section":"post","summary":"A total of two papers from the Artificial Intelligence Laboratory (AI Lab) of the Department of Electronics, Southern University of Science and Technology (SUSTech) have been accepted in the acceptance results published by AAAI-2025, the top international conference on Artificial Intelligence, and both of them have been accepted as Oral Presentation.","tags":null,"title":"He Zhihai's group in the Department of Electronics at SUSTech is pleased to present two AAAI-2025 Oral Papers","type":"post"},{"authors":null,"categories":null,"content":"Recently, the list of winners of the 2024 Wu Wenjun Artificial Intelligence Science and Technology Award was officially released, and Professor He Zhihai Chair of the Department of Electrical and Electronic Engineering of the Southern University of Science and Technology (SUSTech), as the first project completion, stood out for his project of ‘Big Model-Driven Home AI Doctor and Total Patient Care Management’, which won the ‘Second Prize for Technological Invention of the Year 2024’. ‘The Second Prize for Technical Invention in the 2024 Wu Wenjun Artificial Intelligence Science and Technology Award.\nFigure 1. Winners List.\nInitiated by the Chinese Society for Artificial Intelligence, the Wu Wenjun Artificial Intelligence Science and Technology Award, known as ‘China’s Highest Prize for Intelligent Science and Technology’, is a symbol of the highest honour in the field of artificial intelligence. The award aims to recognise units and individuals who have made key discoveries in AI research, promoted scientific and technological progress, and created significant economic and social benefits or ecological and environmental benefits.\nProfessor He Zhihai, together with Professor Cao Wenming of Shenzhen University, Professor Cen Yigang of Beijing Jiaotong University, and Senior Research Scholar Ouyang Jian of the Southern University of Science and Technology, jointly declared the achievement of ‘Big Model-Driven Home AI Doctor and Total Disease Management’, which is an innovative use of AI and big model technology to build a set of products that cover the following areas: home health and disease monitoring, analytical modelling, analysis and modelling, and home health and disease management. It innovatively uses artificial intelligence and big model technology to build a comprehensive platform covering home health and disease monitoring, analysis and modelling, early warning and intervention, diagnosis and treatment assistance, as well as chronic disease prevention and control management. The platform greatly empowers healthcare professionals to provide professional and intelligent health monitoring and disease management services for elderly patients with chronic diseases in the home environment, effectively solving the health monitoring and disease management problems brought about by aging.\nFigure 2. AI home healthcare intelligent agent.\nAt present, the project has been successfully applied on a large scale in Guangdong, Hunan and Zhejiang, effectively improving the health management of local elderly patients with chronic diseases and generating good social benefits, and is expected to provide reference and demonstration for more regions to cope with the health challenges of aging.\nOriginal link: https://mp.weixin.qq.com/s/K3X2Avrt6lgsTJWg3ry3Qw\n","date":1740441600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1740441600,"objectID":"59fbe73209dca5b2c32ccdc30b678812","permalink":"https://nkdailab.github.io/post/2025.2.25/","publishdate":"2025-02-25T00:00:00Z","relpermalink":"/post/2025.2.25/","section":"post","summary":"Large model-driven home AI doctor and whole patient management’ researched by Professor Zhihai He, Chair of Electrical and Electronic Engineering, Southern University of Science and Technology (SUSTech), has won the Second Prize of Technological Invention in the Wu Wenjun Artificial Intelligence Science and Technology Award 2024.","tags":null,"title":"Professor Zhihai He's team from the Department of Electronics, SUSTech, won the second prize for technical invention in the 2024 Wu Wenjun Artificial Intelligence Science and Technology Award","type":"post"},{"authors":["Ce Zhang","Siqi Wu","Zhihai He","Zhao Joy Sun"],"categories":null,"content":" ","date":1699142400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1699142400,"objectID":"7c7fd8c8f4e3f2caee39c18a64959b9e","permalink":"https://nkdailab.github.io/publication/critical-sampling-for-data-driven-modeling-of-unknown-dynamical-systems/","publishdate":"2023-11-05T00:00:00Z","relpermalink":"/publication/critical-sampling-for-data-driven-modeling-of-unknown-dynamical-systems/","section":"publication","summary":"When a robot is exploring an unknown dynamical system, we often face the following important question:what is the minimum number of samples needed for effective learning of its governing laws and accurate prediction of its future evolution behavior, and how to select these critical samples? In this work, we propose to explore this problem based on a design approach. Starting from a small initial set of samples, we adaptively discover critical samples to achieve increasingly accurate learning of the system evolution. We establish a multi-step reciprocal prediction network where forward and backward evolution networks are designed to learn the temporal evolution behavior in the forward and backward time directions, respectively. Very interestingly, we find that the desired network modeling error is highly correlated with the multi-step reciprocal prediction error, which can be directly computed from the current system state. This allows us to perform a dynamic selection of critical samples from regions with high network modeling errors for dynamical systems. Our extensive experimental results demonstrate that our proposed method is able to dramatically reduce the number of samples needed for effective learning and accurate prediction of evolution behaviors of unknown dynamical systems by up to hundreds of times.","tags":null,"title":"Critical Sampling for Data-Driven Modeling of Unknown Dynamical Systems","type":"publication"},{"authors":["Xueting Hu","Ce Zhang","Yi Zhang","Bowen Hai","Ke Yu","Zhihai He"],"categories":null,"content":" ","date":1698883200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1698883200,"objectID":"521043e96fc9adaa48a8e46ef72d2d75","permalink":"https://nkdailab.github.io/publication/learning-to-adapt-clip-for-few-shot-monocular-depth-estimation/","publishdate":"2023-11-02T00:00:00Z","relpermalink":"/publication/learning-to-adapt-clip-for-few-shot-monocular-depth-estimation/","section":"publication","summary":"Pre-trained Vision-Language Models (VLMs), such as CLIP, have shown enhanced performance across a range of tasks that involve the integration of visual and linguistic modalities. When CLIP is used for depth estimation tasks, the patches, divided from the input images, can be combined with a series of semantic descriptions of the depth information to obtain similarity results. The coarse estimation of depth is then achieved by weighting and summing the depth values, called depth bins, corresponding to the predefined semantic descriptions. The zero-shot approach circumvents the computational and time-intensive nature of traditional fully-supervised depth estimation methods. However, this method, utilizing fixed depth bins, may not effectively generalize as images from different scenes may exhibit distinct depth distributions. To address this challenge, we propose a few-shot-based method which learns to adapt the VLMs for monocular depth estimation to balance training costs and generalization capabilities. Specifically, it assigns different depth bins for different scenes, which can be selected by the model during inference. Additionally, we incorporate learnable prompts to preprocess the input text to convert the easily human-understood text into easily model-understood vectors and further enhance the performance. With only one image per scene for training, our extensive experiment results on the NYU V2 and KITTI dataset demonstrate that our method outperforms the previous state-of-the-art method by up to 10.6\\% in terms of MARE.","tags":null,"title":"Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation","type":"publication"},{"authors":["Yushun Tang","Qinghai Guo","Zhihai He"],"categories":null,"content":" ","date":1696723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696723200,"objectID":"1d3e755ec6b18cff7ef301a3685c986a","permalink":"https://nkdailab.github.io/publication/cross-inferential-networks-for-source-free-unsupervised-domain-adaptation/","publishdate":"2023-10-08T00:00:00Z","relpermalink":"/publication/cross-inferential-networks-for-source-free-unsupervised-domain-adaptation/","section":"publication","summary":"One central challenge in source-free unsupervised domain adaptation (UDA) is the lack of an effective approach to evaluate the prediction results of the adapted network model in the target domain. To address this challenge, we propose to explore a new method called cross-inferential networks (CIN). Our main idea is that, when we adapt the network model to predict the sample labels from encoded features, we use these prediction results to construct new training samples with derived labels to learn a new examiner network that performs a different but compatible task in the target domain. Specifically, in this work, the base network model is performing image classification while the examiner network is tasked to perform relative ordering of triplets of samples whose training labels are carefully constructed from the prediction results of the base network model. Two similarity measures, cross-network correlation matrix similarity and attention consistency, are then developed to provide important guidance for the UDA process. Our experimental results on benchmark datasets demonstrate that our proposed CIN approach can significantly improve the performance of source-free UDA.","tags":["Training","Adaptation models","Correlation","Image processing","Predictive models","Benchmark testing","Task analysis"],"title":"Cross-inferential networks for source-free unsupervised domain adaptation","type":"publication"},{"authors":["Yi Zhang","Ce Zhang","Zihan Liao","Yushun Tang","Zhihai He"],"categories":null,"content":" ","date":1693699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693699200,"objectID":"24e7e7985cb362966eae91318043e6aa","permalink":"https://nkdailab.github.io/publication/bdc-adapter-brownian-distance-covariance-for-better-vision-language-reasoning/","publishdate":"2023-09-03T00:00:00Z","relpermalink":"/publication/bdc-adapter-brownian-distance-covariance-for-better-vision-language-reasoning/","section":"publication","summary":"Large-scale pre-trained Vision-Language Models (VLMs), such as CLIP and ALIGN, have introduced a new paradigm for learning transferable visual representations. Recently, there has been a surge of interest among researchers in developing lightweight fine-tuning techniques to adapt these models to downstream visual tasks. We recognize that current state-of-the-art fine-tuning methods, such as Tip-Adapter, simply consider the covariance between the query image feature and features of support few-shot training samples, which only captures linear relations and potentially instigates a deceptive perception of independence. To address this issue, in this work, we innovatively introduce Brownian Distance Covariance (BDC) to the field of vision-language reasoning. The BDC metric can model all possible relations, providing a robust metric for measuring feature dependence. Based on this, we present a novel method called BDC-Adapter, which integrates BDC prototype similarity reasoning and multi-modal reasoning network prediction to perform classification tasks. Our extensive experimental results show that the proposed BDC-Adapter can freely handle non-linear relations and fully characterize independence, outperforming the current state-of-the-art methods by large margins.","tags":null,"title":"BDC-Adapter Brownian Distance Covariance for Better Vision-Language Reasoning","type":"publication"},{"authors":["Yi Zhang","Ce Zhang","Xueting Hu","Zhihai He"],"categories":null,"content":" ","date":1692662400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692662400,"objectID":"d649788896b308d4de68f455f53864fc","permalink":"https://nkdailab.github.io/publication/unsupervised-prototype-adapter-for-vision-language-models/","publishdate":"2023-08-22T00:00:00Z","relpermalink":"/publication/unsupervised-prototype-adapter-for-vision-language-models/","section":"publication","summary":"Recently, large-scale pre-trained vision-language models (e.g. CLIP and ALIGN) have demonstrated remarkable effectiveness in acquiring transferable visual representations. To leverage the valuable knowledge encoded within these models for downstream tasks, several fine-tuning approaches, including prompt tuning methods and adapter-based methods, have been developed to adapt vision-language models effectively with supervision. However, these methods rely on the availability of annotated samples, which can be labor-intensive and time-consuming to acquire, thus limiting scalability. To address this issue, in this work, we design an unsupervised fine-tuning approach for vision-language models called Unsupervised Prototype Adapter (UP-Adapter). Specifically, for the unannotated target datasets, we leverage the text-image aligning capability of CLIP to automatically select the most confident samples for each class. Utilizing these selected samples, we generate class prototypes, which serve as the initialization for the learnable prototype model. After fine-tuning, the prototype model prediction is combined with the original CLIP's prediction by a residual connection to perform downstream recognition tasks. Our extensive experimental results on image recognition and domain generalization show that the proposed unsupervised method outperforms 8-shot CoOp, 8-shot Tip-Adapter, and also the state-of-the-art UPL method by large margins.","tags":null,"title":"Unsupervised Prototype Adapter for Vision-Language Models","type":"publication"},{"authors":["Qifan Liu","Wenming Cao","Zhihai He"],"categories":null,"content":"","date":1688169600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688169600,"objectID":"2b1a2049f9e4235ac4c0335501d2259b","permalink":"https://nkdailab.github.io/publication/cycle-optimization-metric-learning-for-few-shot-classification/","publishdate":"2023-07-01T00:00:00Z","relpermalink":"/publication/cycle-optimization-metric-learning-for-few-shot-classification/","section":"publication","summary":"Metric learning methods are widely used in few-shot learning due to their simplicity and effectiveness. Most existing methods directly predict query labels by comparing the similarity between support and query samples. In this paper, we design a cycle optimization metric network for few-shot classification task that optimizes model performance based on loop-prediction of the labels of query samples and support samples. Specifically, we construct a forward network and reverse network based on a geometric algebra Graph Neural Network (GA-GNN). These two networks form the loop prediction from support samples to query samples and then back to support samples, guided by a cycle-consistency loss. We also introduce an optimization module that is able to correct the predicted results of query samples to further improve the network performance. Our extensive experimental results demonstrate that the proposed cycle optimization metric network outperforms existing state-of-the-art few-shot learning methods on classification tasks.","tags":["Few-shot classification","Graph convolution network","Self-guided information"],"title":"Cycle optimization metric learning for few-shot classification","type":"publication"},{"authors":["Ce Zhang","Kailiang Wu","Zhihai He"],"categories":null,"content":"","date":1681516800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681516800,"objectID":"002eabb64a60ed3e3c66506e950e7eb1","permalink":"https://nkdailab.github.io/publication/critical-sampling-for-robust-evolution-operator-learning-of-unknown-dynamical-systems/","publishdate":"2023-04-15T00:00:00Z","relpermalink":"/publication/critical-sampling-for-robust-evolution-operator-learning-of-unknown-dynamical-systems/","section":"publication","summary":"Given an unknown dynamical system, what is the minimum number of samples needed for effective learning of its governing laws and accurate prediction of its future evolution behavior, and how to select these critical samples? In this work, we propose to explore this problem based on a design approach. Starting from a small initial set of samples, we adaptively discover critical samples to achieve increasingly accurate learning of the system evolution. One central challenge here is that we do not know the network modeling error since the ground-truth system state is unknown, which is however needed for critical sampling. To address this challenge, we introduce a multi-step reciprocal prediction network where forward and backward evolution networks are designed to learn the temporal evolution behavior in the forward and backward time directions, respectively. Very interestingly, we find that the desired network modeling error is highly correlated with the multi-step reciprocal prediction error, which can be directly computed from the current system state. This allows us to perform a dynamic selection of critical samples from regions with high network modeling errors for dynamical systems. Additionally, a joint spatial-temporal evolution network is introduced which incorporates spatial dynamics modeling into the temporal evolution prediction for robust learning of the system evolution operator with few samples. Our extensive experimental results demonstrate that our proposed method is able to dramatically reduce the number of samples needed for effective learning and accurate prediction of evolution behaviors of unknown dynamical systems by up to hundreds of times.","tags":null,"title":"Critical Sampling for Robust Evolution Operator Learning of Unknown Dynamical Systems","type":"publication"},{"authors":["Zhehan Kan","Shuoshuo Chen","Ce Zhang","Yushun Tang","Zhihai He"],"categories":null,"content":" ","date":1679270400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679270400,"objectID":"a18bed0e4080f799751129955a31b702","permalink":"https://nkdailab.github.io/publication/self-correctable-and-adaptable-inference-for-generalizable-human-pose-estimation/","publishdate":"2023-03-20T00:00:00Z","relpermalink":"/publication/self-correctable-and-adaptable-inference-for-generalizable-human-pose-estimation/","section":"publication","summary":"A central challenge in human pose estimation, as well as in many other machine learning and prediction tasks, is the generalization problem. The learned network does not have the capability to characterize the prediction error, generate feedback information from the test sample, and correct the prediction error on the fly for each individual test sample, which results in degraded performance in generalization. In this work, we introduce a self-correctable and adaptable inference (SCAI) method to address the generalization challenge of network prediction and use human pose estimation as an example to demonstrate its effectiveness and performance. We learn a correction network to correct the prediction result conditioned by a fitness feedback error. This feedback error is generated by a learned fitness feedback network which maps the prediction result to the original input domain and compares it against the original input. Interestingly, we find that this self-referential feedback error is highly correlated with the actual prediction error. This strong correlation suggests that we can use this error as feedback to guide the correction process. It can be also used as a loss function to quickly adapt and optimize the correction network during the inference process. Our extensive experimental results on human pose estimation demonstrate that the proposed SCAI method is able to significantly improve the generalization capability and performance of human pose estimation.","tags":null,"title":"Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation","type":"publication"},{"authors":["Yushun Tang","Ce Zhang","Heng Xu","Shuoshuo Chen","Jie Cheng","Luziwei Leng","Qinghai Guo","Zhihai He"],"categories":null,"content":" ","date":1677715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677715200,"objectID":"56303c7b470b49c10d391fc86a30453d","permalink":"https://nkdailab.github.io/publication/neuro-modulated-hebbian-learning-for-fully-test-time-adaptation/","publishdate":"2023-03-02T00:00:00Z","relpermalink":"/publication/neuro-modulated-hebbian-learning-for-fully-test-time-adaptation/","section":"publication","summary":"Fully test-time adaptation aims to adapt the network model based on sequential analysis of input samples during the inference stage to address the cross-domain performance degradation problem of deep neural networks. We take inspiration from the biological plausibility learning where the neuron responses are tuned based on a local synapse-change procedure and activated by competitive lateral inhibition rules. Based on these feed-forward learning rules, we design a soft Hebbian learning process which provides an unsupervised and effective mechanism for online adaptation. We observe that the performance of this feed-forward Hebbian learning for fully test-time adaptation can be significantly improved by incorporating a feedback neuro-modulation layer. It is able to fine-tune the neuron responses based on the external feedback generated by the error back-propagation from the top inference layers. This leads to our proposed neuro-modulated Hebbian learning (NHL) method for fully test-time adaptation. With the unsupervised feed-forward soft Hebbian learning being combined with a learned neuro-modulator to capture feedback from external responses, the source model can be effectively adapted during the testing process. Experimental results on benchmark datasets demonstrate that our proposed method can significantly improve the adaptation performance of network models and outperforms existing state-of-the-art methods.","tags":null,"title":"Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation","type":"publication"},{"authors":["Zhineng Zhao","Qifan Liu","Wenming Cao","Deliang Lian","Zhihai He"],"categories":null,"content":"","date":1667260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667260800,"objectID":"ecb52f55912e8318c680f38d69c6a7dc","permalink":"https://nkdailab.github.io/publication/self-guided-information-for-few-shot-classification/","publishdate":"2022-11-01T00:00:00Z","relpermalink":"/publication/self-guided-information-for-few-shot-classification/","section":"publication","summary":"Few-shot classification aims to identify novel categories using only a few labeled samples. Generally, the metric-based few-shot classification methods compare the feature embedding of Query samples (unlabeled samples) with Support samples (labeled samples) in a metric algorithm to predict which category the Query sample belongs to. Obtaining a good feature embedding for each sample in the feature extraction stage can improve the classification accuracy in the metric stage. Based on this, we design the Self-Guided Information Convolution (SGI-Conv), an improved convolution structure, which utilizes the high-level features to guide the network to extract the required discriminative features. To effectively utilize the feature embeddings of samples, we divide the metric network into multiple blocks and build a multi-layer graph convolutional network by sharing adjacent matrices. The multi-layer structure enhances the aggregation ability of graph convolution. Extensive experiments on multiple benchmark datasets demonstrate that our method has achieved competitive results on the few-shot classification tasks.","tags":["Few-shot classification","Graph convolution network","Self-guided information"],"title":"Self-guided information for few-shot classification","type":"publication"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://nkdailab.github.io/contact/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"Contact","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"b0d61e5cbb7472bf320bf0ef2aaeb977","permalink":"https://nkdailab.github.io/tour/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/tour/","section":"","summary":"","tags":null,"title":"Home","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://nkdailab.github.io/people/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"People","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"b27ca6127db17e2b568383080404fdc7","permalink":"https://nkdailab.github.io/event/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/event/","section":"","summary":"","tags":null,"title":"research","type":"landing"},{"authors":["Zhehan Kan","Shuoshuo Chen","Zeng Li","Zhihai He"],"categories":null,"content":" ","date":1666483200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666483200,"objectID":"7522a23b9d30c71c738b405e2cdbd8e3","permalink":"https://nkdailab.github.io/publication/self-constrained-inference-optimization-on-structural-groups-for-human-pose-estimation/","publishdate":"2023-10-23T00:00:00Z","relpermalink":"/publication/self-constrained-inference-optimization-on-structural-groups-for-human-pose-estimation/","section":"publication","summary":"We observe that human poses exhibit strong group-wise structural correlation and spatial coupling between keypoints due to the biological constraints of different body parts. This group-wise structural correlation can be explored to improve the accuracy and robustness of human pose estimation. In this work, we develop a self-constrained prediction-verification network to characterize and learn the structural correlation between keypoints during training. During the inference stage, the feedback information from the verification network allows us to perform further optimization of pose prediction, which significantly improves the performance of human pose estimation. Specifically, we partition the keypoints into groups according to the biological structure of human body. Within each group, the keypoints are further partitioned into two subsets, high-accuracy proximal keypoints and low-accuracy distal keypoints. We develop a self-constrained prediction-verification network to perform forward and backward predictions between these keypoint subsets. One fundamental challenge in pose estimation, as well as in generic prediction tasks, is that there is no mechanism for us to verify if the obtained pose estimation or prediction results are accurate or not, since the ground truth is not available. Once successfully learned, the verification network serves as an accuracy verification module for the forward pose prediction. During the inference stage, it can be used to guide the local optimization of the pose estimation results of low-accuracy keypoints with the self-constrained loss on high-accuracy keypoints as the objective function. Our extensive experimental results on benchmark MS COCO and CrowdPose datasets demonstrate that the proposed method can significantly improve the pose estimation results.","tags":["Human pose estimated","Self-constrained","Structural inference","Prediction optimization"],"title":"Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation","type":"publication"},{"authors":null,"categories":null,"content":"Context for the reader Human pose estimation aims to correctly detect and localize keypoints, i.e., human body joints or parts. It is one of the fundamental computer vision tasks which plays an important role in a variety of downstream applications, such as motion capture, activity recognition and person tracking. With the advent of the XR era, technologies such as virtual reality (VR), human-computer interaction (HCI), and augmented reality (AR) have gradually matured. As a core part in XR research, it is becoming more and more important to reach accurate estimation of human pose. However, due to free-style motion of human bodies, for complex scenes with person-person occlusions, large variations of appearance and texture, and cluttered backgrounds, pose estimation remains very challenging.\nAuthored researchers and journal details Chair Professor Zhihai He’s team from the Department of Electronic and Electrical Engineering (EEE) at the Southern University of Science and Technology (SUSTech) European Conference on Computer Vision (ECCV 2022), a top conference in computer vision with the proceedings published by Springer Science+Business Media, entitled “Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation.”\nFindings \u0026amp; Conclusion Prof. He’s team observed that human poses exhibit strong group-wise structural correlation and spatial coupling between keypoints due to the biological constraints of different body parts. Based on this observation, researchers propose to partition the body keypoints into structural groups. Within each group, the keypoints are further partitioned into two subsets, proximal keypoints with high estimation accuracy and low-accuracy distal keypoints. This group-wise structural correlation can be explored to improve the accuracy and robustness of human pose estimation. Figure 1. Illustration of the proposed idea of self-constrained inference optimization of structural groups for human pose estimation.\nOne fundamental challenge in pose estimation, as well as in generic prediction tasks, is that there is no mechanism for us to verify if the obtained pose estimation or prediction results are accurate or not, since the ground truth is not available. Prof. He’s team developed a self-constrained prediction-verification network to perform forward and backward predictions between these keypoint subsets. In Figure 2, This prediction-verification network with a forward-backward prediction loop learns the internal structural correlation between the proximal keypoints and the distal keypoint. The learning process is guided by the self-constraint loss. If the internal structural correlation is successfully learned, then the self-constraint loss generated by the forward and backward prediction loop should be small. This step is referred to as self-constrained learning. Figure2. The overall framework of the proposed network.\nOnce successfully learned, the verification network serves as an accuracy verification module for the forward pose prediction. During the inference stage, it can be used to guide the local optimization of the pose estimation results of low-accuracy keypoints with the self-constrained loss on high-accuracy keypoints as the objective function. This provides an effective mechanism to iteratively refine the prediction result based on the specific statistics of the test sample. This step is referred to as self-constrained optimization. Such feedback-based adaptive prediction will result in better generalization capability on the test sample.\nThe comparison and ablation experiments are performed on MS COCO dataset and CrowdPose dataset, both of which contain very challenging scenes for pose estimation such as multi-person poses of various body scales and occlusion patterns. The proposed method outperforms the current best by a large margin, up to 2.5% on MS COCO dataset. On CrowdPose dataset, it has improved the pose estimation accuracy by up to 1.5%, which is quite significantly. Visualization results in Figure 3 also demonstrate that the proposed method can significantly improve the pose estimation results. Figure 3. Three examples of refinement of predicted keypoints. The top row is the original estimation. The bottom row is the refined version by the proposed method.\nConclusion In this work, reaserchers partition the body keypoints into structural groups exploring the structural correlation within each group and develop a prediction-verification network to characterize structural correlation between them based on a self-constraint loss. A self-constrained optimization method was introduced which uses the learned verification network as a performance assessment module to optimize the pose estimation of distal keypoints during the inference stage where the ground truth is not available. The extensive experimental results on benchmark MS COCO datasets demonstrated that the proposed SCIO method is able to significantly improve the pose estimation …","date":1666483200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666483200,"objectID":"b5b26c7b4e66c05454d4eec1720c6227","permalink":"https://nkdailab.github.io/post/zhehan-kan-a-postgraduate-of-zhihai-he-research-group-of-the-department-of-electronics-in-occlusion-and-generalization-issue-in-human-pose-estimation-with-a-novel-self-constrained-approach/","publishdate":"2022-10-23T00:00:00Z","relpermalink":"/post/zhehan-kan-a-postgraduate-of-zhihai-he-research-group-of-the-department-of-electronics-in-occlusion-and-generalization-issue-in-human-pose-estimation-with-a-novel-self-constrained-approach/","section":"post","summary":"Zhehan Kan, a professional master's student in the Department of Electronic and Electrical Engineering, Southern University of Science and Technology (SUSTech), Class 21, has proposed a novel and effective self-constrained human pose estimation method in the field of human pose estimation, which solves the occlusion and generalisation problems in human pose estimation. The research results were presented at one of the top international computer vision conferences (ECCV_2022).  ","tags":null,"title":"Zhehan Kan, a postgraduate of Zhihai He Research Group of the Department of Electronics, in occlusion and generalization issue in human pose estimation with a novel self-constrained approach","type":"post"}]