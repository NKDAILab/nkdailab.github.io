
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"沈滢，南方科技大学电子系硕士生。\n研究方向 机器学习 音频事件检测 人类活动识别 毕业去向 深圳比亚迪股份有限公司高级底座工程师 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"369e00d80d9df9eff8dc96bc2ab22fb9","permalink":"https://nkdailab.github.io/author/%E6%B2%88%E6%BB%A2/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%B2%88%E6%BB%A2/","section":"authors","summary":"沈滢，南方科技大学电子系硕士生。\n研究方向 机器学习 音频事件检测 人类活动识别 毕业去向 深圳比亚迪股份有限公司高级底座工程师 ","tags":null,"title":"沈滢","type":"authors"},{"authors":null,"categories":null,"content":"已毕业。\n研究方向 计算机视觉 毕业去向 深圳亿方联创科技 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"cd103bb22e173e79aa979a12f93936a8","permalink":"https://nkdailab.github.io/author/%E9%99%88%E5%BA%86%E5%8D%97/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%99%88%E5%BA%86%E5%8D%97/","section":"authors","summary":"已毕业。\n研究方向 计算机视觉 毕业去向 深圳亿方联创科技 ","tags":null,"title":"陈庆南","type":"authors"},{"authors":null,"categories":null,"content":"我是陈烁硕，南方科技大学电子与电气工程系硕士三年级学生,由何志海教授指导。我的研究兴趣集中在机器学习模型在视觉任务中的泛化能力。\n研究方向 机器学习 计算机视觉 个人荣誉 (2021) 南方科技大学优秀毕业生 (2018-2020) 优秀学生奖学金 论文 Zhehan Kan, Shuoshuo Chen, Ce Zhang, Yushun Tang and Zhihai He, “Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. Yushun Tang, Ce Zhang, Heng Xu, Shuoshuo Chen, Jie Cheng, Luziwei Leng, Qinghai Guo, Zhihai He,“Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. Zhehan Kan, Shuoshuo Chen, Zeng Li and Zhihai He, “Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation,” in European Conference on Computer Vision (ECCV), 2022. 毕业去向 字节跳动 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"88a703101b1defbd6909ab126a326933","permalink":"https://nkdailab.github.io/author/%E9%99%88%E7%83%81%E7%A1%95/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%99%88%E7%83%81%E7%A1%95/","section":"authors","summary":"我是陈烁硕，南方科技大学电子与电气工程系硕士三年级学生,由何志海教授指导。我的研究兴趣集中在机器学习模型在视觉任务中的泛化能力。\n研究方向 机器学习 计算机视觉 个人荣誉 (2021) 南方科技大学优秀毕业生 (2018-2020) 优秀学生奖学金 论文 Zhehan Kan, Shuoshuo Chen, Ce Zhang, Yushun Tang and Zhihai He, “Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. Yushun Tang, Ce Zhang, Heng Xu, Shuoshuo Chen, Jie Cheng, Luziwei Leng, Qinghai Guo, Zhihai He,“Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. Zhehan Kan, Shuoshuo Chen, Zeng Li and Zhihai He, “Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation,” in European Conference on Computer Vision (ECCV), 2022. 毕业去向 字节跳动 ","tags":null,"title":"陈烁硕","type":"authors"},{"authors":null,"categories":null,"content":"陈玮铭，于2019年和2023年分别获得西安电子科技大学机械设计制造及其自动化专业学士学位和电子科学与技术专业硕士学位。目前在中国深圳南方科技大学攻读智能制造与机器人博士学位。研究方向包括机器学习、计算机视觉、多模态、AIGC、文本到图像的合成、扩散模型、目标检测和遥感。\n请访问他的个人主页了解更多信息 (https://www.weimingchen.net).\n研究方向 机器学习 计算机视觉 多模态 生成式人工智能 文本-图像生成 扩散模型 目标检测 遥感 项目 视觉标注平台(VAP) 陕西省重点产业创新链项目：自适应多域图像数据自动标注关键技术研究 发表成果 Weiming Chen, Bing Han, Xinbo Gao (2023). Oriented Ship Detection Based on Expansion Deformation Rotation Representation. 2023 3rd International Conference on Frontiers of Electronics, Information and Computation Technologies (ICFEICT): 621-627. DOI: 10.1109/ICFEICT59519.2023.00108. Zheng Yang, Bing Han, Weiming Chen, Xinbo Gao (2023). Learn to Encode Heterogeneous Data: A Heterogeneous Aware Network for Multi-Future Trajectory Prediction. International Joint Conference on Neural Networks (IJCNN), Queensland, Australia. Bing Han, Weiming Chen, Yang Zhou, Haitong Wang, Weixiong Zhao (2023). 光学遥感影像数据处理平台V1.0. 中国, 计算机软件著作权. 登记号: 2023SR0674142, 登记日期: 2023年6月15日. (已授权). Yang Zhou, Bing Han, Xinbo Gao, Zheng Yang, Weiming Chen (2023). Domain Adaptive Object Detection Based on Attention Mechanism and Cycle Domain Triplet Loss. ACTA AUTOMATICA SINICA. (published online). Bing Han, Weiming Chen, Ping Wang, Yannan Xiong, Yang Zhou, Weixiong Zhao (2023). 视觉影像标注平台V1.0. 中国, 计算机软件著作权. 登记号: 2023SR0432943, 登记日期: 2023年4月3日. (已授权). Zheng Yang, Bing Han, Weiming Chen, Xinbo Gao (2022). TMDiMP: Temporal memory guided discriminative tracker for UAV object tracking. Remote Sensing, 14(24): 6351. DOI: 10.3390/rs14246351. Weiming Chen, Bing Han, Zheng Yang, Xinbo Gao (2022). MSSDet: Multi-Scale Ship-Detection Framework in Optical Remote-Sensing Images and New Benchmark. Remote Sensing, 14(21): 5460. DOI: 10.3390/rs14215460. Bing Han, Weiming Chen, Xinbo Gao, Zheng Yang, Xiaoyue Huang (2022). 基于联合递归特征金字塔的多尺度目标检测方法. 中国, 发明专利. 申请号: 202211339440.0, 申请日期: 2022年10月29日. (在审查). Bing Han, Zheng Yang, Xinbo Gao, Weiming Chen, Xiaoyue Huang (2022). 基于序列感知与特征增强的无人机视角目标跟踪方法. 中国, 发明专利. 申请号: 202211194947.1, 申请日期: 2022年9月27日. (在审查). Bing Han, Zheng Yang, Xinbo Gao, Weiming Chen, Xiaoyue Huang (2022). 基于异构数据关联挖掘与度量学习的智能体轨迹预测方法. 中国, 发明专利. 申请号: 202211163069.7, 申请日期: 2022年9月23日. (在审查). Bing Han, Lu Gao, Zheng Yang, Weiming Chen, Xiaoyue Huang (2022). 基于点标注数据的病理图像分割方法. 中国, 发明专利. 申请号: 202210569641.3. 申请日期: 2022年5月24日. (在审查). ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"3fc097de1b4c25c640c60e6ff9c933c8","permalink":"https://nkdailab.github.io/author/%E9%99%88%E7%8E%AE%E9%93%AD/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%99%88%E7%8E%AE%E9%93%AD/","section":"authors","summary":"陈玮铭，于2019年和2023年分别获得西安电子科技大学机械设计制造及其自动化专业学士学位和电子科学与技术专业硕士学位。目前在中国深圳南方科技大学攻读智能制造与机器人博士学位。研究方向包括机器学习、计算机视觉、多模态、AIGC、文本到图像的合成、扩散模型、目标检测和遥感。\n请访问他的个人主页了解更多信息 (https://www.weimingchen.net).\n研究方向 机器学习 计算机视觉 多模态 生成式人工智能 文本-图像生成 扩散模型 目标检测 遥感 项目 视觉标注平台(VAP) 陕西省重点产业创新链项目：自适应多域图像数据自动标注关键技术研究 发表成果 Weiming Chen, Bing Han, Xinbo Gao (2023). Oriented Ship Detection Based on Expansion Deformation Rotation Representation. 2023 3rd International Conference on Frontiers of Electronics, Information and Computation Technologies (ICFEICT): 621-627. DOI: 10.1109/ICFEICT59519.2023.00108. Zheng Yang, Bing Han, Weiming Chen, Xinbo Gao (2023). Learn to Encode Heterogeneous Data: A Heterogeneous Aware Network for Multi-Future Trajectory Prediction. International Joint Conference on Neural Networks (IJCNN), Queensland, Australia. Bing Han, Weiming Chen, Yang Zhou, Haitong Wang, Weixiong Zhao (2023). 光学遥感影像数据处理平台V1.0. 中国, 计算机软件著作权. 登记号: 2023SR0674142, 登记日期: 2023年6月15日. (已授权). Yang Zhou, Bing Han, Xinbo Gao, Zheng Yang, Weiming Chen (2023). Domain Adaptive Object Detection Based on Attention Mechanism and Cycle Domain Triplet Loss. ACTA AUTOMATICA SINICA. (published online). Bing Han, Weiming Chen, Ping Wang, Yannan Xiong, Yang Zhou, Weixiong Zhao (2023). 视觉影像标注平台V1.0. 中国, 计算机软件著作权. 登记号: 2023SR0432943, 登记日期: 2023年4月3日. (已授权). Zheng Yang, Bing Han, Weiming Chen, Xinbo Gao (2022). TMDiMP: Temporal memory guided discriminative tracker for UAV object tracking. Remote Sensing, 14(24): 6351. DOI: 10.3390/rs14246351. Weiming Chen, Bing Han, Zheng Yang, Xinbo Gao (2022). MSSDet: Multi-Scale Ship-Detection Framework in Optical Remote-Sensing Images and New Benchmark. Remote Sensing, 14(21): 5460. DOI: 10.3390/rs14215460. Bing Han, Weiming Chen, Xinbo Gao, Zheng Yang, Xiaoyue Huang (2022). 基于联合递归特征金字塔的多尺度目标检测方法. 中国, 发明专利. 申请号: 202211339440.0, 申请日期: 2022年10月29日. (在审查). Bing Han, Zheng Yang, Xinbo Gao, Weiming Chen, Xiaoyue Huang (2022). 基于序列感知与特征增强的无人机视角目标跟踪方法. 中国, 发明专利. 申请号: 202211194947.1, 申请日期: 2022年9月27日. (在审查). Bing Han, Zheng Yang, Xinbo Gao, Weiming Chen, Xiaoyue Huang (2022). 基于异构数据关联挖掘与度量学习的智能体轨迹预测方法. 中国, 发明专利. 申请号: 202211163069.7, 申请日期: 2022年9月23日. (在审查). Bing Han, Lu Gao, Zheng Yang, Weiming Chen, Xiaoyue Huang (2022). 基于点标注数据的病理图像分割方法. 中国, 发明专利. 申请号: 202210569641.3. 申请日期: 2022年5月24日. (在审查). ","tags":null,"title":"陈玮铭","type":"authors"},{"authors":null,"categories":null,"content":"杜凡，南方科技大学电子与电气工程系硕士生。\n研究方向 VLA 具身智能 个人荣誉 (2025) 南方科技大学研究生特等奖学金\n(2025) 南方科技大学电子与电气工程系优秀毕业生\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"c6ce01b637b60f487c7f56ce82eed11d","permalink":"https://nkdailab.github.io/author/%E6%9D%9C%E5%87%A1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%9D%9C%E5%87%A1/","section":"authors","summary":"杜凡，南方科技大学电子与电气工程系硕士生。\n研究方向 VLA 具身智能 个人荣誉 (2025) 南方科技大学研究生特等奖学金\n(2025) 南方科技大学电子与电气工程系优秀毕业生\n","tags":null,"title":"杜凡","type":"authors"},{"authors":null,"categories":null,"content":"范昕华，中南大学生物医学工程系研究生。\n研究方向 语言信号处理 深度学习 个人荣誉 (2022) 天津市优秀学生 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"bac2091007ad984c34c485cfcb0927d4","permalink":"https://nkdailab.github.io/author/%E8%8C%83%E6%98%95%E5%8D%8E/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E8%8C%83%E6%98%95%E5%8D%8E/","section":"authors","summary":"范昕华，中南大学生物医学工程系研究生。\n研究方向 语言信号处理 深度学习 个人荣誉 (2022) 天津市优秀学生 ","tags":null,"title":"范昕华","type":"authors"},{"authors":null,"categories":null,"content":"高勇勇，南方科技大学电子系硕士研究生，大连海事大学智能科学与技术学士。主要研究方向为大语言模型，多模态大模型，具身智能。\n研究方向 大语言模型 多模态大模型 具身智能 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"db25c29556d5090637c6b72766064c18","permalink":"https://nkdailab.github.io/author/%E9%AB%98%E5%8B%87%E5%8B%87/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%AB%98%E5%8B%87%E5%8B%87/","section":"authors","summary":"高勇勇，南方科技大学电子系硕士研究生，大连海事大学智能科学与技术学士。主要研究方向为大语言模型，多模态大模型，具身智能。\n研究方向 大语言模型 多模态大模型 具身智能 ","tags":null,"title":"高勇勇","type":"authors"},{"authors":null,"categories":null,"content":"海博文，南方科技大学电子系硕士生。\n研究方向 机器学习 图像/视频压缩 推荐系统 工作经历 (2023) 深圳 Honor Device Company AI工程师实习生 论文 Xueting Hu, Ce Zhang, Yi Zhang, Bowen Hai, Ke Yu, Zhihai He, “Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation”. arXiv:2311.01034, 2023. 毕业去向 荣耀终端 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"73ca0e2397bbeed610dfe3b5ca81cfe3","permalink":"https://nkdailab.github.io/author/%E6%B5%B7%E5%8D%9A%E6%96%87/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%B5%B7%E5%8D%9A%E6%96%87/","section":"authors","summary":"海博文，南方科技大学电子系硕士生。\n研究方向 机器学习 图像/视频压缩 推荐系统 工作经历 (2023) 深圳 Honor Device Company AI工程师实习生 论文 Xueting Hu, Ce Zhang, Yi Zhang, Bowen Hai, Ke Yu, Zhihai He, “Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation”. arXiv:2311.01034, 2023. 毕业去向 荣耀终端 ","tags":null,"title":"海博文","type":"authors"},{"authors":null,"categories":null,"content":"阚哲涵，2023届南方科技大学硕士研究生。\n研究方向 机器学习 计算机视觉 多模态大语言模型 (MLLMs) 工作经历 (2022) 北京阿里巴巴达摩研究院XRLab研究实习生 (2023-至今) 深圳鹏程实验室研究实习生 个人荣誉 (2023) 南方科技大学优秀毕业生 个人活动 ECCV2022审稿人 智能技术学报2023审稿人 论文 Zhehan Kan, Xueting Hu, Zihan Liao, Ke Yu, Shuoshuo Chen, Zhihai He. Cross-Constrained Progressive Inference for 3D Hand Pose Estimation. Association for the Advancement of Artificial Intelligence (AAAI), 2024. Zhehan Kan, Shuoshuo Chen, Ce Zhang, Zhihai He. Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. Zhehan Kan, Shuoshuo Chen, Zeng Li, Zhihai He. Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation. European Conference on Computer Vision (ECCV ), 2022. 毕业去向 清华大学博士 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"1c2ab05a6ac8f52e4953fc68117b776d","permalink":"https://nkdailab.github.io/author/%E9%98%9A%E5%93%B2%E6%B6%B5/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%98%9A%E5%93%B2%E6%B6%B5/","section":"authors","summary":"阚哲涵，2023届南方科技大学硕士研究生。\n研究方向 机器学习 计算机视觉 多模态大语言模型 (MLLMs) 工作经历 (2022) 北京阿里巴巴达摩研究院XRLab研究实习生 (2023-至今) 深圳鹏程实验室研究实习生 个人荣誉 (2023) 南方科技大学优秀毕业生 个人活动 ECCV2022审稿人 智能技术学报2023审稿人 论文 Zhehan Kan, Xueting Hu, Zihan Liao, Ke Yu, Shuoshuo Chen, Zhihai He. Cross-Constrained Progressive Inference for 3D Hand Pose Estimation. Association for the Advancement of Artificial Intelligence (AAAI), 2024. Zhehan Kan, Shuoshuo Chen, Ce Zhang, Zhihai He. Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. Zhehan Kan, Shuoshuo Chen, Zeng Li, Zhihai He. Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation. European Conference on Computer Vision (ECCV ), 2022. 毕业去向 清华大学博士 ","tags":null,"title":"阚哲涵","type":"authors"},{"authors":null,"categories":null,"content":"何浚亦, 来自南方科技大学信息工程专业的本科生。目前从事与机器学习相关的学习和研究，专注于在这个不断发展的领域学习知识和技能。\n研究方向 机器学习 预训练视觉-语言模型 个人荣誉 南方科技大学2022年优秀学生奖学金二等奖 毕业去向 卡耐基梅隆大学机器学习硕士 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"655595ffef031edfcb28c52a4210876c","permalink":"https://nkdailab.github.io/author/%E4%BD%95%E6%B5%9A%E4%BA%A6/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E4%BD%95%E6%B5%9A%E4%BA%A6/","section":"authors","summary":"何浚亦, 来自南方科技大学信息工程专业的本科生。目前从事与机器学习相关的学习和研究，专注于在这个不断发展的领域学习知识和技能。\n研究方向 机器学习 预训练视觉-语言模型 个人荣誉 南方科技大学2022年优秀学生奖学金二等奖 毕业去向 卡耐基梅隆大学机器学习硕士 ","tags":null,"title":"何浚亦","type":"authors"},{"authors":null,"categories":null,"content":"何志海，南方科技大学电子与电气工程系讲席教授， IEEE Fellow (2015)。2021年6月全职回国前任美国密苏里大学电子工程系讲席教授。研究方向包括生成式视觉AI、多模态大模型推理与控制优化、健康守护机器人、AI 智能体。2019-2025年连续入选斯坦福大学全球顶级科学家终身科学影响力排行榜。在工业AI检测、AI居家医养领域具有丰富的科研成果产业化经验。作为负责人，承担了国家基金委重点项目和国家自然科学基金天元数学与智能+交叉重点专项。 荣获IEEE TCSVT国际期刊最佳论文、中国人工智能学会吴文俊人工智能技术发明奖等奖项。\n研究方向 生成式视觉AI 多模态大模型推理与控制优化 健康守护机器人 AI 智能体 招聘信息 何志海课题组正在招聘生成式视觉AI、多模态大模型推理与控制优化、健康守护机器人、AI 智能体等相关专业博士后、博士等，同时欢迎来自国内外大学及科研机构的访问学者和交流学生，有意加入者请将简历发送至：hezh@sustech.edu.cn。联系地址：广东省深圳市南山区学苑大道1088号南方科技大学工学院南楼434，电话：+86 13602642426\n工作经历 (2021 - 至今) 南方科技大学电子系\t讲席教授研究内容：智能信息物理系统、深度学习、复杂动态系统的人工智能方法 (2013 - 2021) 美国密苏里大学\t终身正教授研究内容：智能信息物理系统、深度学习 (2009 - 2013) 美国密苏里大学\t终身副教授研究内容：信息物理系统、机器视觉、机器学习、智能制造 (2003 - 2009) 美国密苏里大学\t助理教授研究内容：多媒体网络通信、视觉感应器网络、人工智能物联网智慧养老、野生动物生态监测网络 (2001 - 2003) 美国新泽西普林斯顿大卫-索纳福研究中心\t研究工程师主要科研、技术工作：研究和开发多媒体网络通信系统；无人机、无人车的机器视觉技术和系统 个人荣誉 (2025) 2024年度吴文俊人工智能科学技术奖技术发明二等奖，中国人工智能学会 (2021) 深圳市海外高层次人才 (2017) 密苏⾥州荣誉⼯程⾼级教师研究奖 (2015) IEEE Fellow (2010) IEEE TCSVT 杰出副主编奖 (2009) 杰出青年教师研究和创意活动奖 (2008) 密苏里荣誉工程青年教师研究奖 (2004) SPIE VCIP 青年研究员奖 (2002) IEEE TCSVT 最佳论文奖 兼职活动 (2021.01~至今) 国际期刊IEEE Transactions on Circuits and Systems for Video Technology 编委 (2009.01~2011.01)\t国际期刊IEEE Transactions on Circuits and Systems for Video Technology 编委 (2016.08 – 至今) 深圳深视创新科技有限公司\t首席科学家（兼职） (2009 – 2013) 国际期刊 IEEE Transactions on Multimedia 编委 (2009.06 – 至今) Elsevier Journal of Visual Communication and Image Representation 编委 (2008) 国际期刊 IEEE Transactions on Circuits and Systems for Video Technologies 客座编辑 (2005) 国际无线多媒体会议（International Symposium on Wireless Multimedia, Hawaii）副主席 (2007) IEEE 视频处理技术委员会委员 项目 国家自然科学基金（NSFC）重点项目，基于多智能体协同学习的屏幕混合内容编码理论与方法，项目负责人，2024-01至2028-12 国家自然科学基金专项基金项目-天元基金，非侵入式血流动力学新型高分辨率成像方法与理论研究，共同项目负责人，2025-01至2026-12 美国国家科学基金（NSF），CPS: SenSE: Wearable hybrid biochemical and biophysical sensing systems integrated with robust artificial, 项目共同负责人Co-PI, 项目总额：73.8万美元，2020-09 至 2021-01 美国国家科学基金（NSF），CPS: Synergy: Cyber-Physical Sensing, Modeling, and Control with Augmented Reality for Smart Manufacturing Workforce Training and Operations Management National Science Foundation, 项目负责人PI, 项目总额：19.6万美元，2017-02 至 2020-01 美国国家科学基金（NSF），NSF-USIgnite: Focus Area 1: A GENI-Enabled Virtual Reality System for Immersive Online Social Learning of Youth with Autism Spectrum Disorders，项目负责人PI, 项目总额：59.9万美元，2017-02 至 2020-01 美国国家科学基金（NSF），CyberSEES: Collaborative Research: Cyber-infrastructure and Technologies to Support Large-Scale Wildlife Monitoring and Research for Wildlife and Ecology Sustainability, 项目总额：68.9万美元，2015-11 至 2018-10 美国国家科学基金（NSF），CPS: Synergy: Collaborative Research: Cyber-Physical Sensing, Modeling, and Control for Large-Scale Wastewater Reuse and Algal Biomass Production，项目负责人PI, 项目总额：67万美元，2015-09 至 2018-08 美国国家科学基金（NSF），Collaborative Research: ABI Innovation: Computational and Informatics Tools for Supporting Collaborative Wildlife Monitoring and Research，项目负责人PI, 项目总额： 89.8万美元，2011-08 至 2015-07 美国国家科学基金（NSF），Collaborative Research : Processes Determining Abundance of Terrestrial Wildlife Communities Across Large Scales National Science Foundation, 项目负责人PI, 项目总额：37.4万美元，2011-01 至 2014-05 美国陆军LWI研究院，Suspicious Activity Analysis for Force Protection, 项目负责人PI, 项目总额：48.9万美元，2009-09至 2010-08 美国国家科学基金（NSF），CPS: Medium: Active Heterogeneous Sensing for Fall Detection and Fall Risk Assessment, 项目共同负责人Co-PI, 项目总额：141万美元，2009-01 至 2012-08 美国国家科学基金（NSF），HCC: Elder-Centered Recognition Technology for the Assessment of Physical Function, 项目共同负责人Co-PI, 项目总额：91.2万美元，2007-09 至 2011-08 美国国家卫生研究院（NIH），Automated Activity Analysis for Eldercare, 项目负责人PI, 项目总额：28.8万美元，2007-07 至 2009-06 美国国家科学基金（NSF），SIRG: Collaborative Research : DeerNet – Wireless sensor networks for wildlife behavior monitoring, interaction modeling, and disease tracking, 项目负责人PI, 项目总额：48万美元，2005-09 至 2009-08 代表性论文 Yi Zhang, Chun-Wun Cheng, Junyi He, Zhihai He, Carola-Bibiane Schönlieb, Yuyan Chen, Angelica I Aviles-Rivero. “Cross-Modal Few-Shot Learning with Second-Order Neural Ordinary Differential Equations.\u0026#34;[J] AAAI Conference on Artificial Intelligence (AAAI2025). (Oral paper). Siqi Wu, Yinda Chen, Dong Liu, Zhihai He. \u0026#34; Conditional Latent Coding with Learnable Synthesized Reference for Deep Image Compression.\u0026#34;[J] AAAI Conference on Artificial Intelligence (AAAI2025). (Oral paper). Yi Zhang, Ke Yu, Siqi Wu, Zhihai He. “Conceptual Codebook Learning for Vision-Language Models”[J]. European Conference on Computer Vision (ECCV 2024). Tushun Tang, Shuoshuo Chen, Zhihe Lu, Xinchao Wang, Zhihai He. “Dual-Path Adversarial Lifting for Domain Shift Correction in Online Test-time Adaptation”[J]. European Conference on Computer Vision (ECCV 2024). Yi Zhang, Ke Yu, Angelica I Aviles-Rivero, Jiyuan Jia, Yushun Tang, Zhihai He. “Training-Free Feature Reconstruction with Sparse Optimization for Vision-Language Models”[J]. Proceedings of the 32nd ACM International Conference on Multimedia, 2024. 4387-4396 Yushun Tang, Shuoshuo Chen, Jiyuan Jia, Yi Zhang, Zhihai He. “Domain-Conditioned Transformer for Fully …","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"e636e7db9f55c48b97b93fffc09401a8","permalink":"https://nkdailab.github.io/author/%E4%BD%95%E5%BF%97%E6%B5%B7/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E4%BD%95%E5%BF%97%E6%B5%B7/","section":"authors","summary":"何志海，南方科技大学电子与电气工程系讲席教授， IEEE Fellow (2015)。2021年6月全职回国前任美国密苏里大学电子工程系讲席教授。研究方向包括生成式视觉AI、多模态大模型推理与控制优化、健康守护机器人、AI 智能体。2019-2025年连续入选斯坦福大学全球顶级科学家终身科学影响力排行榜。在工业AI检测、AI居家医养领域具有丰富的科研成果产业化经验。作为负责人，承担了国家基金委重点项目和国家自然科学基金天元数学与智能+交叉重点专项。 荣获IEEE TCSVT国际期刊最佳论文、中国人工智能学会吴文俊人工智能技术发明奖等奖项。\n研究方向 生成式视觉AI 多模态大模型推理与控制优化 健康守护机器人 AI 智能体 招聘信息 何志海课题组正在招聘生成式视觉AI、多模态大模型推理与控制优化、健康守护机器人、AI 智能体等相关专业博士后、博士等，同时欢迎来自国内外大学及科研机构的访问学者和交流学生，有意加入者请将简历发送至：hezh@sustech.edu.cn。联系地址：广东省深圳市南山区学苑大道1088号南方科技大学工学院南楼434，电话：+86 13602642426\n工作经历 (2021 - 至今) 南方科技大学电子系\t讲席教授研究内容：智能信息物理系统、深度学习、复杂动态系统的人工智能方法 (2013 - 2021) 美国密苏里大学\t终身正教授研究内容：智能信息物理系统、深度学习 (2009 - 2013) 美国密苏里大学\t终身副教授研究内容：信息物理系统、机器视觉、机器学习、智能制造 (2003 - 2009) 美国密苏里大学\t助理教授研究内容：多媒体网络通信、视觉感应器网络、人工智能物联网智慧养老、野生动物生态监测网络 (2001 - 2003) 美国新泽西普林斯顿大卫-索纳福研究中心\t研究工程师主要科研、技术工作：研究和开发多媒体网络通信系统；无人机、无人车的机器视觉技术和系统 个人荣誉 (2025) 2024年度吴文俊人工智能科学技术奖技术发明二等奖，中国人工智能学会 (2021) 深圳市海外高层次人才 (2017) 密苏⾥州荣誉⼯程⾼级教师研究奖 (2015) IEEE Fellow (2010) IEEE TCSVT 杰出副主编奖 (2009) 杰出青年教师研究和创意活动奖 (2008) 密苏里荣誉工程青年教师研究奖 (2004) SPIE VCIP 青年研究员奖 (2002) IEEE TCSVT 最佳论文奖 兼职活动 (2021.01~至今) 国际期刊IEEE Transactions on Circuits and Systems for Video Technology 编委 (2009.01~2011.01)\t国际期刊IEEE Transactions on Circuits and Systems for Video Technology 编委 (2016.08 – 至今) 深圳深视创新科技有限公司\t首席科学家（兼职） (2009 – 2013) 国际期刊 IEEE Transactions on Multimedia 编委 (2009.06 – 至今) Elsevier Journal of Visual Communication and Image Representation 编委 (2008) 国际期刊 IEEE Transactions on Circuits and Systems for Video Technologies 客座编辑 (2005) 国际无线多媒体会议（International Symposium on Wireless Multimedia, Hawaii）副主席 (2007) IEEE 视频处理技术委员会委员 项目 国家自然科学基金（NSFC）重点项目，基于多智能体协同学习的屏幕混合内容编码理论与方法，项目负责人，2024-01至2028-12 国家自然科学基金专项基金项目-天元基金，非侵入式血流动力学新型高分辨率成像方法与理论研究，共同项目负责人，2025-01至2026-12 美国国家科学基金（NSF），CPS: SenSE: Wearable hybrid biochemical and biophysical sensing systems integrated with robust artificial, 项目共同负责人Co-PI, 项目总额：73.8万美元，2020-09 至 2021-01 美国国家科学基金（NSF），CPS: Synergy: Cyber-Physical Sensing, Modeling, and Control with Augmented Reality for Smart Manufacturing Workforce Training and Operations Management National Science Foundation, 项目负责人PI, 项目总额：19.6万美元，2017-02 至 2020-01 美国国家科学基金（NSF），NSF-USIgnite: Focus Area 1: A GENI-Enabled Virtual Reality System for Immersive Online Social Learning of Youth with Autism Spectrum Disorders，项目负责人PI, 项目总额：59.9万美元，2017-02 至 2020-01 美国国家科学基金（NSF），CyberSEES: Collaborative Research: Cyber-infrastructure and Technologies to Support Large-Scale Wildlife Monitoring and Research for Wildlife and Ecology Sustainability, 项目总额：68.9万美元，2015-11 至 2018-10 美国国家科学基金（NSF），CPS: Synergy: Collaborative Research: Cyber-Physical Sensing, Modeling, and Control for Large-Scale Wastewater Reuse and Algal Biomass Production，项目负责人PI, 项目总额：67万美元，2015-09 至 2018-08 美国国家科学基金（NSF），Collaborative Research: ABI Innovation: Computational and Informatics Tools for Supporting Collaborative Wildlife Monitoring and Research，项目负责人PI, 项目总额： 89.8万美元，2011-08 至 2015-07 美国国家科学基金（NSF），Collaborative Research : Processes Determining Abundance of Terrestrial Wildlife Communities Across Large Scales National Science Foundation, 项目负责人PI, 项目总额：37.4万美元，2011-01 至 2014-05 美国陆军LWI研究院，Suspicious Activity Analysis for Force Protection, 项目负责人PI, 项目总额：48.9万美元，2009-09至 2010-08 美国国家科学基金（NSF），CPS: Medium: Active Heterogeneous Sensing for Fall Detection and Fall Risk Assessment, 项目共同负责人Co-PI, 项目总额：141万美元，2009-01 至 2012-08 美国国家科学基金（NSF），HCC: Elder-Centered Recognition Technology for the Assessment of Physical Function, 项目共同负责人Co-PI, 项目总额：91.2万美元，2007-09 至 2011-08 美国国家卫生研究院（NIH），Automated Activity Analysis for Eldercare, 项目负责人PI, 项目总额：28.8万美元，2007-07 至 2009-06 美国国家科学基金（NSF），SIRG: Collaborative Research : DeerNet – Wireless sensor networks for wildlife behavior monitoring, interaction modeling, and disease tracking, 项目负责人PI, 项目总额：48万美元，2005-09 至 2009-08 代表性论文 Yi Zhang, Chun-Wun Cheng, Junyi He, Zhihai He, Carola-Bibiane Schönlieb, Yuyan Chen, Angelica I Aviles-Rivero. “Cross-Modal Few-Shot Learning with Second-Order Neural Ordinary Differential Equations.\"[J] AAAI Conference on Artificial Intelligence (AAAI2025). (Oral paper). Siqi Wu, Yinda Chen, Dong Liu, Zhihai He. \" Conditional Latent Coding with Learnable Synthesized Reference for Deep Image Compression.\"[J] AAAI Conference on Artificial Intelligence (AAAI2025). (Oral paper). Yi Zhang, Ke Yu, Siqi Wu, Zhihai He. “Conceptual Codebook Learning for Vision-Language Models”[J]. European Conference on Computer Vision (ECCV 2024). Tushun Tang, Shuoshuo Chen, Zhihe Lu, Xinchao Wang, Zhihai He. “Dual-Path Adversarial Lifting for Domain Shift Correction in Online Test-time Adaptation”[J]. European Conference on Computer Vision (ECCV 2024). Yi Zhang, Ke Yu, Angelica I Aviles-Rivero, Jiyuan Jia, Yushun Tang, Zhihai He. “Training-Free Feature Reconstruction with Sparse Optimization for Vision-Language Models”[J]. Proceedings of the 32nd ACM International Conference on Multimedia, 2024. 4387-4396 Yushun Tang, Shuoshuo Chen, Jiyuan Jia, Yi Zhang, Zhihai He. “Domain-Conditioned Transformer for Fully Test-time Adaptation.\"[J] Proceedings of the 32nd ACM International Conference on Multimedia, 2024. 6260-6269. Zhehan Kan, Shuoshuo Chen, Ce Zhang, Yushun Tang, Zhihai He, “Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation.” 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5537-5546, 17-24 June 2023. Yushun Tang, Ce Zhang, Heng Xu, Shuoshuo Chen, Jie Cheng, Luziwei Leng, Qinghai Guo, Zhihai He, “Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation.” In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3728-3738. 2023.17-24 June 2023. Zhehan Kan, Shuoshuo Chen, Zeng Li, Zhihai He, “Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation.” Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part V. Cham: Springer Nature Switzerland, 2022. Shichao Kan, Yigang Cen, and Zhihai He, Relative Order Analysis and Optimization for Unsupervised Learning of Discriminative Features, IEEE Proceedings of Computer Vision and Pattern Recognition (CVPR), June 2021. Hao Sun and Zhihai He, “Reciprocal learning networks for human trajectory prediction,” IEEE Proceedings of Computer Vision and Pattern Recognition (CVPR), June 2020 (Oral paper). Yang Li, Zhiqun Zhao, Yigang Cen, and Zhihai He, Snowball: Iterative Model Evolution and Confident Sample Discovery for Semi-Supervised Learning on Very Small Labeled Datasets, accepted by IEEE Transactions on Multimedia, May 2020. Jianhe Yuan and Zhihai He, “Ensemble generative cleaning for adversarial defense of deep neural networks,” IEEE Proceedings of Computer Vision and Pattern Recognition (CVPR), June 2020. Kan, Shichao, Yigang Cen, Zhihai He, Zhi Zhang, Linna Zhang, and Yanhong Wang. “Supervised deep feature embedding with handcrafted feature.” IEEE Transactions on Image Processing 28, no. 12 (2019): 5809-5823. Zhi Zhang, Zhihai He, and Wenmin Cao, Animal Detection from Highly Cluttered Natural Scenes Using Spatiotemporal Object Region Proposals and Patch Verification, IEEE Transaction on Multimedia, Vol. 18, No. 10, pp. 2079-2092, July 2016. Chenglin Li, Hongkai Xiong, Junni Zou, Zhihai He, “Joint Source and Flow Optimization for Scalable Video Multi-rate Multicast over Hybrid Wired/Wireless Coded Networks”, IEEE Transactions on Circuits and Systems for Video Technology, Vol. 21, No. 5, pp. 550-564, May 2011. Zhou, Zhongna, Xi Chen, Yu-Chia Chung, Zhihai He, Tony X. Han, and James M. Keller. “Activity analysis, summarization, and visualization for indoor human activity monitoring.” IEEE transactions on circuits and systems for video technology 18, no. 11 (2008): 1489-1498. He, Zhihai, and Sanjit K. Mitra. “A linear source model and a unified rate control algorithm for DCT video coding.” IEEE transactions on Circuits and Systems for Video Technology 12, no. 11 (2002): 970-982. He, Zhihai, Jianfei Cai, and Chang Wen Chen. “Joint source channel rate-distortion analysis for adaptive mode selection and rate control in wireless video coding.” IEEE Transactions on circuits and systems for video technology 12, no. 6 (2002): 511-523. He, Zhihai, and Sanjit K. Mitra. “A unified rate-distortion analysis framework for transform coding.” IEEE Transactions on Circuits and Systems for Video Technology 11, no. 12 (2001): 1221-1236. (Best Paper) ","tags":null,"title":"何志海","type":"authors"},{"authors":null,"categories":null,"content":"胡雪婷，南方科技大学工程学院电子与电气工程系硕士研究生，本科毕业于中国地质大学武汉自动化学院。主要研究领域包括大规模视觉语言模型、非分布检测等。\n研究方向 视觉语言模型 计算机视觉 小样本学习 个人荣誉 (2019) 中国地质大学优秀学生校长奖学金 论文 Xueting Hu, Ce Zhang, Yi Zhang, Ke Yu, Zhihai He. Learn to Adapt CLIP for Few-Shot Monocular Depth Estimation. IEEE Winter Conference on Applications of Computer Vision (WACV), 2024. Yi Zhang, Ce Zhang, Xueting Hu, Zhihai He. Unsupervised Prototype Adapter for Vision-Language Models. The 6 th Chinese Conference on Pattern Recognition and Computer Vision (PRCV), 2023. Guochao Zhang, Xueting Hu, Yantao Wei, Weijia Cao, Huang Yao, Xueyang Zhang, Keyi Song. Nonlocal Correntropy Matrix Representation for Hyperspectral Image Classification. IEEE Geoscience and Remote Sensing Letters (GRSL), 2023. 毕业去向 华为技术有限公司 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"dc7132d8d70c74e65910ba985df3ce4d","permalink":"https://nkdailab.github.io/author/%E8%83%A1%E9%9B%AA%E5%A9%B7/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E8%83%A1%E9%9B%AA%E5%A9%B7/","section":"authors","summary":"胡雪婷，南方科技大学工程学院电子与电气工程系硕士研究生，本科毕业于中国地质大学武汉自动化学院。主要研究领域包括大规模视觉语言模型、非分布检测等。\n研究方向 视觉语言模型 计算机视觉 小样本学习 个人荣誉 (2019) 中国地质大学优秀学生校长奖学金 论文 Xueting Hu, Ce Zhang, Yi Zhang, Ke Yu, Zhihai He. Learn to Adapt CLIP for Few-Shot Monocular Depth Estimation. IEEE Winter Conference on Applications of Computer Vision (WACV), 2024. Yi Zhang, Ce Zhang, Xueting Hu, Zhihai He. Unsupervised Prototype Adapter for Vision-Language Models. The 6 th Chinese Conference on Pattern Recognition and Computer Vision (PRCV), 2023. Guochao Zhang, Xueting Hu, Yantao Wei, Weijia Cao, Huang Yao, Xueyang Zhang, Keyi Song. Nonlocal Correntropy Matrix Representation for Hyperspectral Image Classification. IEEE Geoscience and Remote Sensing Letters (GRSL), 2023. 毕业去向 华为技术有限公司 ","tags":null,"title":"胡雪婷","type":"authors"},{"authors":null,"categories":null,"content":"胡志炜，南方科技大学电子系硕士研究生，广东工业大学信息工程学士。主要研究方向为生成式AI、计算机视觉等。\n研究方向 计算机视觉 生成式AI 个人荣誉 （2025）广东工业大学优秀毕业生 （2023-2024）本科生国家奖学金 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"894e522bd18b5b25a629f1ef29e46dc9","permalink":"https://nkdailab.github.io/author/%E8%83%A1%E5%BF%97%E7%82%9C/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E8%83%A1%E5%BF%97%E7%82%9C/","section":"authors","summary":"胡志炜，南方科技大学电子系硕士研究生，广东工业大学信息工程学士。主要研究方向为生成式AI、计算机视觉等。\n研究方向 计算机视觉 生成式AI 个人荣誉 （2025）广东工业大学优秀毕业生 （2023-2024）本科生国家奖学金 ","tags":null,"title":"胡志炜","type":"authors"},{"authors":null,"categories":null,"content":"黄彦基，南方科技大学电子系硕士研究生，深圳大学电子信息工程学士。主要研究方向为自主具身智能、实时多模态数字人、数字信号压缩编码。\n研究方向 自主具身智能 实时多模态数字人 数字信号压缩编码 个人荣誉 (2025) 深圳大学荣誉学士学位 (2025) 深圳大学校级优秀毕业生 (2024) 国家励志奖学金 (2024) 深圳大学本科生最高荣誉奖学金荔园卓越之星 (2024) 深圳大学“湾区引领卓越青年团”暨第二届香港特别行政区政府香港保安局青年制服团队领袖论坛成员 (2024) 深圳大学“助梦翱翔”日本短期公费访学成员 (2024) 全国大学生集成电路创新创业大赛华南赛区二等奖 (2023) 全国大学生电子设计竞赛全国二等奖 (2023) 全国大学生集成电路创新创业大赛华南赛区三等奖 项目成果 国家软件著作权,基于多模态可扩展框架的激光雷达点云压缩编码系统 软著登字15142039号 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"ff41c5f7e3cd05d85f7e0c722ef5eb04","permalink":"https://nkdailab.github.io/author/%E9%BB%84%E5%BD%A6%E5%9F%BA/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%BB%84%E5%BD%A6%E5%9F%BA/","section":"authors","summary":"黄彦基，南方科技大学电子系硕士研究生，深圳大学电子信息工程学士。主要研究方向为自主具身智能、实时多模态数字人、数字信号压缩编码。\n研究方向 自主具身智能 实时多模态数字人 数字信号压缩编码 个人荣誉 (2025) 深圳大学荣誉学士学位 (2025) 深圳大学校级优秀毕业生 (2024) 国家励志奖学金 (2024) 深圳大学本科生最高荣誉奖学金荔园卓越之星 (2024) 深圳大学“湾区引领卓越青年团”暨第二届香港特别行政区政府香港保安局青年制服团队领袖论坛成员 (2024) 深圳大学“助梦翱翔”日本短期公费访学成员 (2024) 全国大学生集成电路创新创业大赛华南赛区二等奖 (2023) 全国大学生电子设计竞赛全国二等奖 (2023) 全国大学生集成电路创新创业大赛华南赛区三等奖 项目成果 国家软件著作权,基于多模态可扩展框架的激光雷达点云压缩编码系统 软著登字15142039号 ","tags":null,"title":"黄彦基","type":"authors"},{"authors":null,"categories":null,"content":"纪俊阳是清华大学电子与信息工程专业的硕士(2023)，准备从2024年开始攻读清华大学和南方科技大学的联合博士学位。\n研究方向 计算机视觉 机器学习 个人荣誉 (2021) 全国研究生数学建模三等奖 (2021) 清华深圳国际研究生院(SIGS)二等奖学金 (2019, 2017) 哈尔滨工业大学二等奖学金 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"b73ee2e46bf7ee73263f9be8cb10b2b1","permalink":"https://nkdailab.github.io/author/%E7%BA%AA%E4%BF%8A%E9%98%B3/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E7%BA%AA%E4%BF%8A%E9%98%B3/","section":"authors","summary":"纪俊阳是清华大学电子与信息工程专业的硕士(2023)，准备从2024年开始攻读清华大学和南方科技大学的联合博士学位。\n研究方向 计算机视觉 机器学习 个人荣誉 (2021) 全国研究生数学建模三等奖 (2021) 清华深圳国际研究生院(SIGS)二等奖学金 (2019, 2017) 哈尔滨工业大学二等奖学金 ","tags":null,"title":"纪俊阳","type":"authors"},{"authors":null,"categories":null,"content":"研究方向 机器学习 计算机视觉 毕业去向 美团 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"e9ce83e4c239bb1ff75521424a1e230f","permalink":"https://nkdailab.github.io/author/%E8%B4%BE%E7%BA%AA%E6%BA%90/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E8%B4%BE%E7%BA%AA%E6%BA%90/","section":"authors","summary":"研究方向 机器学习 计算机视觉 毕业去向 美团 ","tags":null,"title":"贾纪源","type":"authors"},{"authors":null,"categories":null,"content":"李静，中南大学生物医学工程系研究生。\n研究方向 语言信号处理 深度学习 个人荣誉 (2022) 优秀团员 (2023) 优秀学生 论文 Zhongchao Huang, Jing Li, Hongwen Zhong, Bo Tian*. Nucleic acid amplification strategies for volume-amplified magnetic nanoparticle detection assay[J].Frontiers in Bioengineering and Biotechnology, 2022. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"af6a13032e1132d710d0901d434d5b1f","permalink":"https://nkdailab.github.io/author/%E6%9D%8E%E9%9D%99/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%9D%8E%E9%9D%99/","section":"authors","summary":"李静，中南大学生物医学工程系研究生。\n研究方向 语言信号处理 深度学习 个人荣誉 (2022) 优秀团员 (2023) 优秀学生 论文 Zhongchao Huang, Jing Li, Hongwen Zhong, Bo Tian*. Nucleic acid amplification strategies for volume-amplified magnetic nanoparticle detection assay[J].Frontiers in Bioengineering and Biotechnology, 2022. ","tags":null,"title":"李静","type":"authors"},{"authors":null,"categories":null,"content":"李若怡，南方科技大学电子与电气工程系硕士研究生，主要从事人工智能的实验室研究。\n研究方向 开放世界机器人自主感知 工作经历 (2023) (实习) 北京快手科技有限公司 - 客户端开发工程师 (2023) (实习) 华为技术有限公司 - 通用软件开发工程师 个人荣誉 2022年南方科技大学优秀共青团干部 个人活动 曾任南方科技大学电子与电气工程系共青团支部书记 毕业去向 中国人寿 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"32663ab7a2991370bbff0f3e0cb281de","permalink":"https://nkdailab.github.io/author/%E6%9D%8E%E8%8B%A5%E6%80%A1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%9D%8E%E8%8B%A5%E6%80%A1/","section":"authors","summary":"李若怡，南方科技大学电子与电气工程系硕士研究生，主要从事人工智能的实验室研究。\n研究方向 开放世界机器人自主感知 工作经历 (2023) (实习) 北京快手科技有限公司 - 客户端开发工程师 (2023) (实习) 华为技术有限公司 - 通用软件开发工程师 个人荣誉 2022年南方科技大学优秀共青团干部 个人活动 曾任南方科技大学电子与电气工程系共青团支部书记 毕业去向 中国人寿 ","tags":null,"title":"李若怡","type":"authors"},{"authors":null,"categories":null,"content":"李有明，中南大学生物医学工程系硕士研究生。\n研究方向 计算机视觉 机器学习 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"25abcc38122f629c219d75762d66cd6a","permalink":"https://nkdailab.github.io/author/%E6%9D%8E%E6%9C%89%E6%98%8E/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%9D%8E%E6%9C%89%E6%98%8E/","section":"authors","summary":"李有明，中南大学生物医学工程系硕士研究生。\n研究方向 计算机视觉 机器学习 ","tags":null,"title":"李有明","type":"authors"},{"authors":null,"categories":null,"content":"廖博闻，南方科技大学电子系硕士研究生，汕头大学计算机科学与技术学士。主要研究方向为计算机视觉、机器学习。\n研究方向 计算机视觉 机器学习 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"fc1adf4ec003db22daa0515ee8ac571d","permalink":"https://nkdailab.github.io/author/%E5%BB%96%E5%8D%9A%E9%97%BB/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%BB%96%E5%8D%9A%E9%97%BB/","section":"authors","summary":"廖博闻，南方科技大学电子系硕士研究生，汕头大学计算机科学与技术学士。主要研究方向为计算机视觉、机器学习。\n研究方向 计算机视觉 机器学习 ","tags":null,"title":"廖博闻","type":"authors"},{"authors":null,"categories":null,"content":"刘启凡，南方科技大学电子与电气工程系博士后，主要从事人工智能方面研究。\n研究方向 机器学习 计算机视觉 小样本学习 大模型 论文 Liu Q, Zhao Z, Cao W, et al. Residual proportion multilayer perceptron for few-shot classification[C]//2021 IEEE International Conference on Multimedia \u0026amp; Expo Workshops (ICMEW). IEEE, 2021: 1-6. Liu Q, Cao W. Geometric algebra graph neural network for cross-domain few-shot classification[J]. Applied Intelligence, 2022, 52(11): 12422-12435. Zhao Z, Liu Q, Cao W, et al. Self-guided information for few-shot classification[J]. Pattern Recognition, 2022, 131: 108880. Liu Q, Chen Y, Cao W. Dual-domain reciprocal learning design for few-shot image classification[J]. Neural Computing and Applications, 2023: 1-14. Liu Q, Cao W, He Z. Cycle Optimization Metric Learning for Few-Shot Classification[J]. Pattern Recognition, 2023: 109468. Zhang R, Liu Q. Learning with few samples in deep learning for image classification, a mini-review[J]. Frontiers in Computational Neuroscience, 2023. 专利 车辆检测方法、装置及计算机可读存储介质，何志权，刘启凡，曹文明，专利号：ZL 2019 1 0029834.8 基于小波变换的渐进式深度卷积网络图像识别方法及装置，何志权，曹文明，刘启凡，专利号：ZL 2019 1 0783600.2 图像数据的压缩传输方法、系统和计算机可读存储介质，何志权，曹文明，刘启凡，专利号：ZL 2019 1 0811971.7 一种基于深度神经网络的OCR识别方法及装置，曹文明，刘启凡，何志权，专利号：ZL 2019 1 0904514.2 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"6188ff147fb318423f3e4157cf21a324","permalink":"https://nkdailab.github.io/author/%E5%88%98%E5%90%AF%E5%87%A1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%88%98%E5%90%AF%E5%87%A1/","section":"authors","summary":"刘启凡，南方科技大学电子与电气工程系博士后，主要从事人工智能方面研究。\n研究方向 机器学习 计算机视觉 小样本学习 大模型 论文 Liu Q, Zhao Z, Cao W, et al. Residual proportion multilayer perceptron for few-shot classification[C]//2021 IEEE International Conference on Multimedia \u0026 Expo Workshops (ICMEW). IEEE, 2021: 1-6. Liu Q, Cao W. Geometric algebra graph neural network for cross-domain few-shot classification[J]. Applied Intelligence, 2022, 52(11): 12422-12435. Zhao Z, Liu Q, Cao W, et al. Self-guided information for few-shot classification[J]. Pattern Recognition, 2022, 131: 108880. Liu Q, Chen Y, Cao W. Dual-domain reciprocal learning design for few-shot image classification[J]. Neural Computing and Applications, 2023: 1-14. Liu Q, Cao W, He Z. Cycle Optimization Metric Learning for Few-Shot Classification[J]. Pattern Recognition, 2023: 109468. Zhang R, Liu Q. Learning with few samples in deep learning for image classification, a mini-review[J]. Frontiers in Computational Neuroscience, 2023. 专利 车辆检测方法、装置及计算机可读存储介质，何志权，刘启凡，曹文明，专利号：ZL 2019 1 0029834.8 基于小波变换的渐进式深度卷积网络图像识别方法及装置，何志权，曹文明，刘启凡，专利号：ZL 2019 1 0783600.2 图像数据的压缩传输方法、系统和计算机可读存储介质，何志权，曹文明，刘启凡，专利号：ZL 2019 1 0811971.7 一种基于深度神经网络的OCR识别方法及装置，曹文明，刘启凡，何志权，专利号：ZL 2019 1 0904514.2 ","tags":null,"title":"刘启凡","type":"authors"},{"authors":null,"categories":null,"content":"刘思怡，南方科技大学电子系硕士，深圳大学通信工程系本科研究生。主要研究方向为机器学习、计算机视觉、多模态、文本-图像合成、图像压缩。\n研究方向 机器学习 计算机视觉 多模态 文本-图像生成 图像压缩 个人荣誉 (2023) 深圳大学优秀毕业生 (2023) 深圳大学荣誉学士学位 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"fae9828e328a0015025dd442fb5ca600","permalink":"https://nkdailab.github.io/author/%E5%88%98%E6%80%9D%E6%80%A1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%88%98%E6%80%9D%E6%80%A1/","section":"authors","summary":"刘思怡，南方科技大学电子系硕士，深圳大学通信工程系本科研究生。主要研究方向为机器学习、计算机视觉、多模态、文本-图像合成、图像压缩。\n研究方向 机器学习 计算机视觉 多模态 文本-图像生成 图像压缩 个人荣誉 (2023) 深圳大学优秀毕业生 (2023) 深圳大学荣誉学士学位 ","tags":null,"title":"刘思怡","type":"authors"},{"authors":null,"categories":null,"content":"刘夕媛，南方科技大学电子系大二学生，NKD-AI实验室成员，深圳中学舞蹈团成员(2016-2019)，兴趣广泛，喜欢中国古典舞、中国民间舞蹈、马术障碍、花式舞步、演讲、辩论、慢跑、跳绳、游泳、羽毛球、飞盘、网球等。\n研究方向 虚拟技术 计算机视觉 工作经历 (2023) 招商银行私人银行部实习生 个人荣誉 (2023) 桃李杯艺术展演独舞《鸣》表演金奖 (2023) 桃李杯艺术展演独舞《良宵》表演金奖 (2023) “舞蹈大赛”全国网络舞蹈大赛《良宵》获特金奖 (2023) “舞蹈大赛”全国网络舞蹈大赛《鸣》获特金奖 (2023) 南方科技大学优秀团员 (2023) 第9届中国国际“互联网+”创新创业大赛南方科技大学校内赛高教主赛道优胜奖 (2023) 广东省马术公开赛盛装舞步初一级团体第一 (2023) 南方科技大学“生医工杯”英语演讲大赛第二名 (2023) 第一届“思辨展风采，青春筑未来”书院辩论赛亚军 (2023) “外研社·国才杯”英语演讲大赛南科大初赛二等奖 个人活动 (2023) 南方科技大学2023年四川省招生宣讲主讲人 项目 基于大模型的人机知识表达与交互学习系统 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"c287bed3b7b8e956a9b90f9a18f0868a","permalink":"https://nkdailab.github.io/author/%E5%88%98%E5%A4%95%E5%AA%9B/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%88%98%E5%A4%95%E5%AA%9B/","section":"authors","summary":"刘夕媛，南方科技大学电子系大二学生，NKD-AI实验室成员，深圳中学舞蹈团成员(2016-2019)，兴趣广泛，喜欢中国古典舞、中国民间舞蹈、马术障碍、花式舞步、演讲、辩论、慢跑、跳绳、游泳、羽毛球、飞盘、网球等。\n研究方向 虚拟技术 计算机视觉 工作经历 (2023) 招商银行私人银行部实习生 个人荣誉 (2023) 桃李杯艺术展演独舞《鸣》表演金奖 (2023) 桃李杯艺术展演独舞《良宵》表演金奖 (2023) “舞蹈大赛”全国网络舞蹈大赛《良宵》获特金奖 (2023) “舞蹈大赛”全国网络舞蹈大赛《鸣》获特金奖 (2023) 南方科技大学优秀团员 (2023) 第9届中国国际“互联网+”创新创业大赛南方科技大学校内赛高教主赛道优胜奖 (2023) 广东省马术公开赛盛装舞步初一级团体第一 (2023) 南方科技大学“生医工杯”英语演讲大赛第二名 (2023) 第一届“思辨展风采，青春筑未来”书院辩论赛亚军 (2023) “外研社·国才杯”英语演讲大赛南科大初赛二等奖 个人活动 (2023) 南方科技大学2023年四川省招生宣讲主讲人 项目 基于大模型的人机知识表达与交互学习系统 ","tags":null,"title":"刘夕媛","type":"authors"},{"authors":null,"categories":null,"content":"刘紫琼，南方科技大学电子系硕士研究生，主要研究方向为电子科学与技术。\n研究方向 机器学习 计算机视觉 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"956fd1e019236bc593c096208a115068","permalink":"https://nkdailab.github.io/author/%E5%88%98%E7%B4%AB%E7%90%BC/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%88%98%E7%B4%AB%E7%90%BC/","section":"authors","summary":"刘紫琼，南方科技大学电子系硕士研究生，主要研究方向为电子科学与技术。\n研究方向 机器学习 计算机视觉 ","tags":null,"title":"刘紫琼","type":"authors"},{"authors":null,"categories":null,"content":"罗凯泽，南方科技大学电子系硕士研究生，暨南大学电子信息工程学士。主要研究方向为机器学习、计算机视觉、多模态、具身智能。\n研究方向 机器学习 计算机视觉 多模态模型 具身智能 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"731a3308533403bc795e748018e568c3","permalink":"https://nkdailab.github.io/author/%E7%BD%97%E5%87%AF%E6%B3%BD/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E7%BD%97%E5%87%AF%E6%B3%BD/","section":"authors","summary":"罗凯泽，南方科技大学电子系硕士研究生，暨南大学电子信息工程学士。主要研究方向为机器学习、计算机视觉、多模态、具身智能。\n研究方向 机器学习 计算机视觉 多模态模型 具身智能 ","tags":null,"title":"罗凯泽","type":"authors"},{"authors":null,"categories":null,"content":"钱伟烨，南方科技大学电气与电气工程系本科学生。\n项目 攀登计划（广东省大学生创新创业项目）：基于大模型的人机意图表达与知识学习系统，11/14/2023 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"6a0d2fafd975706e51bc7d73f323e071","permalink":"https://nkdailab.github.io/author/%E9%92%B1%E4%BC%9F%E7%83%A8/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E9%92%B1%E4%BC%9F%E7%83%A8/","section":"authors","summary":"钱伟烨，南方科技大学电气与电气工程系本科学生。\n项目 攀登计划（广东省大学生创新创业项目）：基于大模型的人机意图表达与知识学习系统，11/14/2023 ","tags":null,"title":"钱伟烨","type":"authors"},{"authors":null,"categories":null,"content":"尚阳星，致力于成为一名机器人艺术家。\n研究方向 足式机器人结合感知的运动控制 个人活动 创办了一家机器人公司，并获得了奇绩创坛的投资 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"39c1d79a9d3f90d94b33ea1a980a993f","permalink":"https://nkdailab.github.io/author/%E5%B0%9A%E9%98%B3%E6%98%9F/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%B0%9A%E9%98%B3%E6%98%9F/","section":"authors","summary":"尚阳星，致力于成为一名机器人艺术家。\n研究方向 足式机器人结合感知的运动控制 个人活动 创办了一家机器人公司，并获得了奇绩创坛的投资 ","tags":null,"title":"尚阳星","type":"authors"},{"authors":null,"categories":null,"content":"研究方向 机器学习 计算机视觉 迁移学习 领域自适应 工作经历 (2020 - 至今) 华为 研究实习生 兼职活动 ECCV 2022 审稿人 论文 Tang Y, Zhang C, Xu H, et al. Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3728-3738. 毕业去向 华为技术有限公司 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"6592848b6574fb09ed32ece62aa80b97","permalink":"https://nkdailab.github.io/author/%E5%94%90%E9%9B%A8%E9%A1%BA/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%94%90%E9%9B%A8%E9%A1%BA/","section":"authors","summary":"研究方向 机器学习 计算机视觉 迁移学习 领域自适应 工作经历 (2020 - 至今) 华为 研究实习生 兼职活动 ECCV 2022 审稿人 论文 Tang Y, Zhang C, Xu H, et al. Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3728-3738. 毕业去向 华为技术有限公司 ","tags":null,"title":"唐雨顺","type":"authors"},{"authors":null,"categories":null,"content":"王一嘉, 南方科技大学电子与电气工程系本科在读学生。\n请访问个人主页了解更多信息: https://jia-shao.github.io/\n研究方向 计算机视觉 个人荣誉 南方科技大学2023年度优秀学生一等奖学金 项目 攀登计划（广东省大学生创新创业项目）：基于大模型的人机意图表达与知识学习系统, 11/14/2023 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"4c8c78afd83a011d71a9edf1762e7691","permalink":"https://nkdailab.github.io/author/%E7%8E%8B%E4%B8%80%E5%98%89/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E7%8E%8B%E4%B8%80%E5%98%89/","section":"authors","summary":"王一嘉, 南方科技大学电子与电气工程系本科在读学生。\n请访问个人主页了解更多信息: https://jia-shao.github.io/\n研究方向 计算机视觉 个人荣誉 南方科技大学2023年度优秀学生一等奖学金 项目 攀登计划（广东省大学生创新创业项目）：基于大模型的人机意图表达与知识学习系统, 11/14/2023 ","tags":null,"title":"王一嘉","type":"authors"},{"authors":null,"categories":null,"content":"吴冰岩，南方科技大学电子系硕士研究生。\n研究方向 机器学习 计算机视觉 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"731b603320c290b3f8eb61357bdd3d05","permalink":"https://nkdailab.github.io/author/%E5%90%B4%E5%86%B0%E5%B2%A9/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B4%E5%86%B0%E5%B2%A9/","section":"authors","summary":"吴冰岩，南方科技大学电子系硕士研究生。\n研究方向 机器学习 计算机视觉 ","tags":null,"title":"吴冰岩","type":"authors"},{"authors":null,"categories":null,"content":"吴思奇，美国密苏里大学电气与计算机工程系研究生。\n研究方向 图像压缩 论文 Hadeel Alqadi, Majid Bani Yaghoub, Siqi Wu, Sindhu Balakumar, and Alex Francisco. Prospective Spatial–Temporal Clusters of COVID-19 in Local Communities: Case Study of Kansas City, Missouri, United States. Epidemiology and Infection. 2022. 1-24. Hadeel Alqadi, Majid Bani Yaghoub, Sindhu Balakumar, Siqi Wu, and Alex Francisco. Assessment of Retrospective COVID-19 Spatial Clusters with Respect to Demographic Factors: Case Study of Kansas City, Missouri, United States. Int. J. Environ. Res. Public Health. 2021. 18(21), 11496. Siqi Wu, Chang Chen, Zhiwei Xiong, Xuejin Chen, Xiaoyan Sun. Uncertainty-Aware Label Rectification for Domain Adaptive Mitochondria Segmentation. MICCAI. 2021. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"950a1eb53b0b844604430d349980b76d","permalink":"https://nkdailab.github.io/author/%E5%90%B4%E6%80%9D%E5%A5%87/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B4%E6%80%9D%E5%A5%87/","section":"authors","summary":"吴思奇，美国密苏里大学电气与计算机工程系研究生。\n研究方向 图像压缩 论文 Hadeel Alqadi, Majid Bani Yaghoub, Siqi Wu, Sindhu Balakumar, and Alex Francisco. Prospective Spatial–Temporal Clusters of COVID-19 in Local Communities: Case Study of Kansas City, Missouri, United States. Epidemiology and Infection. 2022. 1-24. Hadeel Alqadi, Majid Bani Yaghoub, Sindhu Balakumar, Siqi Wu, and Alex Francisco. Assessment of Retrospective COVID-19 Spatial Clusters with Respect to Demographic Factors: Case Study of Kansas City, Missouri, United States. Int. J. Environ. Res. Public Health. 2021. 18(21), 11496. Siqi Wu, Chang Chen, Zhiwei Xiong, Xuejin Chen, Xiaoyan Sun. Uncertainty-Aware Label Rectification for Domain Adaptive Mitochondria Segmentation. MICCAI. 2021. ","tags":null,"title":"吴思奇","type":"authors"},{"authors":null,"categories":null,"content":"徐衡，南方科技大学电子与电气工程系硕士生。\n研究方向 学习型图像压缩 工作经历 (2021 – 2023) 数字信号处理助教，南方科技大学 论文 Yushun Tang, Ce Zhang, Heng Xu, Shuoshuo Chen, Jie Cheng, Luziwei Leng, Qinghai Guo, Zhihai He, “Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation. arXiv preprint arXiv:2303.00914, 2023. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"e5cda4527eaeea89eaa9f3c443c2d050","permalink":"https://nkdailab.github.io/author/%E5%BE%90%E8%A1%A1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%BE%90%E8%A1%A1/","section":"authors","summary":"徐衡，南方科技大学电子与电气工程系硕士生。\n研究方向 学习型图像压缩 工作经历 (2021 – 2023) 数字信号处理助教，南方科技大学 论文 Yushun Tang, Ce Zhang, Heng Xu, Shuoshuo Chen, Jie Cheng, Luziwei Leng, Qinghai Guo, Zhihai He, “Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation. arXiv preprint arXiv:2303.00914, 2023. ","tags":null,"title":"徐衡","type":"authors"},{"authors":null,"categories":null,"content":"徐婧珺，现南方科技大学电子系信息工程专业在读大二生。被选拔进电子系卧龙班。\n研究方向 机器学习 个人荣誉 获得优秀学生三等奖学金 全国大学生数学建模比赛省三 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"6dc33cbde403b1b15437709e303f1013","permalink":"https://nkdailab.github.io/author/%E5%BE%90%E5%A9%A7%E7%8F%BA/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%BE%90%E5%A9%A7%E7%8F%BA/","section":"authors","summary":"徐婧珺，现南方科技大学电子系信息工程专业在读大二生。被选拔进电子系卧龙班。\n研究方向 机器学习 个人荣誉 获得优秀学生三等奖学金 全国大学生数学建模比赛省三 ","tags":null,"title":"徐婧珺","type":"authors"},{"authors":null,"categories":null,"content":"杨科，南方科技大学电子与电气工程系硕士生。\n研究方向 机器学习 计算机视觉 个人荣誉 (2022) 湖南工商大学优秀毕业生 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"f5208e78cff79924b56d0152c06e1ad5","permalink":"https://nkdailab.github.io/author/%E6%9D%A8%E7%A7%91/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%9D%A8%E7%A7%91/","section":"authors","summary":"杨科，南方科技大学电子与电气工程系硕士生。\n研究方向 机器学习 计算机视觉 个人荣誉 (2022) 湖南工商大学优秀毕业生 ","tags":null,"title":"杨科","type":"authors"},{"authors":null,"categories":null,"content":"余可，南方科技大学电子系本科学生。\n研究方向 视觉-语言模型小样本学习 项目 2023广东省攀登计划：基于人体姿态估计的智能健康系统 论文 Xueting Hu, Ce Zhang, Yi Zhang, Bowen Hai, Ke Yu, and Zhihai He. Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation. In IEEE/CVF Winter Conference on Applications of Computer Vision (WACV ), 2024. 毕业去向 加利福尼亚大学圣迭戈分校硕士 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"3db98ea2913ac5b6ed15efb705aecc1d","permalink":"https://nkdailab.github.io/author/%E4%BD%99%E5%8F%AF/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E4%BD%99%E5%8F%AF/","section":"authors","summary":"余可，南方科技大学电子系本科学生。\n研究方向 视觉-语言模型小样本学习 项目 2023广东省攀登计划：基于人体姿态估计的智能健康系统 论文 Xueting Hu, Ce Zhang, Yi Zhang, Bowen Hai, Ke Yu, and Zhihai He. Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation. In IEEE/CVF Winter Conference on Applications of Computer Vision (WACV ), 2024. 毕业去向 加利福尼亚大学圣迭戈分校硕士 ","tags":null,"title":"余可","type":"authors"},{"authors":null,"categories":null,"content":"我是张策，目前正在卡耐基梅隆大学攻读机器学习硕士学位，并将于2024年12月毕业。此前，我在南方科技大学(SUSTech)获得了通信工程学士学位。我目前的研究方向是视觉语言模型和场景理解。\n请访问个人主页了解更多信息: https://zhangce01.github.io/\n研究方向 计算机视觉 机器学习 个人荣誉 2023年6月，南方科技大学十大优等生 2022年11月，教育部国家奖学金 论文 HiKER-SGG: Hierarchical Knowledge Enhanced Robust Scene Graph Generation Ce Zhang, Simon Stepputtis, Joseph Campbell, Katia Sycara, Yaqi Xie NeurIPS 2023 New Frontiers in Graph Learning Workshop. Submitted to CVPR 2024 Critical Sampling for Robust Evolution Operator Learning of Unknown Dynamical Systems Ce Zhang, Kailiang Wu, Zhihai He IEEE Transactions on Artificial Intelligence, 2023; Also at First Workshop on Out-of-Distribution Generalization in Robotics at CoRL 2023. BDC-Adapter: Brownian Distance Covariance for Better Vision-Language Reasoning Yi Zhang*, Ce Zhang*, Zihan Liao, Yushun Tang, Zhihai He (*Equal contribution) British Machine Vision Conference (BMVC), 2023. Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation Yushun Tang, Ce Zhang, Heng Xu, Shuoshuo Chen, Jie Cheng, Luziwei Leng, Qinghai Guo, Zhihai He IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation Zhehan Kan, Shuoshuo Chen, Ce Zhang, Yushun Tang, Zhihai He IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation Xueting Hu, Ce Zhang, Yi Zhang, Bowen Hai, Ke Yu, Zhihai He IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024. Unsupervised Prototype Adapter for Vision-Languange Models Yi Zhang, Ce Zhang, Xueting Hu, Zhihai He Chinese Conference on Pattern Recognition and Computer Vision (PRCV), 2023. 毕业去向 卡耐基梅隆大学机器学习硕士 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"8002f3fe9913c00356161066c75bdec1","permalink":"https://nkdailab.github.io/author/%E5%BC%A0%E7%AD%96/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%BC%A0%E7%AD%96/","section":"authors","summary":"我是张策，目前正在卡耐基梅隆大学攻读机器学习硕士学位，并将于2024年12月毕业。此前，我在南方科技大学(SUSTech)获得了通信工程学士学位。我目前的研究方向是视觉语言模型和场景理解。\n请访问个人主页了解更多信息: https://zhangce01.github.io/\n研究方向 计算机视觉 机器学习 个人荣誉 2023年6月，南方科技大学十大优等生 2022年11月，教育部国家奖学金 论文 HiKER-SGG: Hierarchical Knowledge Enhanced Robust Scene Graph Generation Ce Zhang, Simon Stepputtis, Joseph Campbell, Katia Sycara, Yaqi Xie NeurIPS 2023 New Frontiers in Graph Learning Workshop. Submitted to CVPR 2024 Critical Sampling for Robust Evolution Operator Learning of Unknown Dynamical Systems Ce Zhang, Kailiang Wu, Zhihai He IEEE Transactions on Artificial Intelligence, 2023; Also at First Workshop on Out-of-Distribution Generalization in Robotics at CoRL 2023. BDC-Adapter: Brownian Distance Covariance for Better Vision-Language Reasoning Yi Zhang*, Ce Zhang*, Zihan Liao, Yushun Tang, Zhihai He (*Equal contribution) British Machine Vision Conference (BMVC), 2023. Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation Yushun Tang, Ce Zhang, Heng Xu, Shuoshuo Chen, Jie Cheng, Luziwei Leng, Qinghai Guo, Zhihai He IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation Zhehan Kan, Shuoshuo Chen, Ce Zhang, Yushun Tang, Zhihai He IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023. Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation Xueting Hu, Ce Zhang, Yi Zhang, Bowen Hai, Ke Yu, Zhihai He IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024. Unsupervised Prototype Adapter for Vision-Languange Models Yi Zhang, Ce Zhang, Xueting Hu, Zhihai He Chinese Conference on Pattern Recognition and Computer Vision (PRCV), 2023. 毕业去向 卡耐基梅隆大学机器学习硕士 ","tags":null,"title":"张策","type":"authors"},{"authors":null,"categories":null,"content":"研究方向 机器学习 计算机视觉 视觉-语言 小样本学习 视觉推理 工作经历 (2021 - 2025) 南方科技大学人工智能实验室科研助理，深圳 (2020 - 2021) 广东东软学院讲师，佛山 (2018 - 2020) SAP软件工程师，上海 (2016 - 2018) 软件工程师，南密西西比大学 论文 Yi Zhang, Ce Zhang, Ke Yu, Yushun Tang, Zhihai He. Concept-Guided Prompt Learning for Generalization in Vision-Language Models. AAAI2024. Yi Zhang, Ce Zhang, Zihan Liao, Yushun Tang, Zhihai He. BDC-Adapter: Brownian Distance Covariance for Better Vision-Language Reasoning. British Machine Vision Conference 2023 (BMVC2023). Xueting Hu, Ce Zhang, Yi Zhang, Ke Yu, Zhihai He. Learn to Adapt CLIP for Few-Shot Monocular Depth Estimation. Submitted to Winter Conference on Computer Vision (WACV), 2024. (Project Lead) Yi Zhang, Ce Zhang, Xueting Hu, Zhihai He. Unsupervised Prototype Adapter for Vision-Language Models. The 6th Chinese Conference on Pattern Recognition and Computer Vision (PRCV2023). Yi Zhang, Ce Zhang, Yushun Tang, Zhihai He. Cross-Model concept learning and reference for Vision-Language\tModels. Neurocomputing. (Under review) Yi Zhang, Ce Zhang, Zhihai He. Distribution Learning Adapter for Vision-Language Models. (Preprint) Yushun Tang, Shuoshuo Chen, Zhehan Kan, Yi Zhang, Qinghai Guo, Zhihai He. Learning Visual Conditioning Tokens to Clean Up Domain Shift for Fully Test-Time Adaptation. IEEE Transactions on Circuits and Systems for Video Technology(TCSVT) (Under review) 毕业去向 深圳大学计算机与软件学院助理教授 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"27523689934ba3c3f28cc28b6e9ef44c","permalink":"https://nkdailab.github.io/author/%E5%BC%A0%E6%AF%85/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%BC%A0%E6%AF%85/","section":"authors","summary":"研究方向 机器学习 计算机视觉 视觉-语言 小样本学习 视觉推理 工作经历 (2021 - 2025) 南方科技大学人工智能实验室科研助理，深圳 (2020 - 2021) 广东东软学院讲师，佛山 (2018 - 2020) SAP软件工程师，上海 (2016 - 2018) 软件工程师，南密西西比大学 论文 Yi Zhang, Ce Zhang, Ke Yu, Yushun Tang, Zhihai He. Concept-Guided Prompt Learning for Generalization in Vision-Language Models. AAAI2024. Yi Zhang, Ce Zhang, Zihan Liao, Yushun Tang, Zhihai He. BDC-Adapter: Brownian Distance Covariance for Better Vision-Language Reasoning. British Machine Vision Conference 2023 (BMVC2023). Xueting Hu, Ce Zhang, Yi Zhang, Ke Yu, Zhihai He. Learn to Adapt CLIP for Few-Shot Monocular Depth Estimation. Submitted to Winter Conference on Computer Vision (WACV), 2024. (Project Lead) Yi Zhang, Ce Zhang, Xueting Hu, Zhihai He. Unsupervised Prototype Adapter for Vision-Language Models. The 6th Chinese Conference on Pattern Recognition and Computer Vision (PRCV2023). Yi Zhang, Ce Zhang, Yushun Tang, Zhihai He. Cross-Model concept learning and reference for Vision-Language\tModels. Neurocomputing. (Under review) Yi Zhang, Ce Zhang, Zhihai He. Distribution Learning Adapter for Vision-Language Models. (Preprint) Yushun Tang, Shuoshuo Chen, Zhehan Kan, Yi Zhang, Qinghai Guo, Zhihai He. Learning Visual Conditioning Tokens to Clean Up Domain Shift for Fully Test-Time Adaptation. IEEE Transactions on Circuits and Systems for Video Technology(TCSVT) (Under review) 毕业去向 深圳大学计算机与软件学院助理教授 ","tags":null,"title":"张毅","type":"authors"},{"authors":null,"categories":null,"content":"研究方向 图像压缩 小样本学习 论文 Zhao Z, Liu Q, Cao W, et al. Self-guided information for few-shot classification[J]. Pattern Recognition, 2022, 131: 108880. Liu Q, Zhao Z, Cao W, et al. Residual proportion multilayer perceptron for few-shot classification[C]//2021 IEEE International conference on multimedia \u0026amp; expo workshops (ICMEW). IEEE, 2021: 1-6. Xiong M, Cao W, Zhao Z. Dual-model Collaborative Learning with Knowledge Clustering for Few-shot Image Classification[J]. Multimedia Tools and Applications, 2023: 1-20. ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"f70bb9260f13c53d9bbcf460fc6ba7a2","permalink":"https://nkdailab.github.io/author/%E8%B5%B5%E4%B9%8B%E8%83%BD/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E8%B5%B5%E4%B9%8B%E8%83%BD/","section":"authors","summary":"研究方向 图像压缩 小样本学习 论文 Zhao Z, Liu Q, Cao W, et al. Self-guided information for few-shot classification[J]. Pattern Recognition, 2022, 131: 108880. Liu Q, Zhao Z, Cao W, et al. Residual proportion multilayer perceptron for few-shot classification[C]//2021 IEEE International conference on multimedia \u0026 expo workshops (ICMEW). IEEE, 2021: 1-6. Xiong M, Cao W, Zhao Z. Dual-model Collaborative Learning with Knowledge Clustering for Few-shot Image Classification[J]. Multimedia Tools and Applications, 2023: 1-20. ","tags":null,"title":"赵之能","type":"authors"},{"authors":null,"categories":null,"content":"周子皓，南方科技大学电子系硕士研究生，南方科技大学信息工程学士。主要研究方向为计算机视觉、机器学习、具身智能。\n研究方向 计算机视觉 机器学习 具身智能 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"df8765018bceba7580e90da92cc569fc","permalink":"https://nkdailab.github.io/author/%E5%91%A8%E5%AD%90%E7%9A%93/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%91%A8%E5%AD%90%E7%9A%93/","section":"authors","summary":"周子皓，南方科技大学电子系硕士研究生，南方科技大学信息工程学士。主要研究方向为计算机视觉、机器学习、具身智能。\n研究方向 计算机视觉 机器学习 具身智能 ","tags":null,"title":"周子皓","type":"authors"},{"authors":null,"categories":null,"content":"朱旨函，南方科技大学电子与电气工程系本科在读学生。目前从事与机器学习和扩散模型相关的学习和研究\n研究方向 机器学习 计算机视觉 扩散模型 个人荣誉 南方科技大学2023-2024年度优秀学生三等奖学金 ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":-62135596800,"objectID":"e4cbca4c97d1c973fee37e0f83495a75","permalink":"https://nkdailab.github.io/author/%E6%9C%B1%E6%97%A8%E5%87%BD/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E6%9C%B1%E6%97%A8%E5%87%BD/","section":"authors","summary":"朱旨函，南方科技大学电子与电气工程系本科在读学生。目前从事与机器学习和扩散模型相关的学习和研究\n研究方向 机器学习 计算机视觉 扩散模型 个人荣誉 南方科技大学2023-2024年度优秀学生三等奖学金 ","tags":null,"title":"朱旨函","type":"authors"},{"authors":null,"categories":null,"content":"AAAI，即The Association for Advancement of Artificial Intelligence（国际人工智能协会）的简称，是人工智能领域最重要的国际会议之一，由国际人工智能协会主办，是中国计算机学会（CCF）推荐的A类会议。AAAI 2025共收到12,957份投稿，3032篇论文被录用，录取率为23.4%，其中Oral Presentation（口头报告）接收率为4.6%。AAAI 2025于2025年2月25日- 3月4日在美国宾夕法尼亚州费城举办。\n《Cross-Modal Few-Shot Learning with Second-Order Neural Ordinary Differential Equations》\n作者 Yi Zhang (Harbin Institute of Technology, Southern University of Science and Technology), Chun-Wun Cheng (University of Cambridge), Junyi He (Southern University of Science and Technology), Zhihai He (Southern University of Science and Technology), Carola-Bibiane Schönlieb (University of Cambridge), Yuyan Chen (Fudan University), Angelica I Aviles-Rivero (Tsinghua University)\n简介 南方科技大学电子与电气工程系2021级博士研究生张毅在跨模态小样本学习领域提出创新性方法SONO，通过二阶神经常微分方程显著提升模型在少样本场景下的泛化能力，有效解决了传统方法中因数据稀缺导致的过拟合问题。 随着多模态人工智能技术的快速发展，如何让模型在极少量标注样本下实现跨模态（如图像-文本）高效学习成为关键挑战。现有方法普遍面临过拟合风险高、计算资源消耗大、跨模态对齐能力不足等瓶颈问题。研究团队创新性地将二阶神经常微分方程引入跨模态学习框架，通过连续动态特征优化增强模型表达能力，并结合\u0026#34;文本即图像\u0026#34;数据增强策略，利用CLIP模型的图文关联特性有效扩充了训练数据。实验表明，该方法在ImageNet等11个基准数据集上小样本分类准确率显著优于现有最优方法，在医疗影像等数据稀缺场景展现出应用潜力。 本文系南科大电子系2021级博士生张毅在英国剑桥大学访问期间的研究成果，由南方科技大学何志海讲席教授和清华大学丘成桐数学科学中心助理教授Angelica I. Aviles-Rivero在剑桥大学担任高级副研究员期间指导完成，合作单位包括南方科技大学、剑桥大学应用数学与理论物理系、清华大学丘成桐数学科学中心、上海市数据科学重点实验室等科研机构。张毅是南方科技大学与哈尔滨工业大学联培博士，为本文第一作者，剑桥大学博士生郑俊焕、南科大2021级本科生何浚亦、剑桥大学Carola-Bibiane Schönlieb教授、复旦大学上海市数据科学重点实验室博士生陈昱妍为本文作者，南科大电子系讲席教授何志海、清华大学丘成桐数学科学中心助理教授Angelica I. Aviles-Rivero为本文通讯作者。南科大博士生张毅和本科生何浚亦均来自何志海课题组。\n论文链接：https://arxiv.org/abs/2412.15813 论文资助信息：本研究工作得到国自然基金重点项目No. 62331014支持\n《Conditional Latent Coding with Learnable Synthesized Reference for Deep Image Compression》\n作者 Siqi Wu (University of Missouri), Yinda Chen (University of Science and Technology of China), Dong Liu (University of Science and Technology of China), Zhihai He (Southern University of Science and Technology)\n简介 美国密苏里大学电子与计算机工程系2022级博士研究生吴思奇在来南方科技大学访问研究期间，与中国科学技术大学合作提出了一种基于可学习合成参考的条件潜在编码方法，提高了深度图像压缩的效率。\n随着数字技术的快速发展和图像数据量的急剧增加，高效的图像压缩技术对于存储、传输和处理图像数据至关重要。当前深度学习方法在图像压缩方面取得了显著进展，但仍面临在保持高重建质量的同时有效利用图像源相关性的挑战。文章提出了一种条件潜在编码方法，通过从外部字典中动态生成参考表示，对输入图像进行条件编码。输入图像会与字典中的特征进行匹配，利用输入图像和参考字典之间的相关性，以实现对输入图像的高效压缩与高质量重建。本论文在公开数据集Kodak和CLIC上取得了较大提升，为进一步的研究和潜在改进提供了有用见解。 美国密苏里大学2022级博士研究生吴思奇作为南方科技大学访问学生，目前在何志海课题组进行访问研究，她与中国科学技术大学2024级博士研究生陈胤达为本文共同第一作者。中国科学技术大学电子工程与信息科学系教授刘东为本文作者，南方科技大学电子系讲席教授何志海为本文通讯作者。美国密苏里大学为论文第一单位，南方科技大学为论文第三单位。\n论文链接：https://arxiv.org/abs/2502.09971v1 论文资助信息：本研究工作得到国自然基金重点项目No. 62331014支持\n","date":1740528000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1740528000,"objectID":"235108c165bae6c48f0b4c9e042a3472","permalink":"https://nkdailab.github.io/post/2025.3.6/","publishdate":"2025-02-26T00:00:00Z","relpermalink":"/post/2025.3.6/","section":"post","summary":"在国际人工智能顶级会议AAAI-2025公布的录用结果中，南方科技大学电子系人工智能实验室（AI Lab）共有2篇论文被录用，并均录用为Oral Presentation。","tags":null,"title":"南科大电子系何志海课题组喜提2篇AAAI-2025 Oral Paper","type":"post"},{"authors":null,"categories":null,"content":"近日，2024年度吴文俊人工智能科学技术奖获奖名单正式发布，南方科技大学电子与电气工程系何志海讲席教授作为项目第一完成人，其研究的“大模型驱动的居家AI医生和全病程管理”项目脱颖而出，荣获“2024年度吴文俊人工智能科学技术奖技术发明二等奖”。\n图1. 获奖名单\n吴文俊人工智能科学技术奖由中国人工智能学会发起，素有“中国智能科学技术最高奖”之称，是人工智能领域的至高荣誉象征。该奖项旨在表彰在智能科学研究中取得关键发现，有力推动科学技术进步，并创造出显著经济社会效益或生态环境效益的单位和个人。\n此次何志海教授联合深圳大学曹文明教授、北京交通大学岑翼刚教授以及南方科技大学高级研究学者欧阳健共同申报的“大模型驱动的居家AI医生和全病程管理”成果，创新性地运用人工智能与大模型技术，搭建起一套涵盖居家健康与疾病感知监测、分析建模、预警干预、诊疗辅助以及慢病防控管理的综合性平台。该平台极大地赋能医护人员，让他们能够在居家环境下，为老年慢病患者提供专业、智能的健康监护与疾病管理服务，有效破解了老龄化加剧带来的健康监护与疾病管理难题。\n图2. AI居家医养智能体\n目前，该项目已在广东、湖南、浙江等地成功实现规模化应用，切实改善了当地老年慢病患者的健康管理状况，产生了良好的社会效益，有望为更多地区应对老龄化健康挑战提供借鉴与示范。\n原文链接: https://mp.weixin.qq.com/s/K3X2Avrt6lgsTJWg3ry3Qw\n","date":1740441600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1740441600,"objectID":"59fbe73209dca5b2c32ccdc30b678812","permalink":"https://nkdailab.github.io/post/2025.2.25/","publishdate":"2025-02-25T00:00:00Z","relpermalink":"/post/2025.2.25/","section":"post","summary":"南方科技大学电子与电气工程系何志海讲席教授研究的“大模型驱动的居家AI医生和全病程管理”荣获“2024年度吴文俊人工智能科学技术奖技术发明二等奖”。","tags":null,"title":"南科大电子系何志海教授团队荣获2024年度吴文俊人工智能科学技术奖技术发明二等奖","type":"post"},{"authors":["Siqi Wu","Yinda Chen","Dong Liu","Zhihai He"],"categories":null,"content":"","date":1738368000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1738368000,"objectID":"1e28e05cca2d420807381383b87847dd","permalink":"https://nkdailab.github.io/publication/conditional-latent-coding-with-learnable-synthesized-reference-for-deep-image-compression/","publishdate":"2025-02-01T00:00:00Z","relpermalink":"/publication/conditional-latent-coding-with-learnable-synthesized-reference-for-deep-image-compression/","section":"publication","summary":"In this paper, we study how to synthesize a dynamic reference from an external dictionary to perform conditional coding of the input image in the latent domain and how to learn the conditional latent synthesis and coding modules in an end-to-end manner. Our approach begins by constructing a universal image feature dictionary using a multi-stage approach involving modified spatial pyramid pooling, dimension reduction, and multi-scale feature clustering. For each input image, we learn to synthesize a conditioning latent by selecting and synthesizing relevant features from the dictionary, which significantly enhances the model's capability in capturing and exploring image source correlation. This conditional latent synthesis involves a correlation-based feature matching and alignment strategy, comprising a Conditional Latent Matching (CLM) module and a Conditional Latent Synthesis (CLS) module. The synthesized latent is then used to guide the encoding process, allowing for more efficient compression by exploiting the correlation between the input image and the reference dictionary. According to our theoretical analysis, the proposed conditional latent coding (CLC) method is robust to perturbations in the external dictionary samples and the selected conditioning latent, with an error bound that scales logarithmically with the dictionary size, ensuring stability even with large and diverse dictionaries. Experimental results on benchmark datasets show that our new method improves the coding performance by a large margin (up to 1.2 dB) with a very small overhead of approximately 0.5% bits per pixel.","tags":null,"title":"Conditional Latent Coding with Learnable Synthesized Reference for Deep Image Compression","type":"publication"},{"authors":["Yi Zhang","Chun-Wun Cheng","Junyi He","Zhihai He","Carola-Bibiane Schönlieb","Yuyan Chen","Angelica I Aviles-Rivero"],"categories":null,"content":"","date":1738368000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1738368000,"objectID":"ad6f4fbd188eb71df522a0c719bd5f77","permalink":"https://nkdailab.github.io/publication/cross-modal-few-shot-learning-with-second-order-neural-ordinary-differential-equations/","publishdate":"2025-02-01T00:00:00Z","relpermalink":"/publication/cross-modal-few-shot-learning-with-second-order-neural-ordinary-differential-equations/","section":"publication","summary":"We introduce SONO, a novel method leveraging Second-Order Neural Ordinary Differential Equations (Second-Order NODEs) to enhance cross-modal few-shot learning. By employing a simple yet effective architecture consisting of a Second-Order NODEs model paired with a cross-modal classifier, SONO addresses the significant challenge of overfitting, which is common in few-shot scenarios due to limited training examples. Our second-order approach can approximate a broader class of functions, enhancing the model's expressive power and feature generalization capabilities. We initialize our cross-modal classifier with text embeddings derived from class-relevant prompts, streamlining training efficiency by avoiding the need for frequent text encoder processing. Additionally, we utilize text-based image augmentation, exploiting CLIP's robust image-text correlation to enrich training data significantly. Extensive experiments across multiple datasets demonstrate that SONO outperforms existing state-of-the-art methods in few-shot learning performance.","tags":null,"title":"Cross-Modal Few-Shot Learning with Second-Order Neural Ordinary Differential Equations","type":"publication"},{"authors":["Ce Zhang","Siqi Wu","Zhihai He","Zhao Joy Sun"],"categories":null,"content":" ","date":1699142400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1699142400,"objectID":"7c7fd8c8f4e3f2caee39c18a64959b9e","permalink":"https://nkdailab.github.io/publication/critical-sampling-for-data-driven-modeling-of-unknown-dynamical-systems/","publishdate":"2023-11-05T00:00:00Z","relpermalink":"/publication/critical-sampling-for-data-driven-modeling-of-unknown-dynamical-systems/","section":"publication","summary":"When a robot is exploring an unknown dynamical system, we often face the following important question:what is the minimum number of samples needed for effective learning of its governing laws and accurate prediction of its future evolution behavior, and how to select these critical samples? In this work, we propose to explore this problem based on a design approach. Starting from a small initial set of samples, we adaptively discover critical samples to achieve increasingly accurate learning of the system evolution. We establish a multi-step reciprocal prediction network where forward and backward evolution networks are designed to learn the temporal evolution behavior in the forward and backward time directions, respectively. Very interestingly, we find that the desired network modeling error is highly correlated with the multi-step reciprocal prediction error, which can be directly computed from the current system state. This allows us to perform a dynamic selection of critical samples from regions with high network modeling errors for dynamical systems. Our extensive experimental results demonstrate that our proposed method is able to dramatically reduce the number of samples needed for effective learning and accurate prediction of evolution behaviors of unknown dynamical systems by up to hundreds of times.","tags":null,"title":"Critical Sampling for Data-Driven Modeling of Unknown Dynamical Systems","type":"publication"},{"authors":["Xueting Hu","Ce Zhang","Yi Zhang","Bowen Hai","Ke Yu","Zhihai He"],"categories":null,"content":" ","date":1698883200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1698883200,"objectID":"521043e96fc9adaa48a8e46ef72d2d75","permalink":"https://nkdailab.github.io/publication/learning-to-adapt-clip-for-few-shot-monocular-depth-estimation/","publishdate":"2023-11-02T00:00:00Z","relpermalink":"/publication/learning-to-adapt-clip-for-few-shot-monocular-depth-estimation/","section":"publication","summary":"Pre-trained Vision-Language Models (VLMs), such as CLIP, have shown enhanced performance across a range of tasks that involve the integration of visual and linguistic modalities. When CLIP is used for depth estimation tasks, the patches, divided from the input images, can be combined with a series of semantic descriptions of the depth information to obtain similarity results. The coarse estimation of depth is then achieved by weighting and summing the depth values, called depth bins, corresponding to the predefined semantic descriptions. The zero-shot approach circumvents the computational and time-intensive nature of traditional fully-supervised depth estimation methods. However, this method, utilizing fixed depth bins, may not effectively generalize as images from different scenes may exhibit distinct depth distributions. To address this challenge, we propose a few-shot-based method which learns to adapt the VLMs for monocular depth estimation to balance training costs and generalization capabilities. Specifically, it assigns different depth bins for different scenes, which can be selected by the model during inference. Additionally, we incorporate learnable prompts to preprocess the input text to convert the easily human-understood text into easily model-understood vectors and further enhance the performance. With only one image per scene for training, our extensive experiment results on the NYU V2 and KITTI dataset demonstrate that our method outperforms the previous state-of-the-art method by up to 10.6\\% in terms of MARE.","tags":null,"title":"Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation","type":"publication"},{"authors":["Yushun Tang","Qinghai Guo","Zhihai He"],"categories":null,"content":" ","date":1696723200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1696723200,"objectID":"1d3e755ec6b18cff7ef301a3685c986a","permalink":"https://nkdailab.github.io/publication/cross-inferential-networks-for-source-free-unsupervised-domain-adaptation/","publishdate":"2023-10-08T00:00:00Z","relpermalink":"/publication/cross-inferential-networks-for-source-free-unsupervised-domain-adaptation/","section":"publication","summary":"One central challenge in source-free unsupervised domain adaptation (UDA) is the lack of an effective approach to evaluate the prediction results of the adapted network model in the target domain. To address this challenge, we propose to explore a new method called cross-inferential networks (CIN). Our main idea is that, when we adapt the network model to predict the sample labels from encoded features, we use these prediction results to construct new training samples with derived labels to learn a new examiner network that performs a different but compatible task in the target domain. Specifically, in this work, the base network model is performing image classification while the examiner network is tasked to perform relative ordering of triplets of samples whose training labels are carefully constructed from the prediction results of the base network model. Two similarity measures, cross-network correlation matrix similarity and attention consistency, are then developed to provide important guidance for the UDA process. Our experimental results on benchmark datasets demonstrate that our proposed CIN approach can significantly improve the performance of source-free UDA.","tags":["Training","Adaptation models","Correlation","Image processing","Predictive models","Benchmark testing","Task analysis"],"title":"Cross-inferential networks for source-free unsupervised domain adaptation","type":"publication"},{"authors":["Yi Zhang","Ce Zhang","Zihan Liao","Yushun Tang","Zhihai He"],"categories":null,"content":" ","date":1693699200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1693699200,"objectID":"24e7e7985cb362966eae91318043e6aa","permalink":"https://nkdailab.github.io/publication/bdc-adapter-brownian-distance-covariance-for-better-vision-language-reasoning/","publishdate":"2023-09-03T00:00:00Z","relpermalink":"/publication/bdc-adapter-brownian-distance-covariance-for-better-vision-language-reasoning/","section":"publication","summary":"Large-scale pre-trained Vision-Language Models (VLMs), such as CLIP and ALIGN, have introduced a new paradigm for learning transferable visual representations. Recently, there has been a surge of interest among researchers in developing lightweight fine-tuning techniques to adapt these models to downstream visual tasks. We recognize that current state-of-the-art fine-tuning methods, such as Tip-Adapter, simply consider the covariance between the query image feature and features of support few-shot training samples, which only captures linear relations and potentially instigates a deceptive perception of independence. To address this issue, in this work, we innovatively introduce Brownian Distance Covariance (BDC) to the field of vision-language reasoning. The BDC metric can model all possible relations, providing a robust metric for measuring feature dependence. Based on this, we present a novel method called BDC-Adapter, which integrates BDC prototype similarity reasoning and multi-modal reasoning network prediction to perform classification tasks. Our extensive experimental results show that the proposed BDC-Adapter can freely handle non-linear relations and fully characterize independence, outperforming the current state-of-the-art methods by large margins.","tags":null,"title":"BDC-Adapter Brownian Distance Covariance for Better Vision-Language Reasoning","type":"publication"},{"authors":["Yi Zhang","Ce Zhang","Xueting Hu","Zhihai He"],"categories":null,"content":" ","date":1692662400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1692662400,"objectID":"d649788896b308d4de68f455f53864fc","permalink":"https://nkdailab.github.io/publication/unsupervised-prototype-adapter-for-vision-language-models/","publishdate":"2023-08-22T00:00:00Z","relpermalink":"/publication/unsupervised-prototype-adapter-for-vision-language-models/","section":"publication","summary":"Recently, large-scale pre-trained vision-language models (e.g. CLIP and ALIGN) have demonstrated remarkable effectiveness in acquiring transferable visual representations. To leverage the valuable knowledge encoded within these models for downstream tasks, several fine-tuning approaches, including prompt tuning methods and adapter-based methods, have been developed to adapt vision-language models effectively with supervision. However, these methods rely on the availability of annotated samples, which can be labor-intensive and time-consuming to acquire, thus limiting scalability. To address this issue, in this work, we design an unsupervised fine-tuning approach for vision-language models called Unsupervised Prototype Adapter (UP-Adapter). Specifically, for the unannotated target datasets, we leverage the text-image aligning capability of CLIP to automatically select the most confident samples for each class. Utilizing these selected samples, we generate class prototypes, which serve as the initialization for the learnable prototype model. After fine-tuning, the prototype model prediction is combined with the original CLIP's prediction by a residual connection to perform downstream recognition tasks. Our extensive experimental results on image recognition and domain generalization show that the proposed unsupervised method outperforms 8-shot CoOp, 8-shot Tip-Adapter, and also the state-of-the-art UPL method by large margins.","tags":null,"title":"Unsupervised Prototype Adapter for Vision-Language Models","type":"publication"},{"authors":["Qifan Liu","Wenming Cao","Zhihai He"],"categories":null,"content":"","date":1688169600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1688169600,"objectID":"2b1a2049f9e4235ac4c0335501d2259b","permalink":"https://nkdailab.github.io/publication/cycle-optimization-metric-learning-for-few-shot-classification/","publishdate":"2023-07-01T00:00:00Z","relpermalink":"/publication/cycle-optimization-metric-learning-for-few-shot-classification/","section":"publication","summary":"Metric learning methods are widely used in few-shot learning due to their simplicity and effectiveness. Most existing methods directly predict query labels by comparing the similarity between support and query samples. In this paper, we design a cycle optimization metric network for few-shot classification task that optimizes model performance based on loop-prediction of the labels of query samples and support samples. Specifically, we construct a forward network and reverse network based on a geometric algebra Graph Neural Network (GA-GNN). These two networks form the loop prediction from support samples to query samples and then back to support samples, guided by a cycle-consistency loss. We also introduce an optimization module that is able to correct the predicted results of query samples to further improve the network performance. Our extensive experimental results demonstrate that the proposed cycle optimization metric network outperforms existing state-of-the-art few-shot learning methods on classification tasks.","tags":["Few-shot classification","Graph convolution network","Self-guided information"],"title":"Cycle optimization metric learning for few-shot classification","type":"publication"},{"authors":["Ce Zhang","Kailiang Wu","Zhihai He"],"categories":null,"content":"","date":1681516800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1681516800,"objectID":"002eabb64a60ed3e3c66506e950e7eb1","permalink":"https://nkdailab.github.io/publication/critical-sampling-for-robust-evolution-operator-learning-of-unknown-dynamical-systems/","publishdate":"2023-04-15T00:00:00Z","relpermalink":"/publication/critical-sampling-for-robust-evolution-operator-learning-of-unknown-dynamical-systems/","section":"publication","summary":"Given an unknown dynamical system, what is the minimum number of samples needed for effective learning of its governing laws and accurate prediction of its future evolution behavior, and how to select these critical samples? In this work, we propose to explore this problem based on a design approach. Starting from a small initial set of samples, we adaptively discover critical samples to achieve increasingly accurate learning of the system evolution. One central challenge here is that we do not know the network modeling error since the ground-truth system state is unknown, which is however needed for critical sampling. To address this challenge, we introduce a multi-step reciprocal prediction network where forward and backward evolution networks are designed to learn the temporal evolution behavior in the forward and backward time directions, respectively. Very interestingly, we find that the desired network modeling error is highly correlated with the multi-step reciprocal prediction error, which can be directly computed from the current system state. This allows us to perform a dynamic selection of critical samples from regions with high network modeling errors for dynamical systems. Additionally, a joint spatial-temporal evolution network is introduced which incorporates spatial dynamics modeling into the temporal evolution prediction for robust learning of the system evolution operator with few samples. Our extensive experimental results demonstrate that our proposed method is able to dramatically reduce the number of samples needed for effective learning and accurate prediction of evolution behaviors of unknown dynamical systems by up to hundreds of times.","tags":null,"title":"Critical Sampling for Robust Evolution Operator Learning of Unknown Dynamical Systems","type":"publication"},{"authors":["Zhehan Kan","Shuoshuo Chen","Ce Zhang","Yushun Tang","Zhihai He"],"categories":null,"content":" ","date":1679270400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1679270400,"objectID":"a18bed0e4080f799751129955a31b702","permalink":"https://nkdailab.github.io/publication/self-correctable-and-adaptable-inference-for-generalizable-human-pose-estimation/","publishdate":"2023-03-20T00:00:00Z","relpermalink":"/publication/self-correctable-and-adaptable-inference-for-generalizable-human-pose-estimation/","section":"publication","summary":"A central challenge in human pose estimation, as well as in many other machine learning and prediction tasks, is the generalization problem. The learned network does not have the capability to characterize the prediction error, generate feedback information from the test sample, and correct the prediction error on the fly for each individual test sample, which results in degraded performance in generalization. In this work, we introduce a self-correctable and adaptable inference (SCAI) method to address the generalization challenge of network prediction and use human pose estimation as an example to demonstrate its effectiveness and performance. We learn a correction network to correct the prediction result conditioned by a fitness feedback error. This feedback error is generated by a learned fitness feedback network which maps the prediction result to the original input domain and compares it against the original input. Interestingly, we find that this self-referential feedback error is highly correlated with the actual prediction error. This strong correlation suggests that we can use this error as feedback to guide the correction process. It can be also used as a loss function to quickly adapt and optimize the correction network during the inference process. Our extensive experimental results on human pose estimation demonstrate that the proposed SCAI method is able to significantly improve the generalization capability and performance of human pose estimation.","tags":null,"title":"Self-Correctable and Adaptable Inference for Generalizable Human Pose Estimation","type":"publication"},{"authors":["Yushun Tang","Ce Zhang","Heng Xu","Shuoshuo Chen","Jie Cheng","Luziwei Leng","Qinghai Guo","Zhihai He"],"categories":null,"content":" ","date":1677715200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1677715200,"objectID":"56303c7b470b49c10d391fc86a30453d","permalink":"https://nkdailab.github.io/publication/neuro-modulated-hebbian-learning-for-fully-test-time-adaptation/","publishdate":"2023-03-02T00:00:00Z","relpermalink":"/publication/neuro-modulated-hebbian-learning-for-fully-test-time-adaptation/","section":"publication","summary":"Fully test-time adaptation aims to adapt the network model based on sequential analysis of input samples during the inference stage to address the cross-domain performance degradation problem of deep neural networks. We take inspiration from the biological plausibility learning where the neuron responses are tuned based on a local synapse-change procedure and activated by competitive lateral inhibition rules. Based on these feed-forward learning rules, we design a soft Hebbian learning process which provides an unsupervised and effective mechanism for online adaptation. We observe that the performance of this feed-forward Hebbian learning for fully test-time adaptation can be significantly improved by incorporating a feedback neuro-modulation layer. It is able to fine-tune the neuron responses based on the external feedback generated by the error back-propagation from the top inference layers. This leads to our proposed neuro-modulated Hebbian learning (NHL) method for fully test-time adaptation. With the unsupervised feed-forward soft Hebbian learning being combined with a learned neuro-modulator to capture feedback from external responses, the source model can be effectively adapted during the testing process. Experimental results on benchmark datasets demonstrate that our proposed method can significantly improve the adaptation performance of network models and outperforms existing state-of-the-art methods.","tags":null,"title":"Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation","type":"publication"},{"authors":["Zhineng Zhao","Qifan Liu","Wenming Cao","Deliang Lian","Zhihai He"],"categories":null,"content":"","date":1667260800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1667260800,"objectID":"ecb52f55912e8318c680f38d69c6a7dc","permalink":"https://nkdailab.github.io/publication/self-guided-information-for-few-shot-classification/","publishdate":"2022-11-01T00:00:00Z","relpermalink":"/publication/self-guided-information-for-few-shot-classification/","section":"publication","summary":"Few-shot classification aims to identify novel categories using only a few labeled samples. Generally, the metric-based few-shot classification methods compare the feature embedding of Query samples (unlabeled samples) with Support samples (labeled samples) in a metric algorithm to predict which category the Query sample belongs to. Obtaining a good feature embedding for each sample in the feature extraction stage can improve the classification accuracy in the metric stage. Based on this, we design the Self-Guided Information Convolution (SGI-Conv), an improved convolution structure, which utilizes the high-level features to guide the network to extract the required discriminative features. To effectively utilize the feature embeddings of samples, we divide the metric network into multiple blocks and build a multi-layer graph convolutional network by sharing adjacent matrices. The multi-layer structure enhances the aggregation ability of graph convolution. Extensive experiments on multiple benchmark datasets demonstrate that our method has achieved competitive results on the few-shot classification tasks.","tags":["Few-shot classification","Graph convolution network","Self-guided information"],"title":"Self-guided information for few-shot classification","type":"publication"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1666569600,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://nkdailab.github.io/contact/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"Contact","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1666569600,"objectID":"b0d61e5cbb7472bf320bf0ef2aaeb977","permalink":"https://nkdailab.github.io/tour/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/tour/","section":"","summary":"","tags":null,"title":"Home","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1666569600,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://nkdailab.github.io/people/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"People","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1666569600,"objectID":"b27ca6127db17e2b568383080404fdc7","permalink":"https://nkdailab.github.io/event/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/event/","section":"","summary":"","tags":null,"title":"研究","type":"landing"},{"authors":["Zhehan Kan","Shuoshuo Chen","Zeng Li","Zhihai He"],"categories":null,"content":" ","date":1666483200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1666483200,"objectID":"7522a23b9d30c71c738b405e2cdbd8e3","permalink":"https://nkdailab.github.io/publication/self-constrained-inference-optimization-on-structural-groups-for-human-pose-estimation/","publishdate":"2023-10-23T00:00:00Z","relpermalink":"/publication/self-constrained-inference-optimization-on-structural-groups-for-human-pose-estimation/","section":"publication","summary":"We observe that human poses exhibit strong group-wise structural correlation and spatial coupling between keypoints due to the biological constraints of different body parts. This group-wise structural correlation can be explored to improve the accuracy and robustness of human pose estimation. In this work, we develop a self-constrained prediction-verification network to characterize and learn the structural correlation between keypoints during training. During the inference stage, the feedback information from the verification network allows us to perform further optimization of pose prediction, which significantly improves the performance of human pose estimation. Specifically, we partition the keypoints into groups according to the biological structure of human body. Within each group, the keypoints are further partitioned into two subsets, high-accuracy proximal keypoints and low-accuracy distal keypoints. We develop a self-constrained prediction-verification network to perform forward and backward predictions between these keypoint subsets. One fundamental challenge in pose estimation, as well as in generic prediction tasks, is that there is no mechanism for us to verify if the obtained pose estimation or prediction results are accurate or not, since the ground truth is not available. Once successfully learned, the verification network serves as an accuracy verification module for the forward pose prediction. During the inference stage, it can be used to guide the local optimization of the pose estimation results of low-accuracy keypoints with the self-constrained loss on high-accuracy keypoints as the objective function. Our extensive experimental results on benchmark MS COCO and CrowdPose datasets demonstrate that the proposed method can significantly improve the pose estimation results.","tags":["Human pose estimated","Self-constrained","Structural inference","Prediction optimization"],"title":"Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation","type":"publication"},{"authors":null,"categories":null,"content":"南方科技大学电子与电气工程系2021级专业硕士研究生阚哲涵在人体姿态估计领域提出了一种新型有效的自约束人体姿态估计方法，解决了人体姿态估计中的遮挡、泛化问题。 在国际计算机视觉三大顶级会议之一《European Conference on Computer Vision》（ECCV 2022）上发表研究成果，文章题目为《Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation》。 Figure 1. Illustration of the proposed idea of self-constrained inference optimization of structural groups for human pose estimation.\n随着XR时代的到来，虚拟现实、人机交互、增强现实等技术逐渐成熟，作为XR研究中的核心问题，准确的人体姿态估计愈发重要。但极易发生的对象间的遮挡，背景、纹理变化导致的泛化问题成为了人体姿态估计任务中最难以解决的部分。 Figure 2. The overall framework of the proposed network.\n文章开发了一个自约束的预测验证网络，以表征和学习训练过程中关键点之间的结构相关性。在推理阶段，来自验证网络的反馈信息能够进一步优化姿态预测结果，从而显著提高人体姿态估计的性能。本工作在公开数据集MS COCO 和 CrowdPose 上取得了显著的提升，为后续的研究提供了重要的参考启发价值。 Figure 3. Three examples of refinement of predicted keypoints. The top row is the original estimation. The bottom row is the refined version by the proposed method.\n南科大2021级硕士研究生阚哲涵为本文第一作者，南科大2021级硕士研究生陈烁硕和统计系助理教授李曾为本文作者，电子系讲席教授何志海为本文通讯作者，南科大为论文第一单位。南科大2021级硕士研究生阚哲涵和陈烁硕同学均来自何志海课题组。\r论文链接: https://arxiv.org/abs/2207.02425\r论文资助信息：李曾老师研究部分由国家自然科学基金No. 12031005和No. 12101292支持","date":1666483200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1666483200,"objectID":"b5b26c7b4e66c05454d4eec1720c6227","permalink":"https://nkdailab.github.io/post/zhehan-kan-a-postgraduate-of-zhihai-he-research-group-of-the-department-of-electronics-in-occlusion-and-generalization-issue-in-human-pose-estimation-with-a-novel-self-constrained-approach/","publishdate":"2022-10-23T00:00:00Z","relpermalink":"/post/zhehan-kan-a-postgraduate-of-zhihai-he-research-group-of-the-department-of-electronics-in-occlusion-and-generalization-issue-in-human-pose-estimation-with-a-novel-self-constrained-approach/","section":"post","summary":"南方科技大学电子与电气工程系21级专业硕士研究生阚哲涵在人体姿态估计领域提出了一种新型有效的自约束人体姿态估计方法，解决了人体姿态估计中的遮挡、泛化问题。在国际计算机视觉顶级会议之一（ECCV_2022）上发表研究成果。","tags":null,"title":"电子系何志海课题组硕士研究生阚哲涵提出自约束人体姿态估计方法","type":"post"}]